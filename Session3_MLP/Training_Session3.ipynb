{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Section3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-m0DIxoS-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f996a51b-6f40-495b-a1d5-53aa56c2c5fc"
      },
      "source": [
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyjng-xRCos3"
      },
      "source": [
        "NUM_CLASSES = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIblAyGXmxBO"
      },
      "source": [
        "#Class MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqYjdpGJpkdn"
      },
      "source": [
        "class MLP:\n",
        "  def __init__(self,vocab_size,hidden_size):\n",
        "    self._vocab_size = vocab_size\n",
        "    self._hidden_size = hidden_size\n",
        "  def build_graph(self):\n",
        "    self._X = tf.placeholder(tf.float32,shape= [None,self._vocab_size])\n",
        "    self._real_Y = tf.placeholder(tf.int32,shape=[None,])\n",
        "    weights_1 = tf.get_variable(\n",
        "    name = 'weights_input_hidden',\n",
        "    shape = (self._vocab_size,self._hidden_size),\n",
        "    initializer = tf.random_normal_initializer(seed = 2021),\n",
        "    )\n",
        "    biases_1 = tf.get_variable(\n",
        "        name = \"biases_input_hidden\",\n",
        "        shape = (self._hidden_size),\n",
        "        initializer = tf.random_normal_initializer(seed = 2021)\n",
        "    )\n",
        "    weights_2 = tf.get_variable(\n",
        "    name = 'weights_hidden_output',\n",
        "    shape = (self._hidden_size,NUM_CLASSES),\n",
        "    initializer = tf.random_normal_initializer(seed = 2021),\n",
        "    )\n",
        "    biases_2 = tf.get_variable(\n",
        "        name = \"biases_hidden_output\",\n",
        "        shape = (NUM_CLASSES),\n",
        "        initializer = tf.random_normal_initializer(seed = 2021)\n",
        "    )\n",
        "    hidden = tf.matmul(self._X,weights_1) + biases_1\n",
        "    hidden = tf.sigmoid(hidden)\n",
        "    logits = tf.matmul(hidden,weights_2) + biases_2\n",
        "\n",
        "    labels_one_hot = tf.one_hot(indices=self._real_Y, depth=NUM_CLASSES, dtype = tf.float32)\n",
        "\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels_one_hot, logits = logits)\n",
        "\n",
        "    loss = tf.reduce_mean(loss)\n",
        "\n",
        "    probs = tf.nn.softmax(logits)\n",
        "\n",
        "    predicted_labels = tf.argmax(probs,axis = 1)\n",
        "\n",
        "    predicted_labels = tf.squeeze(predicted_labels)\n",
        "\n",
        "    return predicted_labels, loss\n",
        "  def trainer(self,loss,learning_rate):\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "    return train_op\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hfDe51eSgQa"
      },
      "source": [
        "#DataReader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkZXhjRWSf2n"
      },
      "source": [
        "class DataReader:\n",
        "  def __init__(self,data_path,batch_size,vocab_size):\n",
        "    self._batch_size = batch_size\n",
        "    with open(data_path) as f:\n",
        "      d_lines = f.read().splitlines()\n",
        "    self._data = []\n",
        "    self._labels = []\n",
        "    for data_id, line in enumerate(d_lines):\n",
        "      vector = [0.0 for _ in range(vocab_size)]\n",
        "      features = line.split('<fff>')\n",
        "\n",
        "      label, doc_id = int(features[0]), int(features[1])\n",
        "\n",
        "      tokens = features[2].split()\n",
        "      for token in tokens:\n",
        "        index, value = int(token.split(\":\")[0]), float(token.split(\":\")[1])\n",
        "        vector[index] = value\n",
        "      self._data.append(vector)\n",
        "      self._labels.append(label)\n",
        "\n",
        "    self._data = np.array(self._data)\n",
        "    self._labels = np.array(self._labels)\n",
        "\n",
        "    \n",
        "    self._num_epoch = 0\n",
        "    self._batch_id = 0\n",
        "  def next_batch(self):\n",
        "    start = self._batch_id * self._batch_size\n",
        "    end = start + self._batch_size\n",
        "    self._batch_id += 1\n",
        "\n",
        "    if (end + self._batch_size > len(self._data)):\n",
        "      end = len(self._data)\n",
        "      self._num_epoch  += 1\n",
        "      self._batch_id = 0\n",
        "      indices = range(len(self._data))\n",
        "      random.seed(2021)\n",
        "      random.shuffle(list(indices))\n",
        "      tmpdata = []\n",
        "      tmpy = []\n",
        "      tmpdata = self._data[start:end]\n",
        "      tmpy = self._labels[start:end]\n",
        "      self._data, self._labels = self._data[indices], self._labels[indices]\n",
        "      return tmpdata,tmpy\n",
        "    return  self._data[start:end], self._labels[start:end]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOwbb0TFgGrr"
      },
      "source": [
        "def load_dataset():\n",
        "  train_data_reader = DataReader(\n",
        "      data_path = \"../datasets/20news-bydate/20news-train-tf-idf.txt\",\n",
        "      batch_size = 50,\n",
        "      vocab_size = vocab_size\n",
        "  )\n",
        "\n",
        "  test_data_reader = DataReader(\n",
        "      data_path = \"../datasets/20news-bydate/20news-test-tf-idf.txt\",\n",
        "      batch_size = 50,\n",
        "      vocab_size = vocab_size\n",
        "  )\n",
        "  \n",
        "  return train_data_reader, test_data_reader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyRR4nlTg-23"
      },
      "source": [
        "def save_parameters(name,value,epoch):\n",
        "  filename = name.replace(\":\",\"-colon-\") + \"-epoch-{}.txt\".format(epoch)\n",
        "  if len(value.shape) == 1:\n",
        "    string_form = ','.join([str(number) for number in value])\n",
        "  else:\n",
        "    string_form = '\\n'.join([','.join([str(number) for number in value[row]]) for row in range(value.shape[0])])\n",
        "  with open(\"saved-paras/\"+filename,'w') as f:\n",
        "    f.write(string_form)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meWmlPNzB4j3"
      },
      "source": [
        "def restore_parameters(name,epoch):\n",
        "  filename = name.replace(\":\",\"-colon-\") + \"-epoch-{}.txt\".format(epoch)\n",
        "  with open(\"../saved-paras/\"+filename) as f:\n",
        "    lines = f.read().splitlines()\n",
        "  if len(lines) == 1:\n",
        "    value = [float(number) for number in lines[0].split(',')]\n",
        "  else:\n",
        "    value = [[float(number) for number in lines[row].split(',')] for row in range(len(lines))]\n",
        "  return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-_XFhZsf35H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef731c30-9e47-467c-8b83-c9820ce33996"
      },
      "source": [
        "with open(\"../datasets/20news-bydate/words_idfs.txt\") as f:\n",
        "  vocab_size = len(f.read().splitlines())\n",
        "tf.reset_default_graph()\n",
        "mlp = MLP(\n",
        "    vocab_size = vocab_size,\n",
        "    hidden_size = 50\n",
        ")\n",
        "predicted_labels, loss = mlp.build_graph()\n",
        "train_op = mlp.trainer(loss = loss , learning_rate = 0.1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouF7MplIC86f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37585a81-8d26-4136-d3bc-f694ed335e05"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  train_data_reader,test_data_reader = load_dataset()\n",
        "  print(train_data_reader._labels)\n",
        "  step , MAX_STEP = 0, 10000\n",
        "  tf.global_variables_initializer()\n",
        "\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  while step < MAX_STEP:\n",
        "\n",
        "    train_data, train_labels =  train_data_reader.next_batch()\n",
        "    \n",
        "    plabel_eval, loss_eval, _ = sess.run(\n",
        "        [predicted_labels, loss, train_op],\n",
        "        feed_dict = {\n",
        "            mlp._X : train_data,\n",
        "            mlp._real_Y: train_labels\n",
        "        }\n",
        "    )\n",
        "    step += 1\n",
        "    print('step: {}, loss: {}'.format(step,loss_eval))\n",
        "\n",
        "  trainable_variables = tf.trainable_variables()\n",
        "  for variable in trainable_variables:\n",
        "    save_parameters(\n",
        "      name = variable.name,\n",
        "      value = variable.eval(),\n",
        "      epoch = train_data_reader._num_epoch\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "step: 5001, loss: 0.02486594021320343\n",
            "step: 5002, loss: 0.00012954736303072423\n",
            "step: 5003, loss: 4.7191941121127456e-05\n",
            "step: 5004, loss: 5.5777512898202986e-05\n",
            "step: 5005, loss: 9.724700794322416e-05\n",
            "step: 5006, loss: 0.00018805851868819445\n",
            "step: 5007, loss: 0.05018411576747894\n",
            "step: 5008, loss: 0.0004954746109433472\n",
            "step: 5009, loss: 0.0004638504469767213\n",
            "step: 5010, loss: 0.0001632727071410045\n",
            "step: 5011, loss: 0.0004336951533332467\n",
            "step: 5012, loss: 0.00021524236944969743\n",
            "step: 5013, loss: 0.0007000361219979823\n",
            "step: 5014, loss: 0.00018228247063234448\n",
            "step: 5015, loss: 0.04800159111618996\n",
            "step: 5016, loss: 0.021962208673357964\n",
            "step: 5017, loss: 0.00010516178735997528\n",
            "step: 5018, loss: 5.547820546780713e-05\n",
            "step: 5019, loss: 3.832156289718114e-05\n",
            "step: 5020, loss: 8.2413200289011e-05\n",
            "step: 5021, loss: 7.302707672351971e-05\n",
            "step: 5022, loss: 2.7318579668644816e-05\n",
            "step: 5023, loss: 0.0012954456033185124\n",
            "step: 5024, loss: 0.00011624207400018349\n",
            "step: 5025, loss: 4.5034037611912936e-05\n",
            "step: 5026, loss: 2.336072429898195e-05\n",
            "step: 5027, loss: 6.468754872912541e-05\n",
            "step: 5028, loss: 5.95868841628544e-05\n",
            "step: 5029, loss: 3.522223778418265e-05\n",
            "step: 5030, loss: 0.00023697536380495876\n",
            "step: 5031, loss: 2.145416510757059e-05\n",
            "step: 5032, loss: 2.1583076886599883e-05\n",
            "step: 5033, loss: 5.221628089202568e-05\n",
            "step: 5034, loss: 0.027633514255285263\n",
            "step: 5035, loss: 1.0802043107105419e-05\n",
            "step: 5036, loss: 5.415456325863488e-05\n",
            "step: 5037, loss: 3.983730493928306e-05\n",
            "step: 5038, loss: 1.6166261048056185e-05\n",
            "step: 5039, loss: 0.00013134448090568185\n",
            "step: 5040, loss: 0.0002062341955024749\n",
            "step: 5041, loss: 0.0023722518235445023\n",
            "step: 5042, loss: 9.676207992015406e-05\n",
            "step: 5043, loss: 0.024752572178840637\n",
            "step: 5044, loss: 7.356087007792667e-05\n",
            "step: 5045, loss: 9.159976616501808e-05\n",
            "step: 5046, loss: 3.455797559581697e-05\n",
            "step: 5047, loss: 0.024351969361305237\n",
            "step: 5048, loss: 0.02393493242561817\n",
            "step: 5049, loss: 4.4198237446835265e-05\n",
            "step: 5050, loss: 9.031700028572232e-05\n",
            "step: 5051, loss: 8.82460517459549e-05\n",
            "step: 5052, loss: 0.04598452150821686\n",
            "step: 5053, loss: 1.9064607840846293e-05\n",
            "step: 5054, loss: 3.643529998953454e-05\n",
            "step: 5055, loss: 0.027706502005457878\n",
            "step: 5056, loss: 3.6795769119635224e-05\n",
            "step: 5057, loss: 2.3202541342470795e-05\n",
            "step: 5058, loss: 3.462354652583599e-05\n",
            "step: 5059, loss: 1.3653097994392738e-05\n",
            "step: 5060, loss: 2.784639264064026e-06\n",
            "step: 5061, loss: 3.69997214875184e-05\n",
            "step: 5062, loss: 1.871565018518595e-06\n",
            "step: 5063, loss: 1.3910877896705642e-05\n",
            "step: 5064, loss: 1.4704522072861437e-05\n",
            "step: 5065, loss: 0.00024584922357462347\n",
            "step: 5066, loss: 1.9241071640863083e-05\n",
            "step: 5067, loss: 0.030583884567022324\n",
            "step: 5068, loss: 0.00021975146955810487\n",
            "step: 5069, loss: 3.245937477913685e-05\n",
            "step: 5070, loss: 2.3078316644387087e-06\n",
            "step: 5071, loss: 1.364628678857116e-05\n",
            "step: 5072, loss: 5.545458861888619e-06\n",
            "step: 5073, loss: 4.579886081046425e-06\n",
            "step: 5074, loss: 8.078878636297304e-06\n",
            "step: 5075, loss: 5.593035439233063e-06\n",
            "step: 5076, loss: 4.3963636926491745e-06\n",
            "step: 5077, loss: 4.389208697830327e-06\n",
            "step: 5078, loss: 6.519741145893931e-05\n",
            "step: 5079, loss: 5.364315711631207e-06\n",
            "step: 5080, loss: 3.038227623619605e-05\n",
            "step: 5081, loss: 1.4404623470909428e-05\n",
            "step: 5082, loss: 3.4044860512949526e-05\n",
            "step: 5083, loss: 5.438052539830096e-06\n",
            "step: 5084, loss: 1.6973759557004087e-05\n",
            "step: 5085, loss: 2.5991535949287936e-05\n",
            "step: 5086, loss: 3.6038123653270304e-05\n",
            "step: 5087, loss: 3.896635098499246e-05\n",
            "step: 5088, loss: 6.546485110447975e-06\n",
            "step: 5089, loss: 4.473318040254526e-05\n",
            "step: 5090, loss: 0.00021625513909384608\n",
            "step: 5091, loss: 0.0001316591224167496\n",
            "step: 5092, loss: 3.571466095309006e-06\n",
            "step: 5093, loss: 3.6834424008702626e-06\n",
            "step: 5094, loss: 1.1340565833961591e-05\n",
            "step: 5095, loss: 5.6786461755109485e-06\n",
            "step: 5096, loss: 9.871076144918334e-06\n",
            "step: 5097, loss: 7.392996394628426e-06\n",
            "step: 5098, loss: 1.4829483916400932e-06\n",
            "step: 5099, loss: 3.006407951033907e-06\n",
            "step: 5100, loss: 2.031312078543124e-06\n",
            "step: 5101, loss: 0.0001282702141907066\n",
            "step: 5102, loss: 4.9085997488873545e-06\n",
            "step: 5103, loss: 7.196776550699724e-06\n",
            "step: 5104, loss: 6.019876309437677e-06\n",
            "step: 5105, loss: 2.9872951472498244e-06\n",
            "step: 5106, loss: 1.9621716091933195e-06\n",
            "step: 5107, loss: 1.7547391735206475e-06\n",
            "step: 5108, loss: 0.00024034328816924244\n",
            "step: 5109, loss: 1.0158329132536892e-05\n",
            "step: 5110, loss: 2.3531717943114927e-06\n",
            "step: 5111, loss: 6.3107936512096785e-06\n",
            "step: 5112, loss: 1.2051240446453448e-05\n",
            "step: 5113, loss: 3.4598273487063125e-05\n",
            "step: 5114, loss: 0.0444042906165123\n",
            "step: 5115, loss: 0.0009567646775394678\n",
            "step: 5116, loss: 4.168280429439619e-05\n",
            "step: 5117, loss: 0.00010308206401532516\n",
            "step: 5118, loss: 0.0002515668165870011\n",
            "step: 5119, loss: 3.1689702154835686e-05\n",
            "step: 5120, loss: 0.00828886590898037\n",
            "step: 5121, loss: 0.028257446363568306\n",
            "step: 5122, loss: 2.8352014851407148e-05\n",
            "step: 5123, loss: 1.531941961729899e-05\n",
            "step: 5124, loss: 5.5640841310378164e-05\n",
            "step: 5125, loss: 3.370003469171934e-05\n",
            "step: 5126, loss: 0.00030388313462026417\n",
            "step: 5127, loss: 2.3348584363702685e-05\n",
            "step: 5128, loss: 0.0003345537115819752\n",
            "step: 5129, loss: 2.5710980480653234e-05\n",
            "step: 5130, loss: 0.00010220307012787089\n",
            "step: 5131, loss: 3.970424222643487e-05\n",
            "step: 5132, loss: 0.00016963467351160944\n",
            "step: 5133, loss: 1.7079692042898387e-05\n",
            "step: 5134, loss: 0.00011041511606890708\n",
            "step: 5135, loss: 2.742867945926264e-05\n",
            "step: 5136, loss: 1.6523157682968304e-05\n",
            "step: 5137, loss: 2.731288259383291e-05\n",
            "step: 5138, loss: 1.201595750899287e-05\n",
            "step: 5139, loss: 0.00046864349860697985\n",
            "step: 5140, loss: 1.4217325770005118e-05\n",
            "step: 5141, loss: 7.273731625900837e-06\n",
            "step: 5142, loss: 1.649839646233886e-06\n",
            "step: 5143, loss: 3.273425363659044e-06\n",
            "step: 5144, loss: 1.2841756870329846e-05\n",
            "step: 5145, loss: 5.745862949879665e-07\n",
            "step: 5146, loss: 5.214046723267529e-06\n",
            "step: 5147, loss: 0.0002069393958663568\n",
            "step: 5148, loss: 9.736840729601681e-05\n",
            "step: 5149, loss: 6.753760681021959e-05\n",
            "step: 5150, loss: 6.464283796958625e-05\n",
            "step: 5151, loss: 4.0533846913604066e-05\n",
            "step: 5152, loss: 1.4651479432359338e-05\n",
            "step: 5153, loss: 1.0320537512598094e-05\n",
            "step: 5154, loss: 2.6104156859219074e-05\n",
            "step: 5155, loss: 2.813755054376088e-05\n",
            "step: 5156, loss: 8.584003080613911e-05\n",
            "step: 5157, loss: 8.025665010791272e-05\n",
            "step: 5158, loss: 0.00015477437409572303\n",
            "step: 5159, loss: 5.174575198907405e-05\n",
            "step: 5160, loss: 8.242097828770056e-05\n",
            "step: 5161, loss: 0.00010527786071179435\n",
            "step: 5162, loss: 4.0442380850436166e-05\n",
            "step: 5163, loss: 4.361866376711987e-05\n",
            "step: 5164, loss: 1.817518386815209e-05\n",
            "step: 5165, loss: 3.6692238154500956e-06\n",
            "step: 5166, loss: 0.00032842240761965513\n",
            "step: 5167, loss: 7.13012195774354e-05\n",
            "step: 5168, loss: 4.138471558690071e-05\n",
            "step: 5169, loss: 2.1448162442538887e-05\n",
            "step: 5170, loss: 3.62075115845073e-05\n",
            "step: 5171, loss: 1.7529619071865454e-05\n",
            "step: 5172, loss: 1.6712061551515944e-05\n",
            "step: 5173, loss: 1.838771640905179e-05\n",
            "step: 5174, loss: 4.827012890018523e-05\n",
            "step: 5175, loss: 1.1326225830998737e-05\n",
            "step: 5176, loss: 1.3755231520917732e-05\n",
            "step: 5177, loss: 1.0371181815571617e-06\n",
            "step: 5178, loss: 7.493084922316484e-06\n",
            "step: 5179, loss: 6.737489002262009e-06\n",
            "step: 5180, loss: 8.220432391681243e-06\n",
            "step: 5181, loss: 3.3282919957855484e-06\n",
            "step: 5182, loss: 1.4437858226301614e-05\n",
            "step: 5183, loss: 8.692654955666512e-05\n",
            "step: 5184, loss: 4.282557711121626e-05\n",
            "step: 5185, loss: 1.8492539311409928e-05\n",
            "step: 5186, loss: 7.984278454387095e-06\n",
            "step: 5187, loss: 2.887205027946038e-06\n",
            "step: 5188, loss: 9.216257240041159e-06\n",
            "step: 5189, loss: 2.2054182409192435e-05\n",
            "step: 5190, loss: 1.3947189927421277e-06\n",
            "step: 5191, loss: 5.888675786991371e-06\n",
            "step: 5192, loss: 5.0292313972022384e-05\n",
            "step: 5193, loss: 0.0002312909928150475\n",
            "step: 5194, loss: 8.736856398172677e-05\n",
            "step: 5195, loss: 1.5125162462936714e-05\n",
            "step: 5196, loss: 8.998627890832722e-05\n",
            "step: 5197, loss: 5.1894778152927756e-05\n",
            "step: 5198, loss: 1.5085851373441983e-05\n",
            "step: 5199, loss: 5.856617644894868e-05\n",
            "step: 5200, loss: 2.8221651518833824e-05\n",
            "step: 5201, loss: 2.1589505195152014e-05\n",
            "step: 5202, loss: 2.0992978534195572e-05\n",
            "step: 5203, loss: 4.194937719148584e-05\n",
            "step: 5204, loss: 1.777482611942105e-05\n",
            "step: 5205, loss: 3.103858034592122e-05\n",
            "step: 5206, loss: 3.9401780668413267e-05\n",
            "step: 5207, loss: 2.1587289666058496e-05\n",
            "step: 5208, loss: 0.0133152911439538\n",
            "step: 5209, loss: 0.00033616143628023565\n",
            "step: 5210, loss: 0.0003702504909597337\n",
            "step: 5211, loss: 0.03431905433535576\n",
            "step: 5212, loss: 0.00012583710486069322\n",
            "step: 5213, loss: 6.21409562882036e-05\n",
            "step: 5214, loss: 0.00020336074521765113\n",
            "step: 5215, loss: 7.123722025426105e-05\n",
            "step: 5216, loss: 0.046016875654459\n",
            "step: 5217, loss: 0.0314863882958889\n",
            "step: 5218, loss: 0.00012592686107382178\n",
            "step: 5219, loss: 9.029972716234624e-05\n",
            "step: 5220, loss: 0.03211032226681709\n",
            "step: 5221, loss: 0.00039116450352594256\n",
            "step: 5222, loss: 0.00012421925202943385\n",
            "step: 5223, loss: 0.00019747957412619144\n",
            "step: 5224, loss: 0.00014738080790266395\n",
            "step: 5225, loss: 0.024858737364411354\n",
            "step: 5226, loss: 0.0004424705693963915\n",
            "step: 5227, loss: 0.026839638128876686\n",
            "step: 5228, loss: 0.00011083405115641654\n",
            "step: 5229, loss: 4.14547830587253e-05\n",
            "step: 5230, loss: 4.724757673102431e-05\n",
            "step: 5231, loss: 8.589235949330032e-05\n",
            "step: 5232, loss: 0.0001672254002187401\n",
            "step: 5233, loss: 0.051877204328775406\n",
            "step: 5234, loss: 0.0004342501924838871\n",
            "step: 5235, loss: 0.00040614523459225893\n",
            "step: 5236, loss: 0.00013801228487864137\n",
            "step: 5237, loss: 0.00032244515023194253\n",
            "step: 5238, loss: 0.00018084532348439097\n",
            "step: 5239, loss: 0.000627962697762996\n",
            "step: 5240, loss: 0.00016627552395220846\n",
            "step: 5241, loss: 0.0839400663971901\n",
            "step: 5242, loss: 0.023324375972151756\n",
            "step: 5243, loss: 0.00040605306276120245\n",
            "step: 5244, loss: 4.801535396836698e-05\n",
            "step: 5245, loss: 3.55503179889638e-05\n",
            "step: 5246, loss: 6.911250966368243e-05\n",
            "step: 5247, loss: 6.255295738810673e-05\n",
            "step: 5248, loss: 2.413897163933143e-05\n",
            "step: 5249, loss: 0.0011698787566274405\n",
            "step: 5250, loss: 8.409118163399398e-05\n",
            "step: 5251, loss: 3.5953260521637276e-05\n",
            "step: 5252, loss: 2.050503098871559e-05\n",
            "step: 5253, loss: 5.490741750691086e-05\n",
            "step: 5254, loss: 5.135859828442335e-05\n",
            "step: 5255, loss: 3.193098382325843e-05\n",
            "step: 5256, loss: 0.00023001512454356998\n",
            "step: 5257, loss: 1.9454952052910812e-05\n",
            "step: 5258, loss: 1.9576569684431888e-05\n",
            "step: 5259, loss: 5.634200351778418e-05\n",
            "step: 5260, loss: 0.027813108637928963\n",
            "step: 5261, loss: 1.029905160976341e-05\n",
            "step: 5262, loss: 4.7702258598292246e-05\n",
            "step: 5263, loss: 3.4426237107254565e-05\n",
            "step: 5264, loss: 1.3617912372865248e-05\n",
            "step: 5265, loss: 8.252704719780013e-05\n",
            "step: 5266, loss: 0.00016737949044909328\n",
            "step: 5267, loss: 0.0017209394136443734\n",
            "step: 5268, loss: 8.519061520928517e-05\n",
            "step: 5269, loss: 0.024269305169582367\n",
            "step: 5270, loss: 6.909011426614597e-05\n",
            "step: 5271, loss: 8.409377187490463e-05\n",
            "step: 5272, loss: 2.915390723501332e-05\n",
            "step: 5273, loss: 0.0233999565243721\n",
            "step: 5274, loss: 0.024800539016723633\n",
            "step: 5275, loss: 3.761436164495535e-05\n",
            "step: 5276, loss: 7.541575178038329e-05\n",
            "step: 5277, loss: 7.520403596572578e-05\n",
            "step: 5278, loss: 0.04618820175528526\n",
            "step: 5279, loss: 1.695738137641456e-05\n",
            "step: 5280, loss: 3.4211869206046686e-05\n",
            "step: 5281, loss: 0.02958577126264572\n",
            "step: 5282, loss: 2.9217078918009065e-05\n",
            "step: 5283, loss: 1.974164115381427e-05\n",
            "step: 5284, loss: 2.9895052648498677e-05\n",
            "step: 5285, loss: 1.1271663424849976e-05\n",
            "step: 5286, loss: 2.551005536588491e-06\n",
            "step: 5287, loss: 2.9852786610717885e-05\n",
            "step: 5288, loss: 1.537785919936141e-06\n",
            "step: 5289, loss: 1.4987754184403457e-05\n",
            "step: 5290, loss: 1.2444676031009294e-05\n",
            "step: 5291, loss: 0.00019789833459071815\n",
            "step: 5292, loss: 1.7698654119158164e-05\n",
            "step: 5293, loss: 0.030360747128725052\n",
            "step: 5294, loss: 0.0002156914706574753\n",
            "step: 5295, loss: 3.609862324083224e-05\n",
            "step: 5296, loss: 2.0861104985669954e-06\n",
            "step: 5297, loss: 1.2242157026776113e-05\n",
            "step: 5298, loss: 5.428629265225027e-06\n",
            "step: 5299, loss: 5.080532901047263e-06\n",
            "step: 5300, loss: 7.473395726265153e-06\n",
            "step: 5301, loss: 5.0471076065150555e-06\n",
            "step: 5302, loss: 4.169865405856399e-06\n",
            "step: 5303, loss: 3.3878850445034914e-06\n",
            "step: 5304, loss: 5.503500869963318e-05\n",
            "step: 5305, loss: 3.7669608445867198e-06\n",
            "step: 5306, loss: 2.6328647436457686e-05\n",
            "step: 5307, loss: 1.138508741860278e-05\n",
            "step: 5308, loss: 2.832923928508535e-05\n",
            "step: 5309, loss: 4.188869297649944e-06\n",
            "step: 5310, loss: 1.4163407286105212e-05\n",
            "step: 5311, loss: 1.8740605810307898e-05\n",
            "step: 5312, loss: 2.8260772523935884e-05\n",
            "step: 5313, loss: 3.0042203434277326e-05\n",
            "step: 5314, loss: 5.597693416348193e-06\n",
            "step: 5315, loss: 3.471097443252802e-05\n",
            "step: 5316, loss: 0.00021681647922378033\n",
            "step: 5317, loss: 0.00011315440497128293\n",
            "step: 5318, loss: 3.2591424314887263e-06\n",
            "step: 5319, loss: 2.4103696887323167e-06\n",
            "step: 5320, loss: 8.112800060189329e-06\n",
            "step: 5321, loss: 5.8598989198799245e-06\n",
            "step: 5322, loss: 7.613985872012563e-06\n",
            "step: 5323, loss: 5.8743821682583075e-06\n",
            "step: 5324, loss: 1.2946028391525033e-06\n",
            "step: 5325, loss: 2.6058737603307236e-06\n",
            "step: 5326, loss: 1.814354504858784e-06\n",
            "step: 5327, loss: 0.00016843975754454732\n",
            "step: 5328, loss: 4.269758392183576e-06\n",
            "step: 5329, loss: 6.538927664223593e-06\n",
            "step: 5330, loss: 5.192627213546075e-06\n",
            "step: 5331, loss: 2.880014335460146e-06\n",
            "step: 5332, loss: 1.914488393595093e-06\n",
            "step: 5333, loss: 1.6164608496183064e-06\n",
            "step: 5334, loss: 0.0001996688370127231\n",
            "step: 5335, loss: 8.925840120355133e-06\n",
            "step: 5336, loss: 2.2339640963764396e-06\n",
            "step: 5337, loss: 5.395294920162996e-06\n",
            "step: 5338, loss: 1.2954460544278845e-05\n",
            "step: 5339, loss: 2.73848490905948e-05\n",
            "step: 5340, loss: 0.043547939509153366\n",
            "step: 5341, loss: 0.0012556936126202345\n",
            "step: 5342, loss: 4.0989449189510196e-05\n",
            "step: 5343, loss: 5.935503577347845e-05\n",
            "step: 5344, loss: 0.00023373255680780858\n",
            "step: 5345, loss: 2.9081727916491218e-05\n",
            "step: 5346, loss: 0.008050474338233471\n",
            "step: 5347, loss: 0.02721896581351757\n",
            "step: 5348, loss: 2.3768143364577554e-05\n",
            "step: 5349, loss: 1.371764847135637e-05\n",
            "step: 5350, loss: 5.455878272186965e-05\n",
            "step: 5351, loss: 3.445745096541941e-05\n",
            "step: 5352, loss: 0.0002888966409955174\n",
            "step: 5353, loss: 2.264044996991288e-05\n",
            "step: 5354, loss: 0.00031660060631111264\n",
            "step: 5355, loss: 2.5501074560452253e-05\n",
            "step: 5356, loss: 8.92809039214626e-05\n",
            "step: 5357, loss: 3.935109270969406e-05\n",
            "step: 5358, loss: 0.00015868486661929637\n",
            "step: 5359, loss: 1.6016394511098042e-05\n",
            "step: 5360, loss: 5.105894888401963e-05\n",
            "step: 5361, loss: 2.426527498755604e-05\n",
            "step: 5362, loss: 1.3431483239401132e-05\n",
            "step: 5363, loss: 2.3329403120442294e-05\n",
            "step: 5364, loss: 9.430170393898152e-06\n",
            "step: 5365, loss: 0.0003437581763137132\n",
            "step: 5366, loss: 1.2136341865698341e-05\n",
            "step: 5367, loss: 6.289167686190922e-06\n",
            "step: 5368, loss: 1.3708947790291859e-06\n",
            "step: 5369, loss: 2.627330331961275e-06\n",
            "step: 5370, loss: 1.0050599485111888e-05\n",
            "step: 5371, loss: 4.100786838989734e-07\n",
            "step: 5372, loss: 4.525047643255675e-06\n",
            "step: 5373, loss: 0.00018103561887983233\n",
            "step: 5374, loss: 7.379457383649424e-05\n",
            "step: 5375, loss: 6.28720226814039e-05\n",
            "step: 5376, loss: 5.534298543352634e-05\n",
            "step: 5377, loss: 3.7473368138307706e-05\n",
            "step: 5378, loss: 1.396023162669735e-05\n",
            "step: 5379, loss: 9.505254638497718e-06\n",
            "step: 5380, loss: 2.3489816157962196e-05\n",
            "step: 5381, loss: 2.6759738830151036e-05\n",
            "step: 5382, loss: 7.258916593855247e-05\n",
            "step: 5383, loss: 7.633531640749425e-05\n",
            "step: 5384, loss: 0.00013153902546036988\n",
            "step: 5385, loss: 4.7150464524747804e-05\n",
            "step: 5386, loss: 6.833084626123309e-05\n",
            "step: 5387, loss: 7.717984408373013e-05\n",
            "step: 5388, loss: 2.6133078790735453e-05\n",
            "step: 5389, loss: 3.672083403216675e-05\n",
            "step: 5390, loss: 1.3093041161482688e-05\n",
            "step: 5391, loss: 2.508144234525389e-06\n",
            "step: 5392, loss: 0.0002733731525950134\n",
            "step: 5393, loss: 4.274257298675366e-05\n",
            "step: 5394, loss: 2.9156068194424734e-05\n",
            "step: 5395, loss: 1.3769517863693181e-05\n",
            "step: 5396, loss: 2.5607296265661716e-05\n",
            "step: 5397, loss: 1.5148231796047185e-05\n",
            "step: 5398, loss: 1.5377147065009922e-05\n",
            "step: 5399, loss: 1.3062655852991156e-05\n",
            "step: 5400, loss: 4.6390414354391396e-05\n",
            "step: 5401, loss: 8.797081136435736e-06\n",
            "step: 5402, loss: 1.2086621609341819e-05\n",
            "step: 5403, loss: 1.0442707889524172e-06\n",
            "step: 5404, loss: 6.463258159783436e-06\n",
            "step: 5405, loss: 6.661232873739209e-06\n",
            "step: 5406, loss: 7.481385637220228e-06\n",
            "step: 5407, loss: 3.2829941574163968e-06\n",
            "step: 5408, loss: 1.1616331903496757e-05\n",
            "step: 5409, loss: 6.050420779502019e-05\n",
            "step: 5410, loss: 4.2764255340443924e-05\n",
            "step: 5411, loss: 2.0351879356894642e-05\n",
            "step: 5412, loss: 7.364457815128844e-06\n",
            "step: 5413, loss: 3.1828394639887847e-06\n",
            "step: 5414, loss: 8.746703315409832e-06\n",
            "step: 5415, loss: 2.084147672576364e-05\n",
            "step: 5416, loss: 1.170616314993822e-06\n",
            "step: 5417, loss: 4.620416802936234e-06\n",
            "step: 5418, loss: 4.414114300743677e-05\n",
            "step: 5419, loss: 0.00020329462131485343\n",
            "step: 5420, loss: 7.095948240021244e-05\n",
            "step: 5421, loss: 1.7760614355211146e-05\n",
            "step: 5422, loss: 7.98904147814028e-05\n",
            "step: 5423, loss: 4.6972454583738e-05\n",
            "step: 5424, loss: 1.3566395864472724e-05\n",
            "step: 5425, loss: 5.1132541557308286e-05\n",
            "step: 5426, loss: 2.4373175619984977e-05\n",
            "step: 5427, loss: 1.8164717403124087e-05\n",
            "step: 5428, loss: 1.887623147922568e-05\n",
            "step: 5429, loss: 3.7205212720436975e-05\n",
            "step: 5430, loss: 1.6239582691923715e-05\n",
            "step: 5431, loss: 2.694697104743682e-05\n",
            "step: 5432, loss: 3.639727219706401e-05\n",
            "step: 5433, loss: 2.009260242630262e-05\n",
            "step: 5434, loss: 0.014672632329165936\n",
            "step: 5435, loss: 0.0003535512078087777\n",
            "step: 5436, loss: 0.0004077685298398137\n",
            "step: 5437, loss: 0.03900528326630592\n",
            "step: 5438, loss: 0.00015130284009501338\n",
            "step: 5439, loss: 7.774827827233821e-05\n",
            "step: 5440, loss: 0.00023343235079664737\n",
            "step: 5441, loss: 8.31273355288431e-05\n",
            "step: 5442, loss: 0.04860471189022064\n",
            "step: 5443, loss: 0.034895919263362885\n",
            "step: 5444, loss: 0.0001413891150150448\n",
            "step: 5445, loss: 9.6158153610304e-05\n",
            "step: 5446, loss: 0.03283698856830597\n",
            "step: 5447, loss: 0.00027207733364775777\n",
            "step: 5448, loss: 0.00013675456284545362\n",
            "step: 5449, loss: 0.00013828395458403975\n",
            "step: 5450, loss: 0.00015794570208527148\n",
            "step: 5451, loss: 0.02588946558535099\n",
            "step: 5452, loss: 0.0002631803508847952\n",
            "step: 5453, loss: 0.02803502045571804\n",
            "step: 5454, loss: 0.00010604586714180186\n",
            "step: 5455, loss: 3.9555205148644745e-05\n",
            "step: 5456, loss: 4.483268639887683e-05\n",
            "step: 5457, loss: 8.298876491608098e-05\n",
            "step: 5458, loss: 0.00014162571460474283\n",
            "step: 5459, loss: 0.054674528539180756\n",
            "step: 5460, loss: 0.0003191551077179611\n",
            "step: 5461, loss: 0.0003553838178049773\n",
            "step: 5462, loss: 0.00010024898074334487\n",
            "step: 5463, loss: 0.000214093248359859\n",
            "step: 5464, loss: 0.00014369719428941607\n",
            "step: 5465, loss: 0.0005462373956106603\n",
            "step: 5466, loss: 0.0001412005367456004\n",
            "step: 5467, loss: 0.01740572601556778\n",
            "step: 5468, loss: 0.024003375321626663\n",
            "step: 5469, loss: 5.8104764320887625e-05\n",
            "step: 5470, loss: 4.341826934251003e-05\n",
            "step: 5471, loss: 3.3753778552636504e-05\n",
            "step: 5472, loss: 5.9390738897491246e-05\n",
            "step: 5473, loss: 5.722969945054501e-05\n",
            "step: 5474, loss: 2.2572980014956556e-05\n",
            "step: 5475, loss: 0.0010019507026299834\n",
            "step: 5476, loss: 6.707173452014104e-05\n",
            "step: 5477, loss: 3.0442566639976576e-05\n",
            "step: 5478, loss: 1.7675958588370122e-05\n",
            "step: 5479, loss: 4.618938692146912e-05\n",
            "step: 5480, loss: 4.247432661941275e-05\n",
            "step: 5481, loss: 2.6692485334933735e-05\n",
            "step: 5482, loss: 0.0002107450127368793\n",
            "step: 5483, loss: 1.5147641533985734e-05\n",
            "step: 5484, loss: 1.6702075299690478e-05\n",
            "step: 5485, loss: 4.8019603127613664e-05\n",
            "step: 5486, loss: 0.028495710343122482\n",
            "step: 5487, loss: 8.62314846017398e-06\n",
            "step: 5488, loss: 4.318646097090095e-05\n",
            "step: 5489, loss: 2.836377825587988e-05\n",
            "step: 5490, loss: 1.0738040145952255e-05\n",
            "step: 5491, loss: 6.927038339199498e-05\n",
            "step: 5492, loss: 0.00012502854224294424\n",
            "step: 5493, loss: 0.00015931212692521513\n",
            "step: 5494, loss: 7.927428669063374e-05\n",
            "step: 5495, loss: 0.023220684379339218\n",
            "step: 5496, loss: 6.707391003146768e-05\n",
            "step: 5497, loss: 8.523512951796874e-05\n",
            "step: 5498, loss: 2.5938112230505794e-05\n",
            "step: 5499, loss: 0.022563830018043518\n",
            "step: 5500, loss: 0.024775536730885506\n",
            "step: 5501, loss: 3.399104389245622e-05\n",
            "step: 5502, loss: 6.431362999137491e-05\n",
            "step: 5503, loss: 6.955082790227607e-05\n",
            "step: 5504, loss: 0.050399575382471085\n",
            "step: 5505, loss: 1.5634388546459377e-05\n",
            "step: 5506, loss: 3.365154771017842e-05\n",
            "step: 5507, loss: 0.0270403865724802\n",
            "step: 5508, loss: 2.7065238100476563e-05\n",
            "step: 5509, loss: 1.733893259370234e-05\n",
            "step: 5510, loss: 2.893960481742397e-05\n",
            "step: 5511, loss: 1.1212063327548094e-05\n",
            "step: 5512, loss: 2.3054446955939056e-06\n",
            "step: 5513, loss: 2.6176348910667002e-05\n",
            "step: 5514, loss: 1.5067911363075837e-06\n",
            "step: 5515, loss: 1.5040090147522278e-05\n",
            "step: 5516, loss: 1.1712833838828374e-05\n",
            "step: 5517, loss: 0.000181394032551907\n",
            "step: 5518, loss: 1.7488930097897537e-05\n",
            "step: 5519, loss: 0.031681548804044724\n",
            "step: 5520, loss: 0.00018113601254299283\n",
            "step: 5521, loss: 2.8154394385637715e-05\n",
            "step: 5522, loss: 2.0813388346141437e-06\n",
            "step: 5523, loss: 1.145781970990356e-05\n",
            "step: 5524, loss: 4.66572237201035e-06\n",
            "step: 5525, loss: 3.545209210642497e-06\n",
            "step: 5526, loss: 5.363914169720374e-06\n",
            "step: 5527, loss: 4.1745693124539685e-06\n",
            "step: 5528, loss: 3.1995341487345286e-06\n",
            "step: 5529, loss: 3.356891056682798e-06\n",
            "step: 5530, loss: 5.1807779527734965e-05\n",
            "step: 5531, loss: 3.662061089926283e-06\n",
            "step: 5532, loss: 2.5063289285753854e-05\n",
            "step: 5533, loss: 1.003847319225315e-05\n",
            "step: 5534, loss: 2.4265060346806422e-05\n",
            "step: 5535, loss: 4.0982877180795185e-06\n",
            "step: 5536, loss: 1.3083501471555792e-05\n",
            "step: 5537, loss: 1.582140612299554e-05\n",
            "step: 5538, loss: 2.4234939701273106e-05\n",
            "step: 5539, loss: 2.6948158847517334e-05\n",
            "step: 5540, loss: 5.20674211657024e-06\n",
            "step: 5541, loss: 2.962236976600252e-05\n",
            "step: 5542, loss: 0.00013675220543518662\n",
            "step: 5543, loss: 9.633028093958274e-05\n",
            "step: 5544, loss: 2.758474693109747e-06\n",
            "step: 5545, loss: 1.9168624021403957e-06\n",
            "step: 5546, loss: 6.310592198133236e-06\n",
            "step: 5547, loss: 5.404608600656502e-06\n",
            "step: 5548, loss: 6.4770142671477515e-06\n",
            "step: 5549, loss: 4.787273155670846e-06\n",
            "step: 5550, loss: 1.1420171404097346e-06\n",
            "step: 5551, loss: 2.3054753910400905e-06\n",
            "step: 5552, loss: 1.6903778714549844e-06\n",
            "step: 5553, loss: 0.00018133848789148033\n",
            "step: 5554, loss: 4.1219591366825625e-06\n",
            "step: 5555, loss: 5.478269940795144e-06\n",
            "step: 5556, loss: 5.264152605377603e-06\n",
            "step: 5557, loss: 2.8514070891105803e-06\n",
            "step: 5558, loss: 1.8882624317484442e-06\n",
            "step: 5559, loss: 1.7642752254687366e-06\n",
            "step: 5560, loss: 0.00017470760212745517\n",
            "step: 5561, loss: 8.52776338433614e-06\n",
            "step: 5562, loss: 2.186280880778213e-06\n",
            "step: 5563, loss: 4.982839982403675e-06\n",
            "step: 5564, loss: 1.063275158230681e-05\n",
            "step: 5565, loss: 2.327992297068704e-05\n",
            "step: 5566, loss: 0.04163672775030136\n",
            "step: 5567, loss: 0.0007086531259119511\n",
            "step: 5568, loss: 3.37820929416921e-05\n",
            "step: 5569, loss: 5.6211152696050704e-05\n",
            "step: 5570, loss: 0.00021649895643349737\n",
            "step: 5571, loss: 2.4066415790002793e-05\n",
            "step: 5572, loss: 0.007648195140063763\n",
            "step: 5573, loss: 0.026368523016572\n",
            "step: 5574, loss: 2.0402214431669563e-05\n",
            "step: 5575, loss: 1.1150196769449394e-05\n",
            "step: 5576, loss: 4.7998048103181645e-05\n",
            "step: 5577, loss: 3.278445728938095e-05\n",
            "step: 5578, loss: 0.0002767368860077113\n",
            "step: 5579, loss: 2.0576489987433888e-05\n",
            "step: 5580, loss: 0.00025362957967445254\n",
            "step: 5581, loss: 2.3272139515029266e-05\n",
            "step: 5582, loss: 6.183383811730891e-05\n",
            "step: 5583, loss: 3.613303852034733e-05\n",
            "step: 5584, loss: 0.00014821642253082246\n",
            "step: 5585, loss: 1.3658590432896744e-05\n",
            "step: 5586, loss: 3.304727215436287e-05\n",
            "step: 5587, loss: 2.029612733167596e-05\n",
            "step: 5588, loss: 8.542289833712857e-06\n",
            "step: 5589, loss: 1.9525494280969724e-05\n",
            "step: 5590, loss: 7.726054718659725e-06\n",
            "step: 5591, loss: 0.0002694968425203115\n",
            "step: 5592, loss: 1.1130445273010992e-05\n",
            "step: 5593, loss: 5.8362074923934415e-06\n",
            "step: 5594, loss: 1.2206934343339526e-06\n",
            "step: 5595, loss: 2.3197790142148733e-06\n",
            "step: 5596, loss: 8.215197340177838e-06\n",
            "step: 5597, loss: 3.600110289880831e-07\n",
            "step: 5598, loss: 4.324781457398785e-06\n",
            "step: 5599, loss: 0.0001584795827511698\n",
            "step: 5600, loss: 5.333063018042594e-05\n",
            "step: 5601, loss: 6.166982348076999e-05\n",
            "step: 5602, loss: 5.73223915125709e-05\n",
            "step: 5603, loss: 3.4715743822744116e-05\n",
            "step: 5604, loss: 1.322601929132361e-05\n",
            "step: 5605, loss: 8.04867158876732e-06\n",
            "step: 5606, loss: 2.0594159650499932e-05\n",
            "step: 5607, loss: 2.398029391770251e-05\n",
            "step: 5608, loss: 6.319090607576072e-05\n",
            "step: 5609, loss: 6.664936518063769e-05\n",
            "step: 5610, loss: 0.00010815614223247394\n",
            "step: 5611, loss: 4.1844854422379285e-05\n",
            "step: 5612, loss: 5.325031452230178e-05\n",
            "step: 5613, loss: 5.472584598464891e-05\n",
            "step: 5614, loss: 1.7305164874414913e-05\n",
            "step: 5615, loss: 3.1579424103256315e-05\n",
            "step: 5616, loss: 9.352761480840854e-06\n",
            "step: 5617, loss: 2.16244075090799e-06\n",
            "step: 5618, loss: 0.00022741412976756692\n",
            "step: 5619, loss: 3.0108767532510683e-05\n",
            "step: 5620, loss: 1.8468197595211677e-05\n",
            "step: 5621, loss: 1.0031976671598386e-05\n",
            "step: 5622, loss: 1.9221071852371097e-05\n",
            "step: 5623, loss: 1.3751242477155756e-05\n",
            "step: 5624, loss: 1.5107791114132851e-05\n",
            "step: 5625, loss: 1.4020550224813633e-05\n",
            "step: 5626, loss: 4.47203783551231e-05\n",
            "step: 5627, loss: 8.162970516423229e-06\n",
            "step: 5628, loss: 1.129530392063316e-05\n",
            "step: 5629, loss: 1.0228131941403262e-06\n",
            "step: 5630, loss: 6.141421636129962e-06\n",
            "step: 5631, loss: 6.50149831926683e-06\n",
            "step: 5632, loss: 7.3764767876127735e-06\n",
            "step: 5633, loss: 3.1423305699718185e-06\n",
            "step: 5634, loss: 9.785904694581404e-06\n",
            "step: 5635, loss: 5.6223583669634536e-05\n",
            "step: 5636, loss: 4.03593949158676e-05\n",
            "step: 5637, loss: 1.5193405488389544e-05\n",
            "step: 5638, loss: 5.681336460838793e-06\n",
            "step: 5639, loss: 2.5319711767224362e-06\n",
            "step: 5640, loss: 7.774110599712003e-06\n",
            "step: 5641, loss: 1.64584162121173e-05\n",
            "step: 5642, loss: 1.0514103223613347e-06\n",
            "step: 5643, loss: 3.5332993775227806e-06\n",
            "step: 5644, loss: 3.940763053833507e-05\n",
            "step: 5645, loss: 0.00017730386753100902\n",
            "step: 5646, loss: 6.188768020365387e-05\n",
            "step: 5647, loss: 1.3771383237326518e-05\n",
            "step: 5648, loss: 7.038235344225541e-05\n",
            "step: 5649, loss: 4.2206938815070316e-05\n",
            "step: 5650, loss: 1.1380054274923168e-05\n",
            "step: 5651, loss: 4.836617881665006e-05\n",
            "step: 5652, loss: 2.2819225705461577e-05\n",
            "step: 5653, loss: 1.5385689039248973e-05\n",
            "step: 5654, loss: 1.792271541489754e-05\n",
            "step: 5655, loss: 3.46839296980761e-05\n",
            "step: 5656, loss: 1.5281246305676177e-05\n",
            "step: 5657, loss: 2.4461363864247687e-05\n",
            "step: 5658, loss: 3.5050936276093125e-05\n",
            "step: 5659, loss: 1.9291592252557166e-05\n",
            "step: 5660, loss: 0.012990878894925117\n",
            "step: 5661, loss: 0.00023980245168786496\n",
            "step: 5662, loss: 0.00024032648070715368\n",
            "step: 5663, loss: 0.028054244816303253\n",
            "step: 5664, loss: 8.739347686059773e-05\n",
            "step: 5665, loss: 4.453001020010561e-05\n",
            "step: 5666, loss: 0.0001396529987687245\n",
            "step: 5667, loss: 5.4735413868911564e-05\n",
            "step: 5668, loss: 0.04837223142385483\n",
            "step: 5669, loss: 0.03206585347652435\n",
            "step: 5670, loss: 9.290305752074346e-05\n",
            "step: 5671, loss: 6.783979188185185e-05\n",
            "step: 5672, loss: 0.035259634256362915\n",
            "step: 5673, loss: 0.0002109530323650688\n",
            "step: 5674, loss: 0.00011933995119761676\n",
            "step: 5675, loss: 0.00011533001088537276\n",
            "step: 5676, loss: 0.00013482900976669043\n",
            "step: 5677, loss: 0.02696075290441513\n",
            "step: 5678, loss: 0.00020896564819850028\n",
            "step: 5679, loss: 0.03096386231482029\n",
            "step: 5680, loss: 8.573028026148677e-05\n",
            "step: 5681, loss: 3.428734271437861e-05\n",
            "step: 5682, loss: 3.736951111932285e-05\n",
            "step: 5683, loss: 6.97238210705109e-05\n",
            "step: 5684, loss: 0.00013181920803617686\n",
            "step: 5685, loss: 0.054537247866392136\n",
            "step: 5686, loss: 0.0002412505418760702\n",
            "step: 5687, loss: 0.0003354235668666661\n",
            "step: 5688, loss: 9.567672532284632e-05\n",
            "step: 5689, loss: 0.0001794916024664417\n",
            "step: 5690, loss: 0.00012654706370085478\n",
            "step: 5691, loss: 0.0005893696798011661\n",
            "step: 5692, loss: 0.00013667605526279658\n",
            "step: 5693, loss: 0.020624399185180664\n",
            "step: 5694, loss: 0.024815646931529045\n",
            "step: 5695, loss: 5.4767322581028566e-05\n",
            "step: 5696, loss: 3.833977098111063e-05\n",
            "step: 5697, loss: 3.179509803885594e-05\n",
            "step: 5698, loss: 5.1079579861834645e-05\n",
            "step: 5699, loss: 5.013139161746949e-05\n",
            "step: 5700, loss: 2.0248990040272474e-05\n",
            "step: 5701, loss: 0.0008875656640157104\n",
            "step: 5702, loss: 5.439452070277184e-05\n",
            "step: 5703, loss: 2.575157668616157e-05\n",
            "step: 5704, loss: 1.4093664503889158e-05\n",
            "step: 5705, loss: 3.7259753298712894e-05\n",
            "step: 5706, loss: 3.647906123660505e-05\n",
            "step: 5707, loss: 2.3186375983641483e-05\n",
            "step: 5708, loss: 0.00019165835692547262\n",
            "step: 5709, loss: 1.1889075722137932e-05\n",
            "step: 5710, loss: 1.573905501572881e-05\n",
            "step: 5711, loss: 4.074215758009814e-05\n",
            "step: 5712, loss: 0.029878757894039154\n",
            "step: 5713, loss: 7.948456186568365e-06\n",
            "step: 5714, loss: 3.853668749798089e-05\n",
            "step: 5715, loss: 2.3051636162563227e-05\n",
            "step: 5716, loss: 9.021523510455154e-06\n",
            "step: 5717, loss: 5.527761823032051e-05\n",
            "step: 5718, loss: 7.982050738064572e-05\n",
            "step: 5719, loss: 0.00013901917554903775\n",
            "step: 5720, loss: 7.367716170847416e-05\n",
            "step: 5721, loss: 0.022900283336639404\n",
            "step: 5722, loss: 6.641740765189752e-05\n",
            "step: 5723, loss: 8.470801549265161e-05\n",
            "step: 5724, loss: 2.2707938114763238e-05\n",
            "step: 5725, loss: 0.021975098177790642\n",
            "step: 5726, loss: 0.025698460638523102\n",
            "step: 5727, loss: 2.981932630063966e-05\n",
            "step: 5728, loss: 5.331698775989935e-05\n",
            "step: 5729, loss: 6.250576552702114e-05\n",
            "step: 5730, loss: 0.05114597827196121\n",
            "step: 5731, loss: 1.48906674439786e-05\n",
            "step: 5732, loss: 3.5707958886632696e-05\n",
            "step: 5733, loss: 0.032392121851444244\n",
            "step: 5734, loss: 2.6626867111190222e-05\n",
            "step: 5735, loss: 1.5620244084857404e-05\n",
            "step: 5736, loss: 2.8112604923080653e-05\n",
            "step: 5737, loss: 1.1428977813920937e-05\n",
            "step: 5738, loss: 2.1671651211363496e-06\n",
            "step: 5739, loss: 2.2170841475599445e-05\n",
            "step: 5740, loss: 1.4376503258972662e-06\n",
            "step: 5741, loss: 1.455869096389506e-05\n",
            "step: 5742, loss: 1.0578096407698467e-05\n",
            "step: 5743, loss: 0.00013443047646433115\n",
            "step: 5744, loss: 1.4401767657545861e-05\n",
            "step: 5745, loss: 0.028797101229429245\n",
            "step: 5746, loss: 0.00015335259377025068\n",
            "step: 5747, loss: 2.4287346604978666e-05\n",
            "step: 5748, loss: 1.8882299173128558e-06\n",
            "step: 5749, loss: 1.0442251550557557e-05\n",
            "step: 5750, loss: 4.494062068260973e-06\n",
            "step: 5751, loss: 3.2352772905142047e-06\n",
            "step: 5752, loss: 4.636859557649586e-06\n",
            "step: 5753, loss: 3.7645199881808367e-06\n",
            "step: 5754, loss: 3.130394588879426e-06\n",
            "step: 5755, loss: 2.9873522180423606e-06\n",
            "step: 5756, loss: 4.7319135774159804e-05\n",
            "step: 5757, loss: 3.3759656616894063e-06\n",
            "step: 5758, loss: 2.3051938114804216e-05\n",
            "step: 5759, loss: 8.775207788858097e-06\n",
            "step: 5760, loss: 2.235338070022408e-05\n",
            "step: 5761, loss: 3.6667800031864317e-06\n",
            "step: 5762, loss: 1.1960677511524409e-05\n",
            "step: 5763, loss: 1.2112824151699897e-05\n",
            "step: 5764, loss: 2.0659406800405122e-05\n",
            "step: 5765, loss: 2.326767389604356e-05\n",
            "step: 5766, loss: 4.760957835969748e-06\n",
            "step: 5767, loss: 2.6024663384305313e-05\n",
            "step: 5768, loss: 0.00011581866419874132\n",
            "step: 5769, loss: 8.472870831610635e-05\n",
            "step: 5770, loss: 2.346018391108373e-06\n",
            "step: 5771, loss: 1.5950057559166453e-06\n",
            "step: 5772, loss: 5.1520032684493344e-06\n",
            "step: 5773, loss: 4.744278157886583e-06\n",
            "step: 5774, loss: 5.487797352543566e-06\n",
            "step: 5775, loss: 3.886108970618807e-06\n",
            "step: 5776, loss: 9.870470876194304e-07\n",
            "step: 5777, loss: 2.0289162421249785e-06\n",
            "step: 5778, loss: 1.5020291357359383e-06\n",
            "step: 5779, loss: 8.062832785071805e-05\n",
            "step: 5780, loss: 3.7095555853738915e-06\n",
            "step: 5781, loss: 4.913336397294188e-06\n",
            "step: 5782, loss: 4.770647592522437e-06\n",
            "step: 5783, loss: 2.732205075517413e-06\n",
            "step: 5784, loss: 1.792896455299342e-06\n",
            "step: 5785, loss: 1.6712938304408453e-06\n",
            "step: 5786, loss: 0.0001605588913662359\n",
            "step: 5787, loss: 7.700527930865064e-06\n",
            "step: 5788, loss: 2.05753667614772e-06\n",
            "step: 5789, loss: 4.429728505783714e-06\n",
            "step: 5790, loss: 1.0155956260859966e-05\n",
            "step: 5791, loss: 2.0819796191062778e-05\n",
            "step: 5792, loss: 0.04186371713876724\n",
            "step: 5793, loss: 0.0007193413912318647\n",
            "step: 5794, loss: 3.019021824002266e-05\n",
            "step: 5795, loss: 4.0593604353489354e-05\n",
            "step: 5796, loss: 0.00022756066755391657\n",
            "step: 5797, loss: 2.1951964299660176e-05\n",
            "step: 5798, loss: 0.008007831871509552\n",
            "step: 5799, loss: 0.02611636370420456\n",
            "step: 5800, loss: 1.7803868104238063e-05\n",
            "step: 5801, loss: 1.0232342901872471e-05\n",
            "step: 5802, loss: 4.4141932448837906e-05\n",
            "step: 5803, loss: 3.178341285092756e-05\n",
            "step: 5804, loss: 0.00026167716714553535\n",
            "step: 5805, loss: 1.842441088228952e-05\n",
            "step: 5806, loss: 0.00021120964083820581\n",
            "step: 5807, loss: 2.1531854144996032e-05\n",
            "step: 5808, loss: 3.965175346820615e-05\n",
            "step: 5809, loss: 3.3246400562347844e-05\n",
            "step: 5810, loss: 0.0001369387173326686\n",
            "step: 5811, loss: 1.1872936738654971e-05\n",
            "step: 5812, loss: 2.885421235987451e-05\n",
            "step: 5813, loss: 1.7878797734738328e-05\n",
            "step: 5814, loss: 6.167780156829394e-06\n",
            "step: 5815, loss: 1.6450780094601214e-05\n",
            "step: 5816, loss: 6.472308996308129e-06\n",
            "step: 5817, loss: 0.00022202887339517474\n",
            "step: 5818, loss: 1.014359531836817e-05\n",
            "step: 5819, loss: 5.252129540167516e-06\n",
            "step: 5820, loss: 1.0633393685566261e-06\n",
            "step: 5821, loss: 2.016994130826788e-06\n",
            "step: 5822, loss: 6.72295118420152e-06\n",
            "step: 5823, loss: 3.027908519470657e-07\n",
            "step: 5824, loss: 3.7955167044856353e-06\n",
            "step: 5825, loss: 0.0001391938712913543\n",
            "step: 5826, loss: 4.773681575898081e-05\n",
            "step: 5827, loss: 5.891126420465298e-05\n",
            "step: 5828, loss: 6.853199010947719e-05\n",
            "step: 5829, loss: 3.32095441990532e-05\n",
            "step: 5830, loss: 1.3133124411979225e-05\n",
            "step: 5831, loss: 8.046286893659271e-06\n",
            "step: 5832, loss: 1.829424400057178e-05\n",
            "step: 5833, loss: 2.292669887538068e-05\n",
            "step: 5834, loss: 5.819250873173587e-05\n",
            "step: 5835, loss: 6.698679499095306e-05\n",
            "step: 5836, loss: 0.00010183527774643153\n",
            "step: 5837, loss: 3.880132135236636e-05\n",
            "step: 5838, loss: 4.853664358961396e-05\n",
            "step: 5839, loss: 4.7323814214905724e-05\n",
            "step: 5840, loss: 1.3306159416970331e-05\n",
            "step: 5841, loss: 2.773227242869325e-05\n",
            "step: 5842, loss: 7.5647785706678405e-06\n",
            "step: 5843, loss: 1.990780219784938e-06\n",
            "step: 5844, loss: 0.00021124392515048385\n",
            "step: 5845, loss: 2.355605647608172e-05\n",
            "step: 5846, loss: 1.2153966963523999e-05\n",
            "step: 5847, loss: 8.441982572549023e-06\n",
            "step: 5848, loss: 1.6299009075737558e-05\n",
            "step: 5849, loss: 1.1743981303879991e-05\n",
            "step: 5850, loss: 1.4220996490621474e-05\n",
            "step: 5851, loss: 1.1046578038076404e-05\n",
            "step: 5852, loss: 4.182313568890095e-05\n",
            "step: 5853, loss: 7.135515261325054e-06\n",
            "step: 5854, loss: 1.0477658179297578e-05\n",
            "step: 5855, loss: 9.98971586341213e-07\n",
            "step: 5856, loss: 5.631252406601561e-06\n",
            "step: 5857, loss: 5.960321232123533e-06\n",
            "step: 5858, loss: 6.961639883229509e-06\n",
            "step: 5859, loss: 3.0398132366826758e-06\n",
            "step: 5860, loss: 8.789576895651408e-06\n",
            "step: 5861, loss: 5.379198046284728e-05\n",
            "step: 5862, loss: 3.7992744182702154e-05\n",
            "step: 5863, loss: 1.1870274647662882e-05\n",
            "step: 5864, loss: 4.773005457536783e-06\n",
            "step: 5865, loss: 2.217264864157187e-06\n",
            "step: 5866, loss: 7.006528448982863e-06\n",
            "step: 5867, loss: 1.3605294952867553e-05\n",
            "step: 5868, loss: 8.940584734773438e-07\n",
            "step: 5869, loss: 2.9372777134994976e-06\n",
            "step: 5870, loss: 3.6554458347382024e-05\n",
            "step: 5871, loss: 0.00016154255717992783\n",
            "step: 5872, loss: 5.767972834291868e-05\n",
            "step: 5873, loss: 1.1187787094968371e-05\n",
            "step: 5874, loss: 6.283963739406317e-05\n",
            "step: 5875, loss: 3.809383269981481e-05\n",
            "step: 5876, loss: 1.015832822304219e-05\n",
            "step: 5877, loss: 4.281858855392784e-05\n",
            "step: 5878, loss: 2.0247758584446274e-05\n",
            "step: 5879, loss: 1.3295312783156987e-05\n",
            "step: 5880, loss: 1.678567787166685e-05\n",
            "step: 5881, loss: 3.201010258635506e-05\n",
            "step: 5882, loss: 1.4413500139198732e-05\n",
            "step: 5883, loss: 2.2037644157535397e-05\n",
            "step: 5884, loss: 3.278733493061736e-05\n",
            "step: 5885, loss: 1.82855856110109e-05\n",
            "step: 5886, loss: 0.01480457466095686\n",
            "step: 5887, loss: 0.00023149354092311114\n",
            "step: 5888, loss: 0.00022744160378351808\n",
            "step: 5889, loss: 0.024575911462306976\n",
            "step: 5890, loss: 8.441228419542313e-05\n",
            "step: 5891, loss: 4.713468297268264e-05\n",
            "step: 5892, loss: 0.00012843238073401153\n",
            "step: 5893, loss: 5.032111585023813e-05\n",
            "step: 5894, loss: 0.050333742052316666\n",
            "step: 5895, loss: 0.035535071045160294\n",
            "step: 5896, loss: 7.791131793055683e-05\n",
            "step: 5897, loss: 5.6176126236096025e-05\n",
            "step: 5898, loss: 0.035860154777765274\n",
            "step: 5899, loss: 0.00018127821385860443\n",
            "step: 5900, loss: 0.00010257936810376123\n",
            "step: 5901, loss: 0.00010135080810869113\n",
            "step: 5902, loss: 0.00012430676724761724\n",
            "step: 5903, loss: 0.027782199904322624\n",
            "step: 5904, loss: 0.00018465366156306118\n",
            "step: 5905, loss: 0.03300315886735916\n",
            "step: 5906, loss: 7.330783409997821e-05\n",
            "step: 5907, loss: 3.121956251561642e-05\n",
            "step: 5908, loss: 3.205324901500717e-05\n",
            "step: 5909, loss: 6.0972055507590994e-05\n",
            "step: 5910, loss: 0.00012393228826113045\n",
            "step: 5911, loss: 0.055785875767469406\n",
            "step: 5912, loss: 0.00019030843395739794\n",
            "step: 5913, loss: 0.00031730529735796154\n",
            "step: 5914, loss: 8.723842620383948e-05\n",
            "step: 5915, loss: 0.00015705684199929237\n",
            "step: 5916, loss: 0.00011630648077698424\n",
            "step: 5917, loss: 0.0005882069235667586\n",
            "step: 5918, loss: 0.00013191955804359168\n",
            "step: 5919, loss: 0.035040147602558136\n",
            "step: 5920, loss: 0.02546185441315174\n",
            "step: 5921, loss: 4.950040965923108e-05\n",
            "step: 5922, loss: 3.5167409805580974e-05\n",
            "step: 5923, loss: 2.9000364520470612e-05\n",
            "step: 5924, loss: 4.413272108649835e-05\n",
            "step: 5925, loss: 4.3828607886098325e-05\n",
            "step: 5926, loss: 1.904281998577062e-05\n",
            "step: 5927, loss: 0.0007594619528390467\n",
            "step: 5928, loss: 4.6167242544470355e-05\n",
            "step: 5929, loss: 2.3241265807882883e-05\n",
            "step: 5930, loss: 1.2675584002863616e-05\n",
            "step: 5931, loss: 3.2391610147897154e-05\n",
            "step: 5932, loss: 3.400345303816721e-05\n",
            "step: 5933, loss: 2.6341229386162013e-05\n",
            "step: 5934, loss: 0.00018042736337520182\n",
            "step: 5935, loss: 9.788926945475396e-06\n",
            "step: 5936, loss: 1.5186095879471395e-05\n",
            "step: 5937, loss: 3.473785181995481e-05\n",
            "step: 5938, loss: 0.03095947951078415\n",
            "step: 5939, loss: 8.389552021981217e-06\n",
            "step: 5940, loss: 3.8266178307821974e-05\n",
            "step: 5941, loss: 2.0339439288363792e-05\n",
            "step: 5942, loss: 1.0599728739180136e-05\n",
            "step: 5943, loss: 5.007967774872668e-05\n",
            "step: 5944, loss: 6.399529956979677e-05\n",
            "step: 5945, loss: 0.0001241043210029602\n",
            "step: 5946, loss: 7.161258690757677e-05\n",
            "step: 5947, loss: 0.02286522090435028\n",
            "step: 5948, loss: 7.01634053257294e-05\n",
            "step: 5949, loss: 8.167415944626555e-05\n",
            "step: 5950, loss: 2.0693558326456696e-05\n",
            "step: 5951, loss: 0.022363312542438507\n",
            "step: 5952, loss: 0.027016451582312584\n",
            "step: 5953, loss: 2.7535616027307697e-05\n",
            "step: 5954, loss: 4.6719625970581546e-05\n",
            "step: 5955, loss: 5.7255365391029045e-05\n",
            "step: 5956, loss: 0.05259732902050018\n",
            "step: 5957, loss: 1.0790357009682339e-05\n",
            "step: 5958, loss: 2.823671093210578e-05\n",
            "step: 5959, loss: 0.06790237873792648\n",
            "step: 5960, loss: 2.3862081434344873e-05\n",
            "step: 5961, loss: 1.5193298168014735e-05\n",
            "step: 5962, loss: 2.395794763287995e-05\n",
            "step: 5963, loss: 1.0649474461388309e-05\n",
            "step: 5964, loss: 2.219615453213919e-06\n",
            "step: 5965, loss: 2.10963607969461e-05\n",
            "step: 5966, loss: 1.3017511264479253e-06\n",
            "step: 5967, loss: 1.966415402421262e-05\n",
            "step: 5968, loss: 9.772335943125654e-06\n",
            "step: 5969, loss: 3.972444392275065e-05\n",
            "step: 5970, loss: 1.2508606232586317e-05\n",
            "step: 5971, loss: 0.02298366092145443\n",
            "step: 5972, loss: 0.0001188527894555591\n",
            "step: 5973, loss: 1.4941358131181914e-05\n",
            "step: 5974, loss: 1.5878458725637756e-06\n",
            "step: 5975, loss: 2.8085382837161887e-06\n",
            "step: 5976, loss: 6.0746679082512856e-06\n",
            "step: 5977, loss: 3.86704277843819e-06\n",
            "step: 5978, loss: 2.658226094354177e-06\n",
            "step: 5979, loss: 3.3187197914230637e-06\n",
            "step: 5980, loss: 3.8766174839111045e-06\n",
            "step: 5981, loss: 3.004038035214762e-06\n",
            "step: 5982, loss: 3.7981986679369584e-05\n",
            "step: 5983, loss: 3.1423214750248007e-06\n",
            "step: 5984, loss: 2.1023923181928694e-05\n",
            "step: 5985, loss: 7.693043698964175e-06\n",
            "step: 5986, loss: 1.957437962119002e-05\n",
            "step: 5987, loss: 3.2424222808913328e-06\n",
            "step: 5988, loss: 1.0463609214639291e-05\n",
            "step: 5989, loss: 8.785260433796793e-06\n",
            "step: 5990, loss: 1.6144545952556655e-05\n",
            "step: 5991, loss: 2.0724153728224337e-05\n",
            "step: 5992, loss: 4.281794190319488e-06\n",
            "step: 5993, loss: 2.204065640398767e-05\n",
            "step: 5994, loss: 9.383961878484115e-05\n",
            "step: 5995, loss: 7.174586062319577e-05\n",
            "step: 5996, loss: 1.9407132185733644e-06\n",
            "step: 5997, loss: 1.3136768757249229e-06\n",
            "step: 5998, loss: 4.105418156541418e-06\n",
            "step: 5999, loss: 3.8073837913543684e-06\n",
            "step: 6000, loss: 4.634428933059098e-06\n",
            "step: 6001, loss: 3.0874487038090592e-06\n",
            "step: 6002, loss: 8.630704542156309e-07\n",
            "step: 6003, loss: 1.7952709185919957e-06\n",
            "step: 6004, loss: 1.292222918891639e-06\n",
            "step: 6005, loss: 1.173677810584195e-05\n",
            "step: 6006, loss: 3.320986934340908e-06\n",
            "step: 6007, loss: 4.7297862693085335e-06\n",
            "step: 6008, loss: 4.30336649515084e-06\n",
            "step: 6009, loss: 2.6535310553299496e-06\n",
            "step: 6010, loss: 1.7332924926449778e-06\n",
            "step: 6011, loss: 1.595002572685189e-06\n",
            "step: 6012, loss: 0.00012035387771902606\n",
            "step: 6013, loss: 7.187979008449474e-06\n",
            "step: 6014, loss: 2.0098534605494933e-06\n",
            "step: 6015, loss: 4.119789082324132e-06\n",
            "step: 6016, loss: 1.4501780242426321e-05\n",
            "step: 6017, loss: 2.3964448701008223e-05\n",
            "step: 6018, loss: 0.04489703103899956\n",
            "step: 6019, loss: 0.010188955813646317\n",
            "step: 6020, loss: 3.4013552067335695e-05\n",
            "step: 6021, loss: 3.53025461663492e-05\n",
            "step: 6022, loss: 0.0002583101741038263\n",
            "step: 6023, loss: 2.0156883692834526e-05\n",
            "step: 6024, loss: 0.006229174789041281\n",
            "step: 6025, loss: 0.025623446330428123\n",
            "step: 6026, loss: 1.7603444575797766e-05\n",
            "step: 6027, loss: 1.3146765923011117e-05\n",
            "step: 6028, loss: 3.924392149201594e-05\n",
            "step: 6029, loss: 3.301125980215147e-05\n",
            "step: 6030, loss: 0.00025028386153280735\n",
            "step: 6031, loss: 1.753100696078036e-05\n",
            "step: 6032, loss: 0.00017986631428357214\n",
            "step: 6033, loss: 2.1763178665423766e-05\n",
            "step: 6034, loss: 3.080101669183932e-05\n",
            "step: 6035, loss: 2.990946450154297e-05\n",
            "step: 6036, loss: 0.0001267213374376297\n",
            "step: 6037, loss: 1.0533090971875936e-05\n",
            "step: 6038, loss: 2.69284428213723e-05\n",
            "step: 6039, loss: 1.69444228959037e-05\n",
            "step: 6040, loss: 6.544448751810705e-06\n",
            "step: 6041, loss: 1.4033820662007201e-05\n",
            "step: 6042, loss: 5.356728706829017e-06\n",
            "step: 6043, loss: 0.000182676303666085\n",
            "step: 6044, loss: 9.271130693377927e-06\n",
            "step: 6045, loss: 4.7014209485496394e-06\n",
            "step: 6046, loss: 9.15521695787902e-07\n",
            "step: 6047, loss: 1.9049356296818587e-06\n",
            "step: 6048, loss: 5.409431651060004e-06\n",
            "step: 6049, loss: 2.6225990268358146e-07\n",
            "step: 6050, loss: 3.0683772820339072e-06\n",
            "step: 6051, loss: 0.00012226885883137584\n",
            "step: 6052, loss: 4.137764699407853e-05\n",
            "step: 6053, loss: 5.41423651156947e-05\n",
            "step: 6054, loss: 5.761070133303292e-05\n",
            "step: 6055, loss: 2.9164526495151222e-05\n",
            "step: 6056, loss: 1.2449002497305628e-05\n",
            "step: 6057, loss: 6.146240139059955e-06\n",
            "step: 6058, loss: 1.5700845324317925e-05\n",
            "step: 6059, loss: 2.096481875923928e-05\n",
            "step: 6060, loss: 5.136054824106395e-05\n",
            "step: 6061, loss: 6.407548062270507e-05\n",
            "step: 6062, loss: 9.169519762508571e-05\n",
            "step: 6063, loss: 3.376720997039229e-05\n",
            "step: 6064, loss: 0.0001108627111534588\n",
            "step: 6065, loss: 4.719154821941629e-05\n",
            "step: 6066, loss: 1.5703299141023308e-05\n",
            "step: 6067, loss: 2.5894312784657814e-05\n",
            "step: 6068, loss: 7.822272891644388e-06\n",
            "step: 6069, loss: 2.257806045236066e-06\n",
            "step: 6070, loss: 0.00034699321258813143\n",
            "step: 6071, loss: 1.896850881166756e-05\n",
            "step: 6072, loss: 1.0175307579629589e-05\n",
            "step: 6073, loss: 8.66379286890151e-06\n",
            "step: 6074, loss: 1.5700701624155045e-05\n",
            "step: 6075, loss: 1.2673956007347442e-05\n",
            "step: 6076, loss: 2.3177173716248944e-05\n",
            "step: 6077, loss: 1.0435070180392358e-05\n",
            "step: 6078, loss: 4.6739591198274866e-05\n",
            "step: 6079, loss: 8.062892447924241e-06\n",
            "step: 6080, loss: 1.018932289298391e-05\n",
            "step: 6081, loss: 2.0289321582822595e-06\n",
            "step: 6082, loss: 5.750521268055309e-06\n",
            "step: 6083, loss: 6.463400950451614e-06\n",
            "step: 6084, loss: 8.365871508431155e-06\n",
            "step: 6085, loss: 5.66951075597899e-06\n",
            "step: 6086, loss: 8.45364138513105e-06\n",
            "step: 6087, loss: 5.063221396994777e-05\n",
            "step: 6088, loss: 3.5242137528257445e-05\n",
            "step: 6089, loss: 9.493458492215723e-06\n",
            "step: 6090, loss: 3.98149086322519e-06\n",
            "step: 6091, loss: 1.909710363179329e-06\n",
            "step: 6092, loss: 6.0505922192533035e-06\n",
            "step: 6093, loss: 1.05303024611203e-05\n",
            "step: 6094, loss: 7.438586067110009e-07\n",
            "step: 6095, loss: 2.3293264348467346e-06\n",
            "step: 6096, loss: 3.151401688228361e-05\n",
            "step: 6097, loss: 0.0001418641913915053\n",
            "step: 6098, loss: 5.4398245993070304e-05\n",
            "step: 6099, loss: 9.71482222666964e-06\n",
            "step: 6100, loss: 5.6484535889467224e-05\n",
            "step: 6101, loss: 3.3774016628740355e-05\n",
            "step: 6102, loss: 9.174984370474704e-06\n",
            "step: 6103, loss: 3.8033223972888663e-05\n",
            "step: 6104, loss: 1.649649493629113e-05\n",
            "step: 6105, loss: 1.1314493349345867e-05\n",
            "step: 6106, loss: 1.5300573068088852e-05\n",
            "step: 6107, loss: 2.956959724542685e-05\n",
            "step: 6108, loss: 1.3622048754768912e-05\n",
            "step: 6109, loss: 1.967577190953307e-05\n",
            "step: 6110, loss: 3.006380757142324e-05\n",
            "step: 6111, loss: 1.7301015759585425e-05\n",
            "step: 6112, loss: 0.016396082937717438\n",
            "step: 6113, loss: 0.00023054616758599877\n",
            "step: 6114, loss: 0.0002281150664202869\n",
            "step: 6115, loss: 0.029725156724452972\n",
            "step: 6116, loss: 9.068015788216144e-05\n",
            "step: 6117, loss: 4.3861218728125095e-05\n",
            "step: 6118, loss: 0.0001223547587869689\n",
            "step: 6119, loss: 5.126103860675357e-05\n",
            "step: 6120, loss: 0.0516543909907341\n",
            "step: 6121, loss: 0.03820501267910004\n",
            "step: 6122, loss: 9.52703194343485e-05\n",
            "step: 6123, loss: 5.6307781051145867e-05\n",
            "step: 6124, loss: 0.037115007638931274\n",
            "step: 6125, loss: 0.00016302695439662784\n",
            "step: 6126, loss: 9.175781451631337e-05\n",
            "step: 6127, loss: 8.400926162721589e-05\n",
            "step: 6128, loss: 0.00011965122394030914\n",
            "step: 6129, loss: 0.028643179684877396\n",
            "step: 6130, loss: 0.00016823533223941922\n",
            "step: 6131, loss: 0.036195989698171616\n",
            "step: 6132, loss: 6.109106470830739e-05\n",
            "step: 6133, loss: 3.0189519748091698e-05\n",
            "step: 6134, loss: 2.8550206479849294e-05\n",
            "step: 6135, loss: 5.4398969950852916e-05\n",
            "step: 6136, loss: 0.00012852247164119035\n",
            "step: 6137, loss: 0.07058755308389664\n",
            "step: 6138, loss: 0.0001699492277111858\n",
            "step: 6139, loss: 0.00039107169141061604\n",
            "step: 6140, loss: 9.05739507288672e-05\n",
            "step: 6141, loss: 0.00015491597878281027\n",
            "step: 6142, loss: 0.000128635874716565\n",
            "step: 6143, loss: 0.0005401525413617492\n",
            "step: 6144, loss: 0.00015024366439320147\n",
            "step: 6145, loss: 0.023754330351948738\n",
            "step: 6146, loss: 0.027142301201820374\n",
            "step: 6147, loss: 5.5056432756828144e-05\n",
            "step: 6148, loss: 3.380568523425609e-05\n",
            "step: 6149, loss: 3.14869248541072e-05\n",
            "step: 6150, loss: 4.037399776279926e-05\n",
            "step: 6151, loss: 3.7868354411330074e-05\n",
            "step: 6152, loss: 1.633727879379876e-05\n",
            "step: 6153, loss: 0.0006268152501434088\n",
            "step: 6154, loss: 3.975086292484775e-05\n",
            "step: 6155, loss: 1.8726579583017156e-05\n",
            "step: 6156, loss: 9.86266604741104e-06\n",
            "step: 6157, loss: 2.6016379706561565e-05\n",
            "step: 6158, loss: 2.780176691885572e-05\n",
            "step: 6159, loss: 2.1477220798260532e-05\n",
            "step: 6160, loss: 0.00021339807426556945\n",
            "step: 6161, loss: 8.18454736872809e-06\n",
            "step: 6162, loss: 1.3772460988548119e-05\n",
            "step: 6163, loss: 2.8895716241095215e-05\n",
            "step: 6164, loss: 0.03165505453944206\n",
            "step: 6165, loss: 7.04020976627362e-06\n",
            "step: 6166, loss: 3.3390453609172255e-05\n",
            "step: 6167, loss: 1.731940392346587e-05\n",
            "step: 6168, loss: 8.229995728470385e-06\n",
            "step: 6169, loss: 4.334249024395831e-05\n",
            "step: 6170, loss: 3.7775560485897586e-05\n",
            "step: 6171, loss: 0.00010817578731803223\n",
            "step: 6172, loss: 6.572507118107751e-05\n",
            "step: 6173, loss: 0.020503120496869087\n",
            "step: 6174, loss: 7.228828326333314e-05\n",
            "step: 6175, loss: 7.350813393713906e-05\n",
            "step: 6176, loss: 1.857661482063122e-05\n",
            "step: 6177, loss: 0.021594632416963577\n",
            "step: 6178, loss: 0.027291201055049896\n",
            "step: 6179, loss: 2.4484190362272784e-05\n",
            "step: 6180, loss: 3.882500095642172e-05\n",
            "step: 6181, loss: 4.991272362531163e-05\n",
            "step: 6182, loss: 0.05437992885708809\n",
            "step: 6183, loss: 1.2425798558979295e-05\n",
            "step: 6184, loss: 4.151802204432897e-05\n",
            "step: 6185, loss: 0.026355711743235588\n",
            "step: 6186, loss: 2.711939305299893e-05\n",
            "step: 6187, loss: 1.3732143997913226e-05\n",
            "step: 6188, loss: 2.5510762498015538e-05\n",
            "step: 6189, loss: 1.070424696081318e-05\n",
            "step: 6190, loss: 2.4556234166084323e-06\n",
            "step: 6191, loss: 1.3271665920910891e-05\n",
            "step: 6192, loss: 1.3661202729053912e-06\n",
            "step: 6193, loss: 2.08595647563925e-05\n",
            "step: 6194, loss: 8.4825996964355e-06\n",
            "step: 6195, loss: 2.872930417652242e-05\n",
            "step: 6196, loss: 1.0332242709409911e-05\n",
            "step: 6197, loss: 0.02099783346056938\n",
            "step: 6198, loss: 0.0001004161240416579\n",
            "step: 6199, loss: 9.485681403020862e-06\n",
            "step: 6200, loss: 1.2564502185341553e-06\n",
            "step: 6201, loss: 3.3282763070019428e-06\n",
            "step: 6202, loss: 4.315244950703345e-06\n",
            "step: 6203, loss: 2.60348133451771e-06\n",
            "step: 6204, loss: 1.8810642359312624e-06\n",
            "step: 6205, loss: 2.68931489699753e-06\n",
            "step: 6206, loss: 2.9801969958498375e-06\n",
            "step: 6207, loss: 2.7441687961982097e-06\n",
            "step: 6208, loss: 3.5821180063067004e-05\n",
            "step: 6209, loss: 3.1017914352560183e-06\n",
            "step: 6210, loss: 2.602625681902282e-05\n",
            "step: 6211, loss: 6.5678991632012185e-06\n",
            "step: 6212, loss: 1.7755633962224238e-05\n",
            "step: 6213, loss: 2.803750703606056e-06\n",
            "step: 6214, loss: 1.2396618330967613e-05\n",
            "step: 6215, loss: 9.264314030588139e-06\n",
            "step: 6216, loss: 1.576547947479412e-05\n",
            "step: 6217, loss: 1.906254510686267e-05\n",
            "step: 6218, loss: 3.9504234337073285e-06\n",
            "step: 6219, loss: 1.9202505427529104e-05\n",
            "step: 6220, loss: 7.636685040779412e-05\n",
            "step: 6221, loss: 5.970907295704819e-05\n",
            "step: 6222, loss: 1.7380596091243206e-06\n",
            "step: 6223, loss: 1.1062556950491853e-06\n",
            "step: 6224, loss: 3.1446688808500767e-06\n",
            "step: 6225, loss: 3.5308432870806428e-06\n",
            "step: 6226, loss: 4.0504000935470685e-06\n",
            "step: 6227, loss: 2.4413618575636065e-06\n",
            "step: 6228, loss: 7.3909438924602e-07\n",
            "step: 6229, loss: 1.5973872677932377e-06\n",
            "step: 6230, loss: 1.2540756415546639e-06\n",
            "step: 6231, loss: 1.0821344403666444e-05\n",
            "step: 6232, loss: 3.2041873510024743e-06\n",
            "step: 6233, loss: 4.2077649595739786e-06\n",
            "step: 6234, loss: 4.272377282177331e-06\n",
            "step: 6235, loss: 2.7941903226746945e-06\n",
            "step: 6236, loss: 1.966939635167364e-06\n",
            "step: 6237, loss: 1.671295194682898e-06\n",
            "step: 6238, loss: 0.0001397435407852754\n",
            "step: 6239, loss: 7.040178843453759e-06\n",
            "step: 6240, loss: 2.2291947061603423e-06\n",
            "step: 6241, loss: 4.169849489699118e-06\n",
            "step: 6242, loss: 6.301273970166221e-06\n",
            "step: 6243, loss: 1.4120875675871503e-05\n",
            "step: 6244, loss: 0.0715567097067833\n",
            "step: 6245, loss: 0.016027307137846947\n",
            "step: 6246, loss: 2.207582292612642e-05\n",
            "step: 6247, loss: 2.30149944400182e-05\n",
            "step: 6248, loss: 0.00014672709221486002\n",
            "step: 6249, loss: 1.3198285159887746e-05\n",
            "step: 6250, loss: 0.006392385344952345\n",
            "step: 6251, loss: 0.024499092251062393\n",
            "step: 6252, loss: 1.1970430932706222e-05\n",
            "step: 6253, loss: 6.134338946139906e-06\n",
            "step: 6254, loss: 4.3722480768337846e-05\n",
            "step: 6255, loss: 3.5444496461423114e-05\n",
            "step: 6256, loss: 0.0003002374724019319\n",
            "step: 6257, loss: 5.183243774808943e-05\n",
            "step: 6258, loss: 0.0001722737797535956\n",
            "step: 6259, loss: 2.175840927520767e-05\n",
            "step: 6260, loss: 3.135895894956775e-05\n",
            "step: 6261, loss: 2.6779083782457747e-05\n",
            "step: 6262, loss: 0.00013227417366579175\n",
            "step: 6263, loss: 1.142715245805448e-05\n",
            "step: 6264, loss: 2.5741423087310977e-05\n",
            "step: 6265, loss: 2.014598430832848e-05\n",
            "step: 6266, loss: 5.8339965107734315e-06\n",
            "step: 6267, loss: 1.2045914445479866e-05\n",
            "step: 6268, loss: 4.3889258449780755e-06\n",
            "step: 6269, loss: 0.00015092967078089714\n",
            "step: 6270, loss: 8.484495083393995e-06\n",
            "step: 6271, loss: 4.2603792280715425e-06\n",
            "step: 6272, loss: 7.915454602880345e-07\n",
            "step: 6273, loss: 1.525861193840683e-06\n",
            "step: 6274, loss: 4.305673428461887e-06\n",
            "step: 6275, loss: 1.9073459611718135e-07\n",
            "step: 6276, loss: 2.591557858977467e-06\n",
            "step: 6277, loss: 0.00010449007095303386\n",
            "step: 6278, loss: 3.712911711772904e-05\n",
            "step: 6279, loss: 5.266012158244848e-05\n",
            "step: 6280, loss: 6.482018943643197e-05\n",
            "step: 6281, loss: 2.7233703804085962e-05\n",
            "step: 6282, loss: 1.2358487765595783e-05\n",
            "step: 6283, loss: 7.190392352640629e-06\n",
            "step: 6284, loss: 1.1953724424529355e-05\n",
            "step: 6285, loss: 1.9126948245684616e-05\n",
            "step: 6286, loss: 4.537216227618046e-05\n",
            "step: 6287, loss: 5.968088225927204e-05\n",
            "step: 6288, loss: 8.660570892971009e-05\n",
            "step: 6289, loss: 3.182727232342586e-05\n",
            "step: 6290, loss: 0.0002704068610910326\n",
            "step: 6291, loss: 0.00012404010340105742\n",
            "step: 6292, loss: 2.5234545319108292e-05\n",
            "step: 6293, loss: 2.511282218620181e-05\n",
            "step: 6294, loss: 8.971381248557009e-06\n",
            "step: 6295, loss: 3.075563654419966e-06\n",
            "step: 6296, loss: 0.0007778389845043421\n",
            "step: 6297, loss: 2.1550804376602173e-05\n",
            "step: 6298, loss: 1.3372198736760765e-05\n",
            "step: 6299, loss: 1.0354055120842531e-05\n",
            "step: 6300, loss: 1.651344427955337e-05\n",
            "step: 6301, loss: 1.2554747627291363e-05\n",
            "step: 6302, loss: 2.1291636585374363e-05\n",
            "step: 6303, loss: 1.0520885552978143e-05\n",
            "step: 6304, loss: 3.9949940401129425e-05\n",
            "step: 6305, loss: 8.5945339378668e-06\n",
            "step: 6306, loss: 9.50042885961011e-06\n",
            "step: 6307, loss: 1.9884007542714244e-06\n",
            "step: 6308, loss: 6.119998943177052e-06\n",
            "step: 6309, loss: 6.0867123465868644e-06\n",
            "step: 6310, loss: 8.015402272576466e-06\n",
            "step: 6311, loss: 5.526462700800039e-06\n",
            "step: 6312, loss: 8.301108209707309e-06\n",
            "step: 6313, loss: 5.1635179261211306e-05\n",
            "step: 6314, loss: 3.2056079362519085e-05\n",
            "step: 6315, loss: 7.81988819653634e-06\n",
            "step: 6316, loss: 3.5285163448861567e-06\n",
            "step: 6317, loss: 1.695138166724064e-06\n",
            "step: 6318, loss: 5.65491609449964e-06\n",
            "step: 6319, loss: 9.083288205147255e-06\n",
            "step: 6320, loss: 7.533950565630221e-07\n",
            "step: 6321, loss: 2.639255171743571e-06\n",
            "step: 6322, loss: 3.506104621919803e-05\n",
            "step: 6323, loss: 0.0001523229293525219\n",
            "step: 6324, loss: 6.6913096816279e-05\n",
            "step: 6325, loss: 1.0096322512254119e-05\n",
            "step: 6326, loss: 5.3718031267635524e-05\n",
            "step: 6327, loss: 4.6348985051736236e-05\n",
            "step: 6328, loss: 9.731968930282164e-06\n",
            "step: 6329, loss: 3.259901131968945e-05\n",
            "step: 6330, loss: 1.4584772543457802e-05\n",
            "step: 6331, loss: 9.860361387836747e-06\n",
            "step: 6332, loss: 1.393464845023118e-05\n",
            "step: 6333, loss: 2.7469692213344388e-05\n",
            "step: 6334, loss: 1.2432436051312834e-05\n",
            "step: 6335, loss: 1.8202743376605213e-05\n",
            "step: 6336, loss: 2.8209709853399545e-05\n",
            "step: 6337, loss: 1.5746674762340263e-05\n",
            "step: 6338, loss: 0.01613510772585869\n",
            "step: 6339, loss: 0.00019695596711244434\n",
            "step: 6340, loss: 0.00018909279606305063\n",
            "step: 6341, loss: 0.027341090142726898\n",
            "step: 6342, loss: 7.233814540086314e-05\n",
            "step: 6343, loss: 3.698707223520614e-05\n",
            "step: 6344, loss: 0.00010457613825565204\n",
            "step: 6345, loss: 4.280923894839361e-05\n",
            "step: 6346, loss: 0.050179071724414825\n",
            "step: 6347, loss: 0.03853435441851616\n",
            "step: 6348, loss: 6.953943375265226e-05\n",
            "step: 6349, loss: 4.35413712693844e-05\n",
            "step: 6350, loss: 0.039761800318956375\n",
            "step: 6351, loss: 0.00015689035353716463\n",
            "step: 6352, loss: 8.909318421501666e-05\n",
            "step: 6353, loss: 6.550611578859389e-05\n",
            "step: 6354, loss: 0.00015133657143451273\n",
            "step: 6355, loss: 0.029676996171474457\n",
            "step: 6356, loss: 0.00017680868040770292\n",
            "step: 6357, loss: 0.03955382481217384\n",
            "step: 6358, loss: 5.983341543469578e-05\n",
            "step: 6359, loss: 2.916471021308098e-05\n",
            "step: 6360, loss: 3.0129132937872782e-05\n",
            "step: 6361, loss: 5.5834752856753767e-05\n",
            "step: 6362, loss: 9.715390478959307e-05\n",
            "step: 6363, loss: 0.04715103283524513\n",
            "step: 6364, loss: 0.00012754302588291466\n",
            "step: 6365, loss: 0.00022585086117032915\n",
            "step: 6366, loss: 7.538915815530345e-05\n",
            "step: 6367, loss: 0.00012932498066220433\n",
            "step: 6368, loss: 0.00023389984562527388\n",
            "step: 6369, loss: 0.0004212712519802153\n",
            "step: 6370, loss: 0.0001328847574768588\n",
            "step: 6371, loss: 0.04421765357255936\n",
            "step: 6372, loss: 0.023340219631791115\n",
            "step: 6373, loss: 5.1784900279017165e-05\n",
            "step: 6374, loss: 7.849179382901639e-05\n",
            "step: 6375, loss: 3.8479869544971734e-05\n",
            "step: 6376, loss: 5.816120756207965e-05\n",
            "step: 6377, loss: 3.862276571453549e-05\n",
            "step: 6378, loss: 2.3677386707277037e-05\n",
            "step: 6379, loss: 0.0005346443504095078\n",
            "step: 6380, loss: 4.5331889850785956e-05\n",
            "step: 6381, loss: 2.9480053854058497e-05\n",
            "step: 6382, loss: 1.8561120668891817e-05\n",
            "step: 6383, loss: 2.470195249770768e-05\n",
            "step: 6384, loss: 4.732397064799443e-05\n",
            "step: 6385, loss: 2.3880564185674302e-05\n",
            "step: 6386, loss: 0.001098623382858932\n",
            "step: 6387, loss: 1.2101448191970121e-05\n",
            "step: 6388, loss: 2.4398803361691535e-05\n",
            "step: 6389, loss: 2.5211209504050203e-05\n",
            "step: 6390, loss: 0.03350763022899628\n",
            "step: 6391, loss: 1.283271467400482e-05\n",
            "step: 6392, loss: 3.58550860255491e-05\n",
            "step: 6393, loss: 1.4568728147423826e-05\n",
            "step: 6394, loss: 6.625541118410183e-06\n",
            "step: 6395, loss: 5.239124584477395e-05\n",
            "step: 6396, loss: 2.1392830603872426e-05\n",
            "step: 6397, loss: 0.00012262551172170788\n",
            "step: 6398, loss: 7.565644773421809e-05\n",
            "step: 6399, loss: 0.026265716180205345\n",
            "step: 6400, loss: 8.894051279639825e-05\n",
            "step: 6401, loss: 7.423181523336098e-05\n",
            "step: 6402, loss: 1.9239334505982697e-05\n",
            "step: 6403, loss: 0.025041479617357254\n",
            "step: 6404, loss: 0.0307095218449831\n",
            "step: 6405, loss: 2.462482370901853e-05\n",
            "step: 6406, loss: 3.893703978974372e-05\n",
            "step: 6407, loss: 4.763923061545938e-05\n",
            "step: 6408, loss: 0.05629698932170868\n",
            "step: 6409, loss: 8.380159670196008e-06\n",
            "step: 6410, loss: 3.071870742132887e-05\n",
            "step: 6411, loss: 0.021287452429533005\n",
            "step: 6412, loss: 1.836054252635222e-05\n",
            "step: 6413, loss: 1.1216968232474755e-05\n",
            "step: 6414, loss: 1.8282005839864723e-05\n",
            "step: 6415, loss: 8.699370482645463e-06\n",
            "step: 6416, loss: 1.4495593632091186e-06\n",
            "step: 6417, loss: 9.67686628428055e-06\n",
            "step: 6418, loss: 9.84659436653601e-07\n",
            "step: 6419, loss: 1.3307289009389933e-05\n",
            "step: 6420, loss: 5.7314400692121126e-06\n",
            "step: 6421, loss: 0.00016149294970091432\n",
            "step: 6422, loss: 9.636923641664907e-05\n",
            "step: 6423, loss: 0.02405845932662487\n",
            "step: 6424, loss: 0.00014406853006221354\n",
            "step: 6425, loss: 2.2723619622411206e-05\n",
            "step: 6426, loss: 9.861362741503399e-06\n",
            "step: 6427, loss: 1.689977761998307e-05\n",
            "step: 6428, loss: 8.43238831294002e-06\n",
            "step: 6429, loss: 8.13434598967433e-06\n",
            "step: 6430, loss: 8.827388228382915e-06\n",
            "step: 6431, loss: 6.594229489564896e-06\n",
            "step: 6432, loss: 4.875556896877242e-06\n",
            "step: 6433, loss: 3.142325113003608e-06\n",
            "step: 6434, loss: 0.00021139626915100962\n",
            "step: 6435, loss: 6.091390787332784e-06\n",
            "step: 6436, loss: 4.882878783973865e-05\n",
            "step: 6437, loss: 1.4539945368596818e-05\n",
            "step: 6438, loss: 3.801479397225194e-05\n",
            "step: 6439, loss: 1.2650245480472222e-05\n",
            "step: 6440, loss: 6.98991643730551e-05\n",
            "step: 6441, loss: 4.1805127693805844e-05\n",
            "step: 6442, loss: 3.593615838326514e-05\n",
            "step: 6443, loss: 4.008950054412708e-05\n",
            "step: 6444, loss: 4.06727303925436e-06\n",
            "step: 6445, loss: 1.8333121261093765e-05\n",
            "step: 6446, loss: 6.52523958706297e-05\n",
            "step: 6447, loss: 5.0899874622700736e-05\n",
            "step: 6448, loss: 1.914488393595093e-06\n",
            "step: 6449, loss: 1.4853379752821638e-06\n",
            "step: 6450, loss: 6.820870112278499e-06\n",
            "step: 6451, loss: 4.291341156203998e-06\n",
            "step: 6452, loss: 3.604642188292928e-06\n",
            "step: 6453, loss: 2.822813485181541e-06\n",
            "step: 6454, loss: 1.032347768159525e-06\n",
            "step: 6455, loss: 3.35444497068238e-06\n",
            "step: 6456, loss: 1.9049531374548678e-06\n",
            "step: 6457, loss: 1.1705805263773073e-05\n",
            "step: 6458, loss: 3.2805116916279076e-06\n",
            "step: 6459, loss: 4.829975750908488e-06\n",
            "step: 6460, loss: 4.761130639963085e-06\n",
            "step: 6461, loss: 3.132727670163149e-06\n",
            "step: 6462, loss: 2.977815483973245e-06\n",
            "step: 6463, loss: 2.1624291548505425e-06\n",
            "step: 6464, loss: 0.00018697389168664813\n",
            "step: 6465, loss: 6.804211352573475e-06\n",
            "step: 6466, loss: 3.3497335607535206e-06\n",
            "step: 6467, loss: 5.407134267443325e-06\n",
            "step: 6468, loss: 1.2060412700520828e-05\n",
            "step: 6469, loss: 1.7573052900843322e-05\n",
            "step: 6470, loss: 0.05061021447181702\n",
            "step: 6471, loss: 0.0003454029792919755\n",
            "step: 6472, loss: 2.7844866053783335e-05\n",
            "step: 6473, loss: 2.9974225981277414e-05\n",
            "step: 6474, loss: 0.00031253823544830084\n",
            "step: 6475, loss: 1.7198195564560592e-05\n",
            "step: 6476, loss: 0.0016146856360137463\n",
            "step: 6477, loss: 0.02102786861360073\n",
            "step: 6478, loss: 1.1708278179867193e-05\n",
            "step: 6479, loss: 7.228661615954479e-06\n",
            "step: 6480, loss: 4.137340511078946e-05\n",
            "step: 6481, loss: 3.445512629696168e-05\n",
            "step: 6482, loss: 0.0002729209081735462\n",
            "step: 6483, loss: 2.9500912205548957e-05\n",
            "step: 6484, loss: 0.00016041880007833242\n",
            "step: 6485, loss: 2.0125415176153183e-05\n",
            "step: 6486, loss: 2.7168185624759644e-05\n",
            "step: 6487, loss: 2.4051811124081723e-05\n",
            "step: 6488, loss: 0.00011440724483691156\n",
            "step: 6489, loss: 1.0108745300385635e-05\n",
            "step: 6490, loss: 2.2144620743347332e-05\n",
            "step: 6491, loss: 1.76976463990286e-05\n",
            "step: 6492, loss: 5.528827841771999e-06\n",
            "step: 6493, loss: 1.1414252185204532e-05\n",
            "step: 6494, loss: 4.012284534837818e-06\n",
            "step: 6495, loss: 0.0001289236533921212\n",
            "step: 6496, loss: 8.21042794996174e-06\n",
            "step: 6497, loss: 4.241293027007487e-06\n",
            "step: 6498, loss: 6.365748390635417e-07\n",
            "step: 6499, loss: 1.4447998637479031e-06\n",
            "step: 6500, loss: 3.7692800560762407e-06\n",
            "step: 6501, loss: 1.4781934964958054e-07\n",
            "step: 6502, loss: 2.2148726657178486e-06\n",
            "step: 6503, loss: 9.664943354437128e-05\n",
            "step: 6504, loss: 3.383174043847248e-05\n",
            "step: 6505, loss: 4.730026194010861e-05\n",
            "step: 6506, loss: 6.134968134574592e-05\n",
            "step: 6507, loss: 2.5152477974188514e-05\n",
            "step: 6508, loss: 1.1936606824747287e-05\n",
            "step: 6509, loss: 6.737444891768973e-06\n",
            "step: 6510, loss: 1.2444746971596032e-05\n",
            "step: 6511, loss: 1.8392673155176453e-05\n",
            "step: 6512, loss: 4.2624051275197417e-05\n",
            "step: 6513, loss: 6.220064824447036e-05\n",
            "step: 6514, loss: 8.017713116714731e-05\n",
            "step: 6515, loss: 2.8940814445377328e-05\n",
            "step: 6516, loss: 0.00012313781189732254\n",
            "step: 6517, loss: 2.7104550099465996e-05\n",
            "step: 6518, loss: 1.307920683757402e-05\n",
            "step: 6519, loss: 2.1277694031596184e-05\n",
            "step: 6520, loss: 6.43475868855603e-06\n",
            "step: 6521, loss: 2.0694467366411118e-06\n",
            "step: 6522, loss: 0.0002783069503493607\n",
            "step: 6523, loss: 9.870039320958313e-06\n",
            "step: 6524, loss: 6.732787369401194e-06\n",
            "step: 6525, loss: 6.704061888740398e-06\n",
            "step: 6526, loss: 1.5106899809325114e-05\n",
            "step: 6527, loss: 1.1064693353546318e-05\n",
            "step: 6528, loss: 1.7484650015830994e-05\n",
            "step: 6529, loss: 8.606572919234168e-06\n",
            "step: 6530, loss: 3.439707506913692e-05\n",
            "step: 6531, loss: 7.228530193970073e-06\n",
            "step: 6532, loss: 8.642182365292683e-06\n",
            "step: 6533, loss: 1.6474654103149078e-06\n",
            "step: 6534, loss: 5.52637084183516e-06\n",
            "step: 6535, loss: 5.550287369260332e-06\n",
            "step: 6536, loss: 7.173792255343869e-06\n",
            "step: 6537, loss: 4.661026650865097e-06\n",
            "step: 6538, loss: 7.190255473688012e-06\n",
            "step: 6539, loss: 4.5430850150296465e-05\n",
            "step: 6540, loss: 8.715735748410225e-05\n",
            "step: 6541, loss: 6.832892722741235e-06\n",
            "step: 6542, loss: 3.473691094768583e-06\n",
            "step: 6543, loss: 1.6259992889899877e-06\n",
            "step: 6544, loss: 5.547673936234787e-06\n",
            "step: 6545, loss: 7.312052730412688e-06\n",
            "step: 6546, loss: 6.723345222781063e-07\n",
            "step: 6547, loss: 2.0837590000155615e-06\n",
            "step: 6548, loss: 3.0048493499634787e-05\n",
            "step: 6549, loss: 0.00013524664973374456\n",
            "step: 6550, loss: 6.926422065589577e-05\n",
            "step: 6551, loss: 1.2946775314048864e-05\n",
            "step: 6552, loss: 4.635465666069649e-05\n",
            "step: 6553, loss: 4.2587002099025995e-05\n",
            "step: 6554, loss: 8.934838660934474e-06\n",
            "step: 6555, loss: 2.9087979783071205e-05\n",
            "step: 6556, loss: 1.266117669729283e-05\n",
            "step: 6557, loss: 7.872232345107477e-06\n",
            "step: 6558, loss: 1.2532890650618356e-05\n",
            "step: 6559, loss: 2.518149085517507e-05\n",
            "step: 6560, loss: 1.1564668056962546e-05\n",
            "step: 6561, loss: 1.616725785424933e-05\n",
            "step: 6562, loss: 2.5988996640080586e-05\n",
            "step: 6563, loss: 1.4743022802576888e-05\n",
            "step: 6564, loss: 0.0193069688975811\n",
            "step: 6565, loss: 0.00020372431026771665\n",
            "step: 6566, loss: 0.0001713977981125936\n",
            "step: 6567, loss: 0.03530823811888695\n",
            "step: 6568, loss: 7.496715261368081e-05\n",
            "step: 6569, loss: 3.0079239877522923e-05\n",
            "step: 6570, loss: 9.952212712960318e-05\n",
            "step: 6571, loss: 5.077270179754123e-05\n",
            "step: 6572, loss: 0.05446702986955643\n",
            "step: 6573, loss: 0.04240189492702484\n",
            "step: 6574, loss: 5.620449883281253e-05\n",
            "step: 6575, loss: 3.656679837149568e-05\n",
            "step: 6576, loss: 0.041095905005931854\n",
            "step: 6577, loss: 0.0002014896017499268\n",
            "step: 6578, loss: 9.080235759029165e-05\n",
            "step: 6579, loss: 6.108298111939803e-05\n",
            "step: 6580, loss: 0.00017660684534348547\n",
            "step: 6581, loss: 0.03568407520651817\n",
            "step: 6582, loss: 0.0001987232972169295\n",
            "step: 6583, loss: 0.043295279145240784\n",
            "step: 6584, loss: 6.403151201084256e-05\n",
            "step: 6585, loss: 3.702395406435244e-05\n",
            "step: 6586, loss: 2.654212585184723e-05\n",
            "step: 6587, loss: 4.7045476094353944e-05\n",
            "step: 6588, loss: 0.00010377545549999923\n",
            "step: 6589, loss: 0.04694948345422745\n",
            "step: 6590, loss: 0.00012596475426107645\n",
            "step: 6591, loss: 0.00028364345780573785\n",
            "step: 6592, loss: 6.832434883108363e-05\n",
            "step: 6593, loss: 0.00013534871686715633\n",
            "step: 6594, loss: 6.058377039153129e-05\n",
            "step: 6595, loss: 0.0003191382857039571\n",
            "step: 6596, loss: 0.00012951696407981217\n",
            "step: 6597, loss: 0.026243211701512337\n",
            "step: 6598, loss: 0.02800665609538555\n",
            "step: 6599, loss: 5.410107405623421e-05\n",
            "step: 6600, loss: 4.704284583567642e-05\n",
            "step: 6601, loss: 3.363233554409817e-05\n",
            "step: 6602, loss: 5.2962273912271485e-05\n",
            "step: 6603, loss: 3.8227197364903986e-05\n",
            "step: 6604, loss: 2.2845168132334948e-05\n",
            "step: 6605, loss: 0.0004950181464664638\n",
            "step: 6606, loss: 3.687789285322651e-05\n",
            "step: 6607, loss: 2.7148886147188023e-05\n",
            "step: 6608, loss: 1.105010505852988e-05\n",
            "step: 6609, loss: 2.2816528144176118e-05\n",
            "step: 6610, loss: 3.3006737794494256e-05\n",
            "step: 6611, loss: 1.3918918739364017e-05\n",
            "step: 6612, loss: 0.00029759391327388585\n",
            "step: 6613, loss: 7.321625162148848e-06\n",
            "step: 6614, loss: 9.507452887191903e-06\n",
            "step: 6615, loss: 9.803264219954144e-06\n",
            "step: 6616, loss: 0.035957884043455124\n",
            "step: 6617, loss: 5.4477154662890825e-06\n",
            "step: 6618, loss: 2.9292215913301334e-05\n",
            "step: 6619, loss: 1.6553569366806187e-05\n",
            "step: 6620, loss: 6.2607509789813776e-06\n",
            "step: 6621, loss: 2.3884354959591292e-05\n",
            "step: 6622, loss: 1.4002073839947116e-05\n",
            "step: 6623, loss: 0.0001018877956084907\n",
            "step: 6624, loss: 9.092725667869672e-05\n",
            "step: 6625, loss: 0.02485867217183113\n",
            "step: 6626, loss: 0.00011903244740096852\n",
            "step: 6627, loss: 8.591968799009919e-05\n",
            "step: 6628, loss: 1.6435784345958382e-05\n",
            "step: 6629, loss: 0.02372085116803646\n",
            "step: 6630, loss: 0.02943882904946804\n",
            "step: 6631, loss: 2.6965166398440488e-05\n",
            "step: 6632, loss: 3.525173815432936e-05\n",
            "step: 6633, loss: 4.595673090079799e-05\n",
            "step: 6634, loss: 0.057399358600378036\n",
            "step: 6635, loss: 7.08799007043126e-06\n",
            "step: 6636, loss: 3.081571776419878e-05\n",
            "step: 6637, loss: 0.022553589195013046\n",
            "step: 6638, loss: 1.642013739910908e-05\n",
            "step: 6639, loss: 8.759085176279768e-06\n",
            "step: 6640, loss: 1.679506567597855e-05\n",
            "step: 6641, loss: 6.992481758061331e-06\n",
            "step: 6642, loss: 1.1658499943223433e-06\n",
            "step: 6643, loss: 8.105870620056521e-06\n",
            "step: 6644, loss: 8.892931759874045e-07\n",
            "step: 6645, loss: 1.0435739568492863e-05\n",
            "step: 6646, loss: 4.706290383182932e-06\n",
            "step: 6647, loss: 3.697823194670491e-05\n",
            "step: 6648, loss: 1.1805535905295983e-05\n",
            "step: 6649, loss: 0.02408413402736187\n",
            "step: 6650, loss: 0.00011230004747631028\n",
            "step: 6651, loss: 1.5766656360938214e-05\n",
            "step: 6652, loss: 2.0026682250318117e-06\n",
            "step: 6653, loss: 9.524316737952176e-06\n",
            "step: 6654, loss: 5.867245363333495e-06\n",
            "step: 6655, loss: 5.013775080442429e-06\n",
            "step: 6656, loss: 5.15409919898957e-06\n",
            "step: 6657, loss: 3.619115659603267e-06\n",
            "step: 6658, loss: 2.982584646815667e-06\n",
            "step: 6659, loss: 2.276880650242674e-06\n",
            "step: 6660, loss: 4.1861945646815e-05\n",
            "step: 6661, loss: 3.840858880721498e-06\n",
            "step: 6662, loss: 3.902890966855921e-05\n",
            "step: 6663, loss: 7.030591859802371e-06\n",
            "step: 6664, loss: 2.32375805353513e-05\n",
            "step: 6665, loss: 2.3054822122503538e-06\n",
            "step: 6666, loss: 1.509039975644555e-05\n",
            "step: 6667, loss: 6.885277798573952e-06\n",
            "step: 6668, loss: 1.453261575079523e-05\n",
            "step: 6669, loss: 2.2192376491148025e-05\n",
            "step: 6670, loss: 3.6691278637590585e-06\n",
            "step: 6671, loss: 2.7579697416513227e-05\n",
            "step: 6672, loss: 5.4745720262872055e-05\n",
            "step: 6673, loss: 4.222523421049118e-05\n",
            "step: 6674, loss: 1.413815198247903e-06\n",
            "step: 6675, loss: 1.163476554211229e-06\n",
            "step: 6676, loss: 3.633409733083681e-06\n",
            "step: 6677, loss: 2.8323352125880774e-06\n",
            "step: 6678, loss: 3.0658802643301897e-06\n",
            "step: 6679, loss: 1.9550066099327523e-06\n",
            "step: 6680, loss: 8.392300401283137e-07\n",
            "step: 6681, loss: 2.353141098865308e-06\n",
            "step: 6682, loss: 1.4972620192565955e-06\n",
            "step: 6683, loss: 9.727095857670065e-06\n",
            "step: 6684, loss: 3.189923972968245e-06\n",
            "step: 6685, loss: 4.105305833945749e-06\n",
            "step: 6686, loss: 4.041122338094283e-06\n",
            "step: 6687, loss: 3.1446456887351815e-06\n",
            "step: 6688, loss: 3.0922519727027975e-06\n",
            "step: 6689, loss: 2.1505113636521855e-06\n",
            "step: 6690, loss: 0.0002649418020155281\n",
            "step: 6691, loss: 6.582504283869639e-06\n",
            "step: 6692, loss: 3.5094690247206017e-06\n",
            "step: 6693, loss: 4.930328032060061e-06\n",
            "step: 6694, loss: 1.083033475879347e-05\n",
            "step: 6695, loss: 1.5985402569640428e-05\n",
            "step: 6696, loss: 0.04956161603331566\n",
            "step: 6697, loss: 0.0003891431842930615\n",
            "step: 6698, loss: 7.742177695035934e-05\n",
            "step: 6699, loss: 3.1999315979192033e-05\n",
            "step: 6700, loss: 0.00023868700372986495\n",
            "step: 6701, loss: 1.9286688257125206e-05\n",
            "step: 6702, loss: 2.7863012292073108e-05\n",
            "step: 6703, loss: 0.021980224177241325\n",
            "step: 6704, loss: 0.0001195790246129036\n",
            "step: 6705, loss: 8.008235454326496e-06\n",
            "step: 6706, loss: 3.53309660567902e-05\n",
            "step: 6707, loss: 3.147350071230903e-05\n",
            "step: 6708, loss: 0.00022473940043710172\n",
            "step: 6709, loss: 1.5043316125229467e-05\n",
            "step: 6710, loss: 0.00014291139086708426\n",
            "step: 6711, loss: 1.7832135199569166e-05\n",
            "step: 6712, loss: 2.1577936422545463e-05\n",
            "step: 6713, loss: 2.132707231794484e-05\n",
            "step: 6714, loss: 9.820603736443445e-05\n",
            "step: 6715, loss: 8.358803825103678e-06\n",
            "step: 6716, loss: 1.6981539374683052e-05\n",
            "step: 6717, loss: 1.530900590296369e-05\n",
            "step: 6718, loss: 4.9518689593242016e-06\n",
            "step: 6719, loss: 9.719452464196365e-06\n",
            "step: 6720, loss: 3.3138267099275254e-06\n",
            "step: 6721, loss: 0.0001171945477835834\n",
            "step: 6722, loss: 8.227163561969064e-06\n",
            "step: 6723, loss: 3.69296208191372e-06\n",
            "step: 6724, loss: 4.577623542445508e-07\n",
            "step: 6725, loss: 9.489011176810891e-07\n",
            "step: 6726, loss: 3.1589786431140965e-06\n",
            "step: 6727, loss: 1.4781932122787111e-07\n",
            "step: 6728, loss: 2.2387134777090978e-06\n",
            "step: 6729, loss: 8.686887304065749e-05\n",
            "step: 6730, loss: 2.8727235985570587e-05\n",
            "step: 6731, loss: 4.425431689014658e-05\n",
            "step: 6732, loss: 5.993923332425766e-05\n",
            "step: 6733, loss: 2.353861964365933e-05\n",
            "step: 6734, loss: 1.1016474672942422e-05\n",
            "step: 6735, loss: 5.9245048760203645e-06\n",
            "step: 6736, loss: 1.0854681022465229e-05\n",
            "step: 6737, loss: 1.6075528037617914e-05\n",
            "step: 6738, loss: 4.029268893646076e-05\n",
            "step: 6739, loss: 5.401687667472288e-05\n",
            "step: 6740, loss: 6.522928015328944e-05\n",
            "step: 6741, loss: 2.48670949076768e-05\n",
            "step: 6742, loss: 7.903907680884004e-05\n",
            "step: 6743, loss: 2.3686548956902698e-05\n",
            "step: 6744, loss: 1.946165139088407e-05\n",
            "step: 6745, loss: 1.9351946320966817e-05\n",
            "step: 6746, loss: 5.299933945934754e-06\n",
            "step: 6747, loss: 1.8739473262030515e-06\n",
            "step: 6748, loss: 0.00021943572210147977\n",
            "step: 6749, loss: 7.969974831212312e-06\n",
            "step: 6750, loss: 5.566964773606742e-06\n",
            "step: 6751, loss: 5.938772119407076e-06\n",
            "step: 6752, loss: 1.3178430890548043e-05\n",
            "step: 6753, loss: 1.0385218047304079e-05\n",
            "step: 6754, loss: 1.568238985782955e-05\n",
            "step: 6755, loss: 7.90087415225571e-06\n",
            "step: 6756, loss: 2.918047903222032e-05\n",
            "step: 6757, loss: 6.150961780804209e-06\n",
            "step: 6758, loss: 8.253570740635041e-06\n",
            "step: 6759, loss: 1.4591164472221863e-06\n",
            "step: 6760, loss: 4.749187610286754e-06\n",
            "step: 6761, loss: 5.1044571591774e-06\n",
            "step: 6762, loss: 7.011627531028353e-06\n",
            "step: 6763, loss: 4.174662080913549e-06\n",
            "step: 6764, loss: 6.224794105946785e-06\n",
            "step: 6765, loss: 3.477829886833206e-05\n",
            "step: 6766, loss: 6.815206143073738e-05\n",
            "step: 6767, loss: 5.1068268476228695e-06\n",
            "step: 6768, loss: 2.8967344860575395e-06\n",
            "step: 6769, loss: 1.3518219930119812e-06\n",
            "step: 6770, loss: 4.741901648230851e-06\n",
            "step: 6771, loss: 5.254625648376532e-06\n",
            "step: 6772, loss: 5.745845896854007e-07\n",
            "step: 6773, loss: 1.8143523448088672e-06\n",
            "step: 6774, loss: 2.7359788873582147e-05\n",
            "step: 6775, loss: 0.00012327426520641893\n",
            "step: 6776, loss: 0.00037703983252868056\n",
            "step: 6777, loss: 6.906667749717599e-06\n",
            "step: 6778, loss: 4.252583676134236e-05\n",
            "step: 6779, loss: 3.8341382605722174e-05\n",
            "step: 6780, loss: 7.979362635524012e-06\n",
            "step: 6781, loss: 2.7686479370458983e-05\n",
            "step: 6782, loss: 1.160525243903976e-05\n",
            "step: 6783, loss: 7.476524388039252e-06\n",
            "step: 6784, loss: 1.2866661563748494e-05\n",
            "step: 6785, loss: 2.5193596229655668e-05\n",
            "step: 6786, loss: 1.1502732377266511e-05\n",
            "step: 6787, loss: 1.533308022771962e-05\n",
            "step: 6788, loss: 2.5055096557480283e-05\n",
            "step: 6789, loss: 1.5026740584289655e-05\n",
            "step: 6790, loss: 0.019653623923659325\n",
            "step: 6791, loss: 0.00017974822549149394\n",
            "step: 6792, loss: 0.0001492358132964\n",
            "step: 6793, loss: 0.029971104115247726\n",
            "step: 6794, loss: 8.113496005535126e-05\n",
            "step: 6795, loss: 2.6555733711575158e-05\n",
            "step: 6796, loss: 0.00022280804114416242\n",
            "step: 6797, loss: 4.400034958962351e-05\n",
            "step: 6798, loss: 0.05607934296131134\n",
            "step: 6799, loss: 0.04597530514001846\n",
            "step: 6800, loss: 0.0004535601183306426\n",
            "step: 6801, loss: 3.0271667128545232e-05\n",
            "step: 6802, loss: 0.04367232322692871\n",
            "step: 6803, loss: 6.861310248496011e-05\n",
            "step: 6804, loss: 3.916974674211815e-05\n",
            "step: 6805, loss: 3.479843508102931e-05\n",
            "step: 6806, loss: 4.551609163172543e-05\n",
            "step: 6807, loss: 0.022702939808368683\n",
            "step: 6808, loss: 0.00010159790690522641\n",
            "step: 6809, loss: 0.04649464040994644\n",
            "step: 6810, loss: 2.8682425181614235e-05\n",
            "step: 6811, loss: 1.9470224287942983e-05\n",
            "step: 6812, loss: 1.0816587746376172e-05\n",
            "step: 6813, loss: 3.107004886260256e-05\n",
            "step: 6814, loss: 8.691525727044791e-05\n",
            "step: 6815, loss: 0.03996985778212547\n",
            "step: 6816, loss: 0.00011333403381286189\n",
            "step: 6817, loss: 0.00029326515505090356\n",
            "step: 6818, loss: 7.095413457136601e-05\n",
            "step: 6819, loss: 0.0001334847038378939\n",
            "step: 6820, loss: 2.83744084299542e-05\n",
            "step: 6821, loss: 0.00019994897593278438\n",
            "step: 6822, loss: 0.00012243706441950053\n",
            "step: 6823, loss: 0.03238128125667572\n",
            "step: 6824, loss: 0.028962500393390656\n",
            "step: 6825, loss: 4.4114574848208576e-05\n",
            "step: 6826, loss: 2.8315324016148224e-05\n",
            "step: 6827, loss: 2.3574295482831076e-05\n",
            "step: 6828, loss: 3.720120366779156e-05\n",
            "step: 6829, loss: 3.232552626286633e-05\n",
            "step: 6830, loss: 2.0353811123641208e-05\n",
            "step: 6831, loss: 0.00043128791730850935\n",
            "step: 6832, loss: 3.3305968827335164e-05\n",
            "step: 6833, loss: 1.5553760022157803e-05\n",
            "step: 6834, loss: 6.625460173381725e-06\n",
            "step: 6835, loss: 1.731026168272365e-05\n",
            "step: 6836, loss: 0.00012688623974099755\n",
            "step: 6837, loss: 1.1871460628753994e-05\n",
            "step: 6838, loss: 0.00021881918655708432\n",
            "step: 6839, loss: 7.009274668234866e-06\n",
            "step: 6840, loss: 2.1512090825126506e-05\n",
            "step: 6841, loss: 1.7338288671453483e-05\n",
            "step: 6842, loss: 0.08835884928703308\n",
            "step: 6843, loss: 7.145078143366845e-06\n",
            "step: 6844, loss: 2.954976116598118e-05\n",
            "step: 6845, loss: 1.4265729987528175e-05\n",
            "step: 6846, loss: 6.120075795479352e-06\n",
            "step: 6847, loss: 1.4710696632391773e-05\n",
            "step: 6848, loss: 0.0002402703685220331\n",
            "step: 6849, loss: 8.662494656164199e-05\n",
            "step: 6850, loss: 6.41363876638934e-05\n",
            "step: 6851, loss: 0.024399161338806152\n",
            "step: 6852, loss: 9.6687457698863e-05\n",
            "step: 6853, loss: 5.583684105658904e-05\n",
            "step: 6854, loss: 1.3851547009835485e-05\n",
            "step: 6855, loss: 0.0230548232793808\n",
            "step: 6856, loss: 0.02996724098920822\n",
            "step: 6857, loss: 1.8297838323633187e-05\n",
            "step: 6858, loss: 2.6493638870306313e-05\n",
            "step: 6859, loss: 3.290346285211854e-05\n",
            "step: 6860, loss: 0.05792298913002014\n",
            "step: 6861, loss: 6.611178378079785e-06\n",
            "step: 6862, loss: 3.0153654734021984e-05\n",
            "step: 6863, loss: 0.023114090785384178\n",
            "step: 6864, loss: 1.5049356989038642e-05\n",
            "step: 6865, loss: 8.31565193948336e-06\n",
            "step: 6866, loss: 1.5124791389098391e-05\n",
            "step: 6867, loss: 6.751672572136158e-06\n",
            "step: 6868, loss: 1.0728697361628292e-06\n",
            "step: 6869, loss: 8.418206562055275e-06\n",
            "step: 6870, loss: 3.3018766316672554e-06\n",
            "step: 6871, loss: 9.27036307984963e-06\n",
            "step: 6872, loss: 4.362968411442125e-06\n",
            "step: 6873, loss: 2.4096842025755905e-05\n",
            "step: 6874, loss: 9.862690603767987e-06\n",
            "step: 6875, loss: 0.024696148931980133\n",
            "step: 6876, loss: 0.00010438433673698455\n",
            "step: 6877, loss: 1.3847795344190672e-05\n",
            "step: 6878, loss: 1.423337039341277e-06\n",
            "step: 6879, loss: 8.625566806585994e-06\n",
            "step: 6880, loss: 4.8397323553217575e-06\n",
            "step: 6881, loss: 4.186510068393545e-06\n",
            "step: 6882, loss: 3.819187440967653e-06\n",
            "step: 6883, loss: 2.5272040602430934e-06\n",
            "step: 6884, loss: 2.2506530967802973e-06\n",
            "step: 6885, loss: 1.864422415565059e-06\n",
            "step: 6886, loss: 3.026732156286016e-05\n",
            "step: 6887, loss: 2.963503447972471e-06\n",
            "step: 6888, loss: 0.0005484622088260949\n",
            "step: 6889, loss: 5.13534951096517e-06\n",
            "step: 6890, loss: 1.7974347429117188e-05\n",
            "step: 6891, loss: 1.6665327393639018e-06\n",
            "step: 6892, loss: 1.1328486834827345e-05\n",
            "step: 6893, loss: 3.931447736249538e-06\n",
            "step: 6894, loss: 1.0625393770169467e-05\n",
            "step: 6895, loss: 1.2380443877191283e-05\n",
            "step: 6896, loss: 3.0802586934441933e-06\n",
            "step: 6897, loss: 1.4450304661295377e-05\n",
            "step: 6898, loss: 4.518783316598274e-05\n",
            "step: 6899, loss: 3.556892625056207e-05\n",
            "step: 6900, loss: 1.2779178177879658e-06\n",
            "step: 6901, loss: 9.274444892071187e-07\n",
            "step: 6902, loss: 2.9205712053226307e-06\n",
            "step: 6903, loss: 3.0182854970917106e-06\n",
            "step: 6904, loss: 2.608163413242437e-06\n",
            "step: 6905, loss: 1.4233477259040228e-06\n",
            "step: 6906, loss: 7.510160457968595e-07\n",
            "step: 6907, loss: 1.9788392364716856e-06\n",
            "step: 6908, loss: 1.3995115750731202e-06\n",
            "step: 6909, loss: 9.595948540663812e-06\n",
            "step: 6910, loss: 3.3019730381056434e-06\n",
            "step: 6911, loss: 5.199443421588512e-06\n",
            "step: 6912, loss: 3.2019231639424106e-06\n",
            "step: 6913, loss: 3.988574917457299e-06\n",
            "step: 6914, loss: 3.1208610380417667e-06\n",
            "step: 6915, loss: 1.8548779507909785e-06\n",
            "step: 6916, loss: 5.927530219196342e-05\n",
            "step: 6917, loss: 1.2748771041515283e-05\n",
            "step: 6918, loss: 3.5380799090489745e-06\n",
            "step: 6919, loss: 4.827833890885813e-06\n",
            "step: 6920, loss: 1.3075947208562866e-05\n",
            "step: 6921, loss: 1.6924639567150734e-05\n",
            "step: 6922, loss: 0.0543149933218956\n",
            "step: 6923, loss: 0.00018433733202982694\n",
            "step: 6924, loss: 1.906064608192537e-05\n",
            "step: 6925, loss: 2.908825445047114e-05\n",
            "step: 6926, loss: 0.0003089923702646047\n",
            "step: 6927, loss: 1.5887000699876808e-05\n",
            "step: 6928, loss: 2.2507249013870023e-05\n",
            "step: 6929, loss: 0.022091194987297058\n",
            "step: 6930, loss: 1.004904061119305e-05\n",
            "step: 6931, loss: 7.872325113567058e-06\n",
            "step: 6932, loss: 3.159573316224851e-05\n",
            "step: 6933, loss: 3.012208799191285e-05\n",
            "step: 6934, loss: 0.00020606227917596698\n",
            "step: 6935, loss: 8.246259312727489e-06\n",
            "step: 6936, loss: 0.00012897691340185702\n",
            "step: 6937, loss: 1.633034298720304e-05\n",
            "step: 6938, loss: 2.0805528038181365e-05\n",
            "step: 6939, loss: 1.9517960026860237e-05\n",
            "step: 6940, loss: 9.258268983103335e-05\n",
            "step: 6941, loss: 7.71508985053515e-06\n",
            "step: 6942, loss: 1.505549607827561e-05\n",
            "step: 6943, loss: 1.3687978935195133e-05\n",
            "step: 6944, loss: 4.71107068733545e-06\n",
            "step: 6945, loss: 9.578746357874479e-06\n",
            "step: 6946, loss: 2.946698486994137e-06\n",
            "step: 6947, loss: 7.373756670858711e-05\n",
            "step: 6948, loss: 7.197259492386365e-06\n",
            "step: 6949, loss: 3.464087967586238e-06\n",
            "step: 6950, loss: 4.5537825599240023e-07\n",
            "step: 6951, loss: 8.749908602112555e-07\n",
            "step: 6952, loss: 2.5033475594682386e-06\n",
            "step: 6953, loss: 1.1920918296937089e-07\n",
            "step: 6954, loss: 2.0169875369902e-06\n",
            "step: 6955, loss: 7.940622890600935e-05\n",
            "step: 6956, loss: 2.4206517991842702e-05\n",
            "step: 6957, loss: 4.120102312299423e-05\n",
            "step: 6958, loss: 5.539507037610747e-05\n",
            "step: 6959, loss: 1.9386096028028987e-05\n",
            "step: 6960, loss: 1.0668444701877888e-05\n",
            "step: 6961, loss: 5.3618737183569465e-06\n",
            "step: 6962, loss: 9.452918675378896e-06\n",
            "step: 6963, loss: 1.483112464484293e-05\n",
            "step: 6964, loss: 3.962273694924079e-05\n",
            "step: 6965, loss: 5.006138235330582e-05\n",
            "step: 6966, loss: 5.512585994438268e-05\n",
            "step: 6967, loss: 2.1217505491222255e-05\n",
            "step: 6968, loss: 5.0987837312277406e-05\n",
            "step: 6969, loss: 2.1893960365559906e-05\n",
            "step: 6970, loss: 3.0969970339356223e-06\n",
            "step: 6971, loss: 1.708816853351891e-05\n",
            "step: 6972, loss: 4.181788426649291e-06\n",
            "step: 6973, loss: 1.5902379573162762e-06\n",
            "step: 6974, loss: 0.00015512030222453177\n",
            "step: 6975, loss: 6.594445039809216e-06\n",
            "step: 6976, loss: 4.627625912689837e-06\n",
            "step: 6977, loss: 4.660940703615779e-06\n",
            "step: 6978, loss: 1.0232165550405625e-05\n",
            "step: 6979, loss: 1.0485332495591138e-05\n",
            "step: 6980, loss: 1.6488060282426886e-05\n",
            "step: 6981, loss: 6.148713509901427e-06\n",
            "step: 6982, loss: 2.6661562515073456e-05\n",
            "step: 6983, loss: 5.793372565676691e-06\n",
            "step: 6984, loss: 7.6218302638153546e-06\n",
            "step: 6985, loss: 1.3995121435073088e-06\n",
            "step: 6986, loss: 4.3629552237689495e-06\n",
            "step: 6987, loss: 4.55849703939748e-06\n",
            "step: 6988, loss: 6.196286904014414e-06\n",
            "step: 6989, loss: 3.855186605505878e-06\n",
            "step: 6990, loss: 5.571599103859626e-06\n",
            "step: 6991, loss: 2.2697378881275654e-05\n",
            "step: 6992, loss: 5.3309137001633644e-05\n",
            "step: 6993, loss: 4.384442036098335e-06\n",
            "step: 6994, loss: 2.4962005227280315e-06\n",
            "step: 6995, loss: 1.2540720035758568e-06\n",
            "step: 6996, loss: 4.238883320795139e-06\n",
            "step: 6997, loss: 4.372503099148162e-06\n",
            "step: 6998, loss: 5.125967277308519e-07\n",
            "step: 6999, loss: 1.4042776683709235e-06\n",
            "step: 7000, loss: 2.3762844648445025e-05\n",
            "step: 7001, loss: 0.00010719628335209563\n",
            "step: 7002, loss: 3.223418752895668e-05\n",
            "step: 7003, loss: 5.666989636665676e-06\n",
            "step: 7004, loss: 3.678225402836688e-05\n",
            "step: 7005, loss: 3.255369665566832e-05\n",
            "step: 7006, loss: 7.383345291600563e-06\n",
            "step: 7007, loss: 2.3488928491133265e-05\n",
            "step: 7008, loss: 1.0182015103055164e-05\n",
            "step: 7009, loss: 6.241605206014356e-06\n",
            "step: 7010, loss: 1.1329047993058339e-05\n",
            "step: 7011, loss: 2.2061260096961632e-05\n",
            "step: 7012, loss: 1.0735075193224475e-05\n",
            "step: 7013, loss: 1.4100773114478216e-05\n",
            "step: 7014, loss: 2.3241578674060293e-05\n",
            "step: 7015, loss: 1.2907347809232306e-05\n",
            "step: 7016, loss: 0.017955129966139793\n",
            "step: 7017, loss: 0.0001358894951408729\n",
            "step: 7018, loss: 0.00012193634029245004\n",
            "step: 7019, loss: 0.032143570482730865\n",
            "step: 7020, loss: 5.2964162023272365e-05\n",
            "step: 7021, loss: 1.954485196620226e-05\n",
            "step: 7022, loss: 7.312076195375994e-05\n",
            "step: 7023, loss: 3.442211163928732e-05\n",
            "step: 7024, loss: 0.0575820654630661\n",
            "step: 7025, loss: 0.03539744019508362\n",
            "step: 7026, loss: 5.2217812481103465e-05\n",
            "step: 7027, loss: 2.4343127734027803e-05\n",
            "step: 7028, loss: 0.047206807881593704\n",
            "step: 7029, loss: 0.0001910013670567423\n",
            "step: 7030, loss: 7.592057954752818e-05\n",
            "step: 7031, loss: 5.126959513290785e-05\n",
            "step: 7032, loss: 0.00029652827652171254\n",
            "step: 7033, loss: 0.04362974688410759\n",
            "step: 7034, loss: 0.00015936508134473115\n",
            "step: 7035, loss: 0.05312081426382065\n",
            "step: 7036, loss: 3.130340701318346e-05\n",
            "step: 7037, loss: 2.3842583686928265e-05\n",
            "step: 7038, loss: 1.3291224604472518e-05\n",
            "step: 7039, loss: 2.456202855682932e-05\n",
            "step: 7040, loss: 7.903332880232483e-05\n",
            "step: 7041, loss: 0.039345547556877136\n",
            "step: 7042, loss: 9.551800758345053e-05\n",
            "step: 7043, loss: 0.0001544354308862239\n",
            "step: 7044, loss: 5.568482811213471e-05\n",
            "step: 7045, loss: 0.00010049658158095554\n",
            "step: 7046, loss: 2.1822423150297254e-05\n",
            "step: 7047, loss: 7.791866664774716e-05\n",
            "step: 7048, loss: 9.280750236939639e-05\n",
            "step: 7049, loss: 0.03279990702867508\n",
            "step: 7050, loss: 0.030105197802186012\n",
            "step: 7051, loss: 3.7387781048892066e-05\n",
            "step: 7052, loss: 2.7371817850507796e-05\n",
            "step: 7053, loss: 2.411102832411416e-05\n",
            "step: 7054, loss: 4.712119698524475e-05\n",
            "step: 7055, loss: 3.2606953027425334e-05\n",
            "step: 7056, loss: 2.3256887288880534e-05\n",
            "step: 7057, loss: 0.00040155756869353354\n",
            "step: 7058, loss: 3.363531141076237e-05\n",
            "step: 7059, loss: 1.712472476356197e-05\n",
            "step: 7060, loss: 6.744666734448401e-06\n",
            "step: 7061, loss: 2.3113623683457263e-05\n",
            "step: 7062, loss: 0.00014179456047713757\n",
            "step: 7063, loss: 1.0038315849669743e-05\n",
            "step: 7064, loss: 0.00014873356849420816\n",
            "step: 7065, loss: 4.28904377258732e-06\n",
            "step: 7066, loss: 7.116488632163964e-06\n",
            "step: 7067, loss: 9.092699656321201e-06\n",
            "step: 7068, loss: 0.03389538824558258\n",
            "step: 7069, loss: 4.577502295433078e-06\n",
            "step: 7070, loss: 1.48135131894378e-05\n",
            "step: 7071, loss: 1.0947447663056664e-05\n",
            "step: 7072, loss: 4.391604306874797e-06\n",
            "step: 7073, loss: 8.239346243499313e-06\n",
            "step: 7074, loss: 1.3197750377003103e-05\n",
            "step: 7075, loss: 7.532564632128924e-05\n",
            "step: 7076, loss: 4.722249650512822e-05\n",
            "step: 7077, loss: 0.024400370195508003\n",
            "step: 7078, loss: 8.93226097105071e-05\n",
            "step: 7079, loss: 4.27166887675412e-05\n",
            "step: 7080, loss: 1.1956256457779091e-05\n",
            "step: 7081, loss: 0.0227894838899374\n",
            "step: 7082, loss: 0.03051299788057804\n",
            "step: 7083, loss: 1.5444187738467008e-05\n",
            "step: 7084, loss: 2.15327618207084e-05\n",
            "step: 7085, loss: 2.847683208528906e-05\n",
            "step: 7086, loss: 0.057116761803627014\n",
            "step: 7087, loss: 4.9041900638258085e-06\n",
            "step: 7088, loss: 2.7905070965061896e-05\n",
            "step: 7089, loss: 0.023697828873991966\n",
            "step: 7090, loss: 2.154873618565034e-05\n",
            "step: 7091, loss: 6.506238150905119e-06\n",
            "step: 7092, loss: 1.7725526049616747e-05\n",
            "step: 7093, loss: 6.7350010795053095e-06\n",
            "step: 7094, loss: 8.678337053424912e-07\n",
            "step: 7095, loss: 6.129552275524475e-06\n",
            "step: 7096, loss: 8.249197094301053e-07\n",
            "step: 7097, loss: 8.085808076430112e-06\n",
            "step: 7098, loss: 3.948126504838001e-06\n",
            "step: 7099, loss: 1.2893732673546765e-05\n",
            "step: 7100, loss: 8.816162335278932e-06\n",
            "step: 7101, loss: 0.02534327283501625\n",
            "step: 7102, loss: 9.431932267034426e-05\n",
            "step: 7103, loss: 1.0632411431288347e-05\n",
            "step: 7104, loss: 1.3279710628921748e-06\n",
            "step: 7105, loss: 7.602844107168494e-06\n",
            "step: 7106, loss: 4.434448783285916e-06\n",
            "step: 7107, loss: 3.5022828797082184e-06\n",
            "step: 7108, loss: 3.015823267560336e-06\n",
            "step: 7109, loss: 2.002697101488593e-06\n",
            "step: 7110, loss: 2.4532980660296744e-06\n",
            "step: 7111, loss: 1.3542116903408896e-06\n",
            "step: 7112, loss: 1.9357456039870158e-05\n",
            "step: 7113, loss: 1.5377898989754613e-06\n",
            "step: 7114, loss: 0.0033268991392105818\n",
            "step: 7115, loss: 2.6225561668979935e-06\n",
            "step: 7116, loss: 9.878980563371442e-06\n",
            "step: 7117, loss: 6.484964956143813e-07\n",
            "step: 7118, loss: 2.8990937153139384e-06\n",
            "step: 7119, loss: 1.0132746410818072e-06\n",
            "step: 7120, loss: 4.825355517823482e-06\n",
            "step: 7121, loss: 3.5976734125142684e-06\n",
            "step: 7122, loss: 2.6272575723851332e-06\n",
            "step: 7123, loss: 2.9817605536663905e-05\n",
            "step: 7124, loss: 9.750526078278199e-05\n",
            "step: 7125, loss: 0.00010293673403793946\n",
            "step: 7126, loss: 1.5306391105696093e-06\n",
            "step: 7127, loss: 1.6331485994669492e-06\n",
            "step: 7128, loss: 5.855046765645966e-06\n",
            "step: 7129, loss: 8.977820471045561e-06\n",
            "step: 7130, loss: 3.1469542136619566e-06\n",
            "step: 7131, loss: 1.7809741166274762e-06\n",
            "step: 7132, loss: 1.1944705420319224e-06\n",
            "step: 7133, loss: 2.300700771229458e-06\n",
            "step: 7134, loss: 1.3756693988398183e-06\n",
            "step: 7135, loss: 7.369242212007521e-06\n",
            "step: 7136, loss: 3.0421288101933897e-06\n",
            "step: 7137, loss: 3.115992285529501e-06\n",
            "step: 7138, loss: 2.787079438348883e-06\n",
            "step: 7139, loss: 3.2328491670341464e-06\n",
            "step: 7140, loss: 2.9182040179875912e-06\n",
            "step: 7141, loss: 1.3852020401827758e-06\n",
            "step: 7142, loss: 0.0001677872787695378\n",
            "step: 7143, loss: 8.201015589293092e-06\n",
            "step: 7144, loss: 3.1637709980714135e-06\n",
            "step: 7145, loss: 5.08533275933587e-06\n",
            "step: 7146, loss: 1.0937653314613272e-05\n",
            "step: 7147, loss: 1.4426175766857341e-05\n",
            "step: 7148, loss: 0.05622924491763115\n",
            "step: 7149, loss: 0.00015289256407413632\n",
            "step: 7150, loss: 1.5570480172755197e-05\n",
            "step: 7151, loss: 2.722191857174039e-05\n",
            "step: 7152, loss: 0.0001671784557402134\n",
            "step: 7153, loss: 1.3824952475260943e-05\n",
            "step: 7154, loss: 2.049296017503366e-05\n",
            "step: 7155, loss: 0.02198243886232376\n",
            "step: 7156, loss: 6.143921837065136e-06\n",
            "step: 7157, loss: 6.027043127687648e-06\n",
            "step: 7158, loss: 5.533671355806291e-05\n",
            "step: 7159, loss: 4.6246797865023836e-05\n",
            "step: 7160, loss: 0.0007076803594827652\n",
            "step: 7161, loss: 3.480062878224999e-05\n",
            "step: 7162, loss: 0.00036480167182162404\n",
            "step: 7163, loss: 2.0623878299375065e-05\n",
            "step: 7164, loss: 3.566980012692511e-05\n",
            "step: 7165, loss: 3.124871363979764e-05\n",
            "step: 7166, loss: 0.0002555415267124772\n",
            "step: 7167, loss: 1.3765680705546401e-05\n",
            "step: 7168, loss: 3.512223338475451e-05\n",
            "step: 7169, loss: 5.278328535496257e-05\n",
            "step: 7170, loss: 6.1820587688998785e-06\n",
            "step: 7171, loss: 6.903601752128452e-05\n",
            "step: 7172, loss: 7.18216979294084e-05\n",
            "step: 7173, loss: 0.00015103934856597334\n",
            "step: 7174, loss: 8.723131941223983e-06\n",
            "step: 7175, loss: 7.204116627690382e-06\n",
            "step: 7176, loss: 0.00017406507686246186\n",
            "step: 7177, loss: 1.4448004321820918e-06\n",
            "step: 7178, loss: 2.8830572773586027e-05\n",
            "step: 7179, loss: 2.980218880566099e-07\n",
            "step: 7180, loss: 4.150653694523498e-06\n",
            "step: 7181, loss: 9.206332470057532e-05\n",
            "step: 7182, loss: 1.9144876205245964e-05\n",
            "step: 7183, loss: 3.81971440219786e-05\n",
            "step: 7184, loss: 5.265951040200889e-05\n",
            "step: 7185, loss: 1.7922453480423428e-05\n",
            "step: 7186, loss: 1.0141626262338832e-05\n",
            "step: 7187, loss: 4.448779691301752e-06\n",
            "step: 7188, loss: 8.015367711777799e-06\n",
            "step: 7189, loss: 1.245195835508639e-05\n",
            "step: 7190, loss: 3.584207661333494e-05\n",
            "step: 7191, loss: 4.590138632920571e-05\n",
            "step: 7192, loss: 5.0129547162214294e-05\n",
            "step: 7193, loss: 1.7911113900481723e-05\n",
            "step: 7194, loss: 3.7057092413306236e-05\n",
            "step: 7195, loss: 2.0993205907871015e-05\n",
            "step: 7196, loss: 5.881361630599713e-06\n",
            "step: 7197, loss: 3.607119288062677e-05\n",
            "step: 7198, loss: 5.1115976020810194e-06\n",
            "step: 7199, loss: 2.546282985349535e-06\n",
            "step: 7200, loss: 0.00014272792031988502\n",
            "step: 7201, loss: 5.910225354455179e-06\n",
            "step: 7202, loss: 4.639545295503922e-06\n",
            "step: 7203, loss: 4.7825042202020995e-06\n",
            "step: 7204, loss: 1.0763726095319726e-05\n",
            "step: 7205, loss: 1.0630722499627154e-05\n",
            "step: 7206, loss: 1.3713253792957403e-05\n",
            "step: 7207, loss: 5.690964371751761e-06\n",
            "step: 7208, loss: 2.4330771339009516e-05\n",
            "step: 7209, loss: 5.638407401420409e-06\n",
            "step: 7210, loss: 7.855446710891556e-06\n",
            "step: 7211, loss: 1.2993770042157848e-06\n",
            "step: 7212, loss: 4.620420440915041e-06\n",
            "step: 7213, loss: 4.458363491721684e-06\n",
            "step: 7214, loss: 6.558608674822608e-06\n",
            "step: 7215, loss: 3.740747160918545e-06\n",
            "step: 7216, loss: 4.484523287828779e-06\n",
            "step: 7217, loss: 1.7471904357080348e-05\n",
            "step: 7218, loss: 4.8084246373036876e-05\n",
            "step: 7219, loss: 3.077943802054506e-06\n",
            "step: 7220, loss: 2.100435040119919e-06\n",
            "step: 7221, loss: 8.916796900848567e-07\n",
            "step: 7222, loss: 3.5570440104493173e-06\n",
            "step: 7223, loss: 3.499909098536591e-06\n",
            "step: 7224, loss: 3.719315770922549e-07\n",
            "step: 7225, loss: 1.1825509318441618e-06\n",
            "step: 7226, loss: 2.13432103919331e-05\n",
            "step: 7227, loss: 0.00011426349374232814\n",
            "step: 7228, loss: 2.8701391784125008e-05\n",
            "step: 7229, loss: 3.194736791556352e-06\n",
            "step: 7230, loss: 3.2633946830173954e-05\n",
            "step: 7231, loss: 2.7350539312465116e-05\n",
            "step: 7232, loss: 6.150325589260319e-06\n",
            "step: 7233, loss: 2.2902446289663203e-05\n",
            "step: 7234, loss: 9.338150448456872e-06\n",
            "step: 7235, loss: 6.787580332456855e-06\n",
            "step: 7236, loss: 1.215158226841595e-05\n",
            "step: 7237, loss: 2.3100938051356934e-05\n",
            "step: 7238, loss: 1.1524213732627686e-05\n",
            "step: 7239, loss: 1.3681475138582755e-05\n",
            "step: 7240, loss: 2.185986886615865e-05\n",
            "step: 7241, loss: 1.3546302398026455e-05\n",
            "step: 7242, loss: 0.023898757994174957\n",
            "step: 7243, loss: 0.00014089680917095393\n",
            "step: 7244, loss: 0.00013477318861987442\n",
            "step: 7245, loss: 0.032673850655555725\n",
            "step: 7246, loss: 6.501680763904005e-05\n",
            "step: 7247, loss: 2.0405454051797278e-05\n",
            "step: 7248, loss: 7.561785605503246e-05\n",
            "step: 7249, loss: 4.048621849506162e-05\n",
            "step: 7250, loss: 0.05928945541381836\n",
            "step: 7251, loss: 0.05679023265838623\n",
            "step: 7252, loss: 4.686585089075379e-05\n",
            "step: 7253, loss: 2.322256113984622e-05\n",
            "step: 7254, loss: 0.047288231551647186\n",
            "step: 7255, loss: 6.999024481046945e-05\n",
            "step: 7256, loss: 3.4118314943043515e-05\n",
            "step: 7257, loss: 2.280814260302577e-05\n",
            "step: 7258, loss: 4.576211722451262e-05\n",
            "step: 7259, loss: 0.029495449736714363\n",
            "step: 7260, loss: 0.00011208896466996521\n",
            "step: 7261, loss: 0.05048571527004242\n",
            "step: 7262, loss: 2.015318750636652e-05\n",
            "step: 7263, loss: 1.3515382306650281e-05\n",
            "step: 7264, loss: 9.128728379437234e-06\n",
            "step: 7265, loss: 1.6839672753121704e-05\n",
            "step: 7266, loss: 8.146760956151411e-05\n",
            "step: 7267, loss: 0.03954930230975151\n",
            "step: 7268, loss: 9.337518713437021e-05\n",
            "step: 7269, loss: 0.0001358275767415762\n",
            "step: 7270, loss: 5.954386142548174e-05\n",
            "step: 7271, loss: 0.0001110327139031142\n",
            "step: 7272, loss: 1.9090752175543457e-05\n",
            "step: 7273, loss: 6.0335434682201594e-05\n",
            "step: 7274, loss: 8.192749373847619e-05\n",
            "step: 7275, loss: 0.037992238998413086\n",
            "step: 7276, loss: 0.030851328745484352\n",
            "step: 7277, loss: 3.1258907256415114e-05\n",
            "step: 7278, loss: 2.3986985979718156e-05\n",
            "step: 7279, loss: 1.7715674403007142e-05\n",
            "step: 7280, loss: 3.9619138988200575e-05\n",
            "step: 7281, loss: 2.9386528694885783e-05\n",
            "step: 7282, loss: 2.0451461750781164e-05\n",
            "step: 7283, loss: 0.0003330589388497174\n",
            "step: 7284, loss: 2.9778568205074407e-05\n",
            "step: 7285, loss: 1.3675100490218028e-05\n",
            "step: 7286, loss: 5.059141130914213e-06\n",
            "step: 7287, loss: 1.7917756849783473e-05\n",
            "step: 7288, loss: 1.532644819235429e-05\n",
            "step: 7289, loss: 9.409249287273269e-06\n",
            "step: 7290, loss: 0.00016254068759735674\n",
            "step: 7291, loss: 3.821769496425986e-06\n",
            "step: 7292, loss: 1.2859115486207884e-05\n",
            "step: 7293, loss: 8.141609214362688e-06\n",
            "step: 7294, loss: 0.038137055933475494\n",
            "step: 7295, loss: 4.6132395254971925e-06\n",
            "step: 7296, loss: 1.3993544598633889e-05\n",
            "step: 7297, loss: 8.129702109727077e-06\n",
            "step: 7298, loss: 4.193727363599464e-06\n",
            "step: 7299, loss: 6.8351018853718415e-06\n",
            "step: 7300, loss: 1.1437095963628963e-05\n",
            "step: 7301, loss: 6.565484363818541e-05\n",
            "step: 7302, loss: 4.1504223190713674e-05\n",
            "step: 7303, loss: 0.02773132547736168\n",
            "step: 7304, loss: 7.41143012419343e-05\n",
            "step: 7305, loss: 3.536116491886787e-05\n",
            "step: 7306, loss: 1.0640269465511665e-05\n",
            "step: 7307, loss: 0.022704362869262695\n",
            "step: 7308, loss: 0.03142530098557472\n",
            "step: 7309, loss: 1.4113899851508904e-05\n",
            "step: 7310, loss: 2.134211354132276e-05\n",
            "step: 7311, loss: 2.5027420633705333e-05\n",
            "step: 7312, loss: 0.059971779584884644\n",
            "step: 7313, loss: 3.90763034374686e-06\n",
            "step: 7314, loss: 2.7071568183600903e-05\n",
            "step: 7315, loss: 0.024425718933343887\n",
            "step: 7316, loss: 0.0005246420041657984\n",
            "step: 7317, loss: 6.148581178422319e-06\n",
            "step: 7318, loss: 5.2642943046521395e-05\n",
            "step: 7319, loss: 8.45847898744978e-06\n",
            "step: 7320, loss: 5.483589688992652e-07\n",
            "step: 7321, loss: 4.088784407940693e-06\n",
            "step: 7322, loss: 5.626628194477235e-07\n",
            "step: 7323, loss: 7.230100891320035e-06\n",
            "step: 7324, loss: 2.543896471252083e-06\n",
            "step: 7325, loss: 8.58457678987179e-06\n",
            "step: 7326, loss: 8.7112393885036e-06\n",
            "step: 7327, loss: 0.026312565430998802\n",
            "step: 7328, loss: 8.830927981762215e-05\n",
            "step: 7329, loss: 9.407184734300245e-06\n",
            "step: 7330, loss: 1.301744759985013e-06\n",
            "step: 7331, loss: 6.675474651274271e-06\n",
            "step: 7332, loss: 3.3592452837183373e-06\n",
            "step: 7333, loss: 3.8455964386230335e-06\n",
            "step: 7334, loss: 2.491359282430494e-06\n",
            "step: 7335, loss: 1.9883937056874856e-06\n",
            "step: 7336, loss: 7.661793461011257e-06\n",
            "step: 7337, loss: 6.985645200074941e-07\n",
            "step: 7338, loss: 9.888441127259284e-06\n",
            "step: 7339, loss: 4.4584197667063563e-07\n",
            "step: 7340, loss: 1.4424208529817406e-06\n",
            "step: 7341, loss: 7.700895139350905e-07\n",
            "step: 7342, loss: 7.418747827614425e-06\n",
            "step: 7343, loss: 3.0040698106859054e-07\n",
            "step: 7344, loss: 2.2053227439755574e-06\n",
            "step: 7345, loss: 8.15388204955525e-07\n",
            "step: 7346, loss: 5.454662186821224e-06\n",
            "step: 7347, loss: 3.50470236298861e-06\n",
            "step: 7348, loss: 2.191004568885546e-06\n",
            "step: 7349, loss: 4.21285440097563e-05\n",
            "step: 7350, loss: 9.787223098101094e-05\n",
            "step: 7351, loss: 7.679222471779212e-05\n",
            "step: 7352, loss: 1.3422908295979141e-06\n",
            "step: 7353, loss: 1.5473193570869626e-06\n",
            "step: 7354, loss: 5.640457402478205e-06\n",
            "step: 7355, loss: 4.143461865169229e-06\n",
            "step: 7356, loss: 2.4985213258332806e-06\n",
            "step: 7357, loss: 3.18277284350188e-06\n",
            "step: 7358, loss: 9.107553182730044e-07\n",
            "step: 7359, loss: 1.933545036081341e-06\n",
            "step: 7360, loss: 1.2516928791228565e-06\n",
            "step: 7361, loss: 6.596847470063949e-06\n",
            "step: 7362, loss: 2.865708665922284e-06\n",
            "step: 7363, loss: 3.9265037230507005e-06\n",
            "step: 7364, loss: 2.8085371468478115e-06\n",
            "step: 7365, loss: 4.439113126863958e-06\n",
            "step: 7366, loss: 2.9491991426766617e-06\n",
            "step: 7367, loss: 1.3637446727443603e-06\n",
            "step: 7368, loss: 0.0002720023621805012\n",
            "step: 7369, loss: 7.0639857767673675e-06\n",
            "step: 7370, loss: 3.0207252166292164e-06\n",
            "step: 7371, loss: 3.993432983406819e-06\n",
            "step: 7372, loss: 1.1490789802337531e-05\n",
            "step: 7373, loss: 1.6059153495007195e-05\n",
            "step: 7374, loss: 0.059590164572000504\n",
            "step: 7375, loss: 0.0001326971541857347\n",
            "step: 7376, loss: 1.4700398423883598e-05\n",
            "step: 7377, loss: 2.6921725293505006e-05\n",
            "step: 7378, loss: 0.0001308436767430976\n",
            "step: 7379, loss: 1.3279131053423043e-05\n",
            "step: 7380, loss: 2.0137862520641647e-05\n",
            "step: 7381, loss: 0.02226199395954609\n",
            "step: 7382, loss: 7.650666702829767e-06\n",
            "step: 7383, loss: 6.911513537488645e-06\n",
            "step: 7384, loss: 3.504844426061027e-05\n",
            "step: 7385, loss: 3.3096941479016095e-05\n",
            "step: 7386, loss: 0.00030050004716031253\n",
            "step: 7387, loss: 5.891190994589124e-06\n",
            "step: 7388, loss: 0.00024145423958543688\n",
            "step: 7389, loss: 1.4125491361483e-05\n",
            "step: 7390, loss: 2.2251984773902223e-05\n",
            "step: 7391, loss: 2.1352601834223606e-05\n",
            "step: 7392, loss: 0.0001285105390707031\n",
            "step: 7393, loss: 8.55901998875197e-06\n",
            "step: 7394, loss: 1.1536808415257838e-05\n",
            "step: 7395, loss: 1.34470619741478e-05\n",
            "step: 7396, loss: 4.699147666542558e-06\n",
            "step: 7397, loss: 1.1631304914772045e-05\n",
            "step: 7398, loss: 9.839719496085308e-06\n",
            "step: 7399, loss: 1.9188946680515073e-05\n",
            "step: 7400, loss: 6.389139343809802e-06\n",
            "step: 7401, loss: 4.217375135340262e-06\n",
            "step: 7402, loss: 3.4615973163454328e-06\n",
            "step: 7403, loss: 9.274405670112174e-07\n",
            "step: 7404, loss: 6.062341071810806e-06\n",
            "step: 7405, loss: 1.1920915454766146e-07\n",
            "step: 7406, loss: 2.450879037496634e-06\n",
            "step: 7407, loss: 7.161806570366025e-05\n",
            "step: 7408, loss: 1.6889925973373465e-05\n",
            "step: 7409, loss: 3.403647860977799e-05\n",
            "step: 7410, loss: 5.399044312071055e-05\n",
            "step: 7411, loss: 1.631338454899378e-05\n",
            "step: 7412, loss: 9.872265763988253e-06\n",
            "step: 7413, loss: 3.964815732615534e-06\n",
            "step: 7414, loss: 7.0140872594492976e-06\n",
            "step: 7415, loss: 1.1248074770264793e-05\n",
            "step: 7416, loss: 3.445466427365318e-05\n",
            "step: 7417, loss: 4.250746133038774e-05\n",
            "step: 7418, loss: 4.506158074946143e-05\n",
            "step: 7419, loss: 1.581809192430228e-05\n",
            "step: 7420, loss: 4.4823475036537275e-05\n",
            "step: 7421, loss: 1.8695373000809923e-05\n",
            "step: 7422, loss: 4.422449819685426e-06\n",
            "step: 7423, loss: 1.1733347491826862e-05\n",
            "step: 7424, loss: 4.315307251090417e-06\n",
            "step: 7425, loss: 1.811962988540472e-06\n",
            "step: 7426, loss: 0.00014827890845481306\n",
            "step: 7427, loss: 5.571695055550663e-06\n",
            "step: 7428, loss: 4.243784132995643e-06\n",
            "step: 7429, loss: 4.815853117179358e-06\n",
            "step: 7430, loss: 1.0353611287428066e-05\n",
            "step: 7431, loss: 1.128392614191398e-05\n",
            "step: 7432, loss: 1.3296093129611108e-05\n",
            "step: 7433, loss: 6.141563517303439e-06\n",
            "step: 7434, loss: 2.2178901417646557e-05\n",
            "step: 7435, loss: 5.516834789887071e-06\n",
            "step: 7436, loss: 7.726723197265528e-06\n",
            "step: 7437, loss: 1.380439016429591e-06\n",
            "step: 7438, loss: 4.63710784970317e-06\n",
            "step: 7439, loss: 4.503665422816994e-06\n",
            "step: 7440, loss: 6.58484896121081e-06\n",
            "step: 7441, loss: 3.824192390311509e-06\n",
            "step: 7442, loss: 4.43208591605071e-06\n",
            "step: 7443, loss: 1.6406365830334835e-05\n",
            "step: 7444, loss: 3.500981620163657e-05\n",
            "step: 7445, loss: 3.3068142784031807e-06\n",
            "step: 7446, loss: 2.062291741822264e-06\n",
            "step: 7447, loss: 1.0442673783472856e-06\n",
            "step: 7448, loss: 3.435465259826742e-06\n",
            "step: 7449, loss: 3.2662601370248012e-06\n",
            "step: 7450, loss: 3.671630963708594e-07\n",
            "step: 7451, loss: 1.06095853880106e-06\n",
            "step: 7452, loss: 1.9476818124530837e-05\n",
            "step: 7453, loss: 9.849112393567339e-05\n",
            "step: 7454, loss: 2.1764968550996855e-05\n",
            "step: 7455, loss: 2.787052835628856e-06\n",
            "step: 7456, loss: 2.923035208368674e-05\n",
            "step: 7457, loss: 2.2524043743032962e-05\n",
            "step: 7458, loss: 5.720076842408162e-06\n",
            "step: 7459, loss: 2.0976447558496147e-05\n",
            "step: 7460, loss: 8.315438208228443e-06\n",
            "step: 7461, loss: 5.814884843857726e-06\n",
            "step: 7462, loss: 1.0704491614887957e-05\n",
            "step: 7463, loss: 2.1551410100073554e-05\n",
            "step: 7464, loss: 1.0394215678388719e-05\n",
            "step: 7465, loss: 1.2084296940884087e-05\n",
            "step: 7466, loss: 2.020111060119234e-05\n",
            "step: 7467, loss: 1.1810737305495422e-05\n",
            "step: 7468, loss: 0.02097899839282036\n",
            "step: 7469, loss: 8.85678018676117e-05\n",
            "step: 7470, loss: 0.00011034503404516727\n",
            "step: 7471, loss: 0.03371235728263855\n",
            "step: 7472, loss: 4.674820229411125e-05\n",
            "step: 7473, loss: 1.5985504433047026e-05\n",
            "step: 7474, loss: 6.170750566525385e-05\n",
            "step: 7475, loss: 2.853962178051006e-05\n",
            "step: 7476, loss: 0.05989380180835724\n",
            "step: 7477, loss: 0.04974709823727608\n",
            "step: 7478, loss: 3.071510582230985e-05\n",
            "step: 7479, loss: 1.7677713913144544e-05\n",
            "step: 7480, loss: 0.05083775147795677\n",
            "step: 7481, loss: 7.644180732313544e-05\n",
            "step: 7482, loss: 4.911304858978838e-05\n",
            "step: 7483, loss: 0.000707488798070699\n",
            "step: 7484, loss: 0.00010613906488288194\n",
            "step: 7485, loss: 0.035610735416412354\n",
            "step: 7486, loss: 0.00012947642244398594\n",
            "step: 7487, loss: 0.0579729825258255\n",
            "step: 7488, loss: 2.4639435650897212e-05\n",
            "step: 7489, loss: 1.5918445569695905e-05\n",
            "step: 7490, loss: 1.0222987839370035e-05\n",
            "step: 7491, loss: 1.7464275515521877e-05\n",
            "step: 7492, loss: 6.797562673455104e-05\n",
            "step: 7493, loss: 0.04024788364768028\n",
            "step: 7494, loss: 8.732383867027238e-05\n",
            "step: 7495, loss: 0.00010570148151600733\n",
            "step: 7496, loss: 6.008885247865692e-05\n",
            "step: 7497, loss: 9.755371138453484e-05\n",
            "step: 7498, loss: 1.7248203221242875e-05\n",
            "step: 7499, loss: 4.671121132560074e-05\n",
            "step: 7500, loss: 4.558250293484889e-05\n",
            "step: 7501, loss: 0.037565939128398895\n",
            "step: 7502, loss: 0.03186244145035744\n",
            "step: 7503, loss: 2.9999964681337588e-05\n",
            "step: 7504, loss: 2.2540310965268873e-05\n",
            "step: 7505, loss: 1.6144824257935397e-05\n",
            "step: 7506, loss: 3.696633575600572e-05\n",
            "step: 7507, loss: 2.7291287551634014e-05\n",
            "step: 7508, loss: 2.2132147933007218e-05\n",
            "step: 7509, loss: 0.0003020311996806413\n",
            "step: 7510, loss: 2.5484059733571485e-05\n",
            "step: 7511, loss: 1.353675270365784e-05\n",
            "step: 7512, loss: 4.3343811739759985e-06\n",
            "step: 7513, loss: 1.75841214513639e-05\n",
            "step: 7514, loss: 1.8403123249299824e-05\n",
            "step: 7515, loss: 1.7289541574427858e-05\n",
            "step: 7516, loss: 0.00015069991059135646\n",
            "step: 7517, loss: 3.3044148040062282e-06\n",
            "step: 7518, loss: 6.2295857787830755e-06\n",
            "step: 7519, loss: 5.755265192419756e-06\n",
            "step: 7520, loss: 0.03283032402396202\n",
            "step: 7521, loss: 3.3783162507461384e-06\n",
            "step: 7522, loss: 1.1009305126208346e-05\n",
            "step: 7523, loss: 6.84951601215289e-06\n",
            "step: 7524, loss: 3.733593075594399e-06\n",
            "step: 7525, loss: 5.640702056552982e-06\n",
            "step: 7526, loss: 8.924861504056025e-06\n",
            "step: 7527, loss: 5.647362195304595e-05\n",
            "step: 7528, loss: 3.2448864658363163e-05\n",
            "step: 7529, loss: 0.02418903075158596\n",
            "step: 7530, loss: 6.393952207872644e-05\n",
            "step: 7531, loss: 2.955434138129931e-05\n",
            "step: 7532, loss: 9.331422916147858e-06\n",
            "step: 7533, loss: 0.02281590737402439\n",
            "step: 7534, loss: 0.031981438398361206\n",
            "step: 7535, loss: 1.2497484931373037e-05\n",
            "step: 7536, loss: 1.6738660633563995e-05\n",
            "step: 7537, loss: 2.241703259642236e-05\n",
            "step: 7538, loss: 0.06078244745731354\n",
            "step: 7539, loss: 1.943098823176115e-06\n",
            "step: 7540, loss: 1.503948078607209e-05\n",
            "step: 7541, loss: 0.024776799604296684\n",
            "step: 7542, loss: 1.2958081242686603e-05\n",
            "step: 7543, loss: 2.0599118215614e-06\n",
            "step: 7544, loss: 0.0006271014572121203\n",
            "step: 7545, loss: 3.4951040106534492e-06\n",
            "step: 7546, loss: 4.219978677610925e-07\n",
            "step: 7547, loss: 1.7309023405687185e-06\n",
            "step: 7548, loss: 3.4093625345121836e-07\n",
            "step: 7549, loss: 5.807091383758234e-06\n",
            "step: 7550, loss: 1.0275797421854804e-06\n",
            "step: 7551, loss: 5.674050044035539e-06\n",
            "step: 7552, loss: 7.593197551614139e-06\n",
            "step: 7553, loss: 0.026833420619368553\n",
            "step: 7554, loss: 7.859856123104692e-05\n",
            "step: 7555, loss: 7.879201803007163e-06\n",
            "step: 7556, loss: 1.1467783451735158e-06\n",
            "step: 7557, loss: 5.872057499800576e-06\n",
            "step: 7558, loss: 3.00639931083424e-06\n",
            "step: 7559, loss: 3.046927076866268e-06\n",
            "step: 7560, loss: 2.0717798179248348e-06\n",
            "step: 7561, loss: 1.881104822132329e-06\n",
            "step: 7562, loss: 1.504411329733557e-06\n",
            "step: 7563, loss: 7.224062414934451e-07\n",
            "step: 7564, loss: 9.159152796200942e-06\n",
            "step: 7565, loss: 4.4107358121436846e-07\n",
            "step: 7566, loss: 1.5640127912774915e-06\n",
            "step: 7567, loss: 7.700894002482528e-07\n",
            "step: 7568, loss: 7.554617695859633e-06\n",
            "step: 7569, loss: 3.242487593979604e-07\n",
            "step: 7570, loss: 2.1099594960105605e-06\n",
            "step: 7571, loss: 8.249244274338707e-07\n",
            "step: 7572, loss: 4.629863269656198e-06\n",
            "step: 7573, loss: 3.139931550322217e-06\n",
            "step: 7574, loss: 1.757103859745257e-06\n",
            "step: 7575, loss: 2.1126013962202705e-05\n",
            "step: 7576, loss: 4.8785339458845556e-05\n",
            "step: 7577, loss: 2.279302862007171e-05\n",
            "step: 7578, loss: 1.296988330068416e-06\n",
            "step: 7579, loss: 1.0514178256926243e-06\n",
            "step: 7580, loss: 3.2304094474966405e-06\n",
            "step: 7581, loss: 2.9300449568836484e-06\n",
            "step: 7582, loss: 2.4747102997935144e-06\n",
            "step: 7583, loss: 1.1753966191463405e-06\n",
            "step: 7584, loss: 5.865082925993192e-07\n",
            "step: 7585, loss: 1.4686411304865032e-06\n",
            "step: 7586, loss: 1.0061235116154421e-06\n",
            "step: 7587, loss: 5.0686403483268805e-06\n",
            "step: 7588, loss: 2.6106135919690132e-06\n",
            "step: 7589, loss: 3.7596232687064912e-06\n",
            "step: 7590, loss: 3.0397879982047016e-06\n",
            "step: 7591, loss: 3.8455123103631195e-06\n",
            "step: 7592, loss: 2.6487975901545724e-06\n",
            "step: 7593, loss: 1.2969882163815782e-06\n",
            "step: 7594, loss: 0.07075070589780807\n",
            "step: 7595, loss: 5.712275651603704e-06\n",
            "step: 7596, loss: 1.4638823131463141e-06\n",
            "step: 7597, loss: 1.678455305409443e-06\n",
            "step: 7598, loss: 1.2053104910592083e-05\n",
            "step: 7599, loss: 1.878602233773563e-05\n",
            "step: 7600, loss: 0.06234901398420334\n",
            "step: 7601, loss: 0.0001254340459126979\n",
            "step: 7602, loss: 2.0998406398575753e-05\n",
            "step: 7603, loss: 2.924677392002195e-05\n",
            "step: 7604, loss: 9.49207678786479e-05\n",
            "step: 7605, loss: 1.2676033293246292e-05\n",
            "step: 7606, loss: 2.475372821209021e-05\n",
            "step: 7607, loss: 0.022027339786291122\n",
            "step: 7608, loss: 7.266836291819345e-06\n",
            "step: 7609, loss: 6.727947038598359e-06\n",
            "step: 7610, loss: 2.927442801592406e-05\n",
            "step: 7611, loss: 2.91982705675764e-05\n",
            "step: 7612, loss: 0.00021348641894292086\n",
            "step: 7613, loss: 3.874252342939144e-06\n",
            "step: 7614, loss: 0.0001638289977563545\n",
            "step: 7615, loss: 8.439808880211785e-06\n",
            "step: 7616, loss: 1.853106550697703e-05\n",
            "step: 7617, loss: 1.4963389730837662e-05\n",
            "step: 7618, loss: 9.499407315161079e-05\n",
            "step: 7619, loss: 7.071347226883518e-06\n",
            "step: 7620, loss: 9.004888852359727e-06\n",
            "step: 7621, loss: 1.066539880412165e-05\n",
            "step: 7622, loss: 4.227091721986653e-06\n",
            "step: 7623, loss: 1.0408448360976763e-05\n",
            "step: 7624, loss: 6.7319369918550365e-06\n",
            "step: 7625, loss: 1.7761049093678594e-05\n",
            "step: 7626, loss: 5.955243977950886e-06\n",
            "step: 7627, loss: 4.048130449518794e-06\n",
            "step: 7628, loss: 1.6569654235354392e-06\n",
            "step: 7629, loss: 8.630667593934049e-07\n",
            "step: 7630, loss: 3.5951454719906906e-06\n",
            "step: 7631, loss: 1.0251987703213672e-07\n",
            "step: 7632, loss: 2.1743248908023816e-06\n",
            "step: 7633, loss: 6.321329419733956e-05\n",
            "step: 7634, loss: 1.4058106899028644e-05\n",
            "step: 7635, loss: 2.9786604500259273e-05\n",
            "step: 7636, loss: 5.881169272470288e-05\n",
            "step: 7637, loss: 1.4599447240470909e-05\n",
            "step: 7638, loss: 9.68396125244908e-06\n",
            "step: 7639, loss: 3.378333531145472e-06\n",
            "step: 7640, loss: 6.0986158132436685e-06\n",
            "step: 7641, loss: 9.624579433875624e-06\n",
            "step: 7642, loss: 3.3865693694679067e-05\n",
            "step: 7643, loss: 4.115148476557806e-05\n",
            "step: 7644, loss: 4.2118903365917504e-05\n",
            "step: 7645, loss: 1.3689265870198142e-05\n",
            "step: 7646, loss: 3.708182703121565e-05\n",
            "step: 7647, loss: 1.6695727026672103e-05\n",
            "step: 7648, loss: 3.864618065563263e-06\n",
            "step: 7649, loss: 1.1292445378785487e-05\n",
            "step: 7650, loss: 3.6668261600425467e-06\n",
            "step: 7651, loss: 1.6188505469472148e-06\n",
            "step: 7652, loss: 0.24613358080387115\n",
            "step: 7653, loss: 5.097283974464517e-06\n",
            "step: 7654, loss: 2.9945017558929976e-06\n",
            "step: 7655, loss: 3.0183014132489916e-06\n",
            "step: 7656, loss: 5.857672476849984e-06\n",
            "step: 7657, loss: 1.0160987585550174e-05\n",
            "step: 7658, loss: 1.1565289241843857e-05\n",
            "step: 7659, loss: 5.335719379218062e-06\n",
            "step: 7660, loss: 1.763842738000676e-05\n",
            "step: 7661, loss: 4.680036909121554e-06\n",
            "step: 7662, loss: 8.625531336292624e-06\n",
            "step: 7663, loss: 1.211162839354074e-06\n",
            "step: 7664, loss: 4.08878258895129e-06\n",
            "step: 7665, loss: 3.98154224967584e-06\n",
            "step: 7666, loss: 5.590710770775331e-06\n",
            "step: 7667, loss: 3.3950479974009795e-06\n",
            "step: 7668, loss: 4.818308298126794e-06\n",
            "step: 7669, loss: 1.5014247765066102e-05\n",
            "step: 7670, loss: 2.817746099026408e-05\n",
            "step: 7671, loss: 2.758466962404782e-06\n",
            "step: 7672, loss: 1.8119578726327745e-06\n",
            "step: 7673, loss: 9.083699978873483e-07\n",
            "step: 7674, loss: 3.135078259219881e-06\n",
            "step: 7675, loss: 2.9587113203888293e-06\n",
            "step: 7676, loss: 3.6954716620130057e-07\n",
            "step: 7677, loss: 7.939314059512981e-07\n",
            "step: 7678, loss: 1.700246866676025e-05\n",
            "step: 7679, loss: 8.033125050133094e-05\n",
            "step: 7680, loss: 1.991274803003762e-05\n",
            "step: 7681, loss: 2.367444949413766e-06\n",
            "step: 7682, loss: 2.124053025909234e-05\n",
            "step: 7683, loss: 1.7424568795831874e-05\n",
            "step: 7684, loss: 5.075623448647093e-06\n",
            "step: 7685, loss: 1.8447266484145075e-05\n",
            "step: 7686, loss: 6.834994564997032e-06\n",
            "step: 7687, loss: 5.147334832145134e-06\n",
            "step: 7688, loss: 1.0663872672012076e-05\n",
            "step: 7689, loss: 1.6578391296206973e-05\n",
            "step: 7690, loss: 8.541827810404357e-06\n",
            "step: 7691, loss: 1.0532403393881395e-05\n",
            "step: 7692, loss: 1.768181573424954e-05\n",
            "step: 7693, loss: 8.184539183275774e-06\n",
            "step: 7694, loss: 0.011614902876317501\n",
            "step: 7695, loss: 6.725666753482074e-05\n",
            "step: 7696, loss: 8.95122648216784e-05\n",
            "step: 7697, loss: 0.035823289304971695\n",
            "step: 7698, loss: 4.329931107349694e-05\n",
            "step: 7699, loss: 1.4931764781067614e-05\n",
            "step: 7700, loss: 5.728874748456292e-05\n",
            "step: 7701, loss: 2.4860048142727464e-05\n",
            "step: 7702, loss: 0.059857483953237534\n",
            "step: 7703, loss: 0.05371015891432762\n",
            "step: 7704, loss: 2.5518686015857384e-05\n",
            "step: 7705, loss: 1.6304511518683285e-05\n",
            "step: 7706, loss: 0.05784754455089569\n",
            "step: 7707, loss: 0.00023461789533030242\n",
            "step: 7708, loss: 0.00011459448433015496\n",
            "step: 7709, loss: 0.000984273967333138\n",
            "step: 7710, loss: 0.00023624300956726074\n",
            "step: 7711, loss: 0.05805249139666557\n",
            "step: 7712, loss: 0.000511610065586865\n",
            "step: 7713, loss: 0.05534503981471062\n",
            "step: 7714, loss: 7.972609455464408e-05\n",
            "step: 7715, loss: 3.600329364417121e-05\n",
            "step: 7716, loss: 2.7675758246914484e-05\n",
            "step: 7717, loss: 2.2144515241961926e-05\n",
            "step: 7718, loss: 6.376473902491853e-05\n",
            "step: 7719, loss: 0.0415402427315712\n",
            "step: 7720, loss: 8.021202665986493e-05\n",
            "step: 7721, loss: 0.00010629055032040924\n",
            "step: 7722, loss: 4.6750035835430026e-05\n",
            "step: 7723, loss: 8.041856199270114e-05\n",
            "step: 7724, loss: 1.360568330710521e-05\n",
            "step: 7725, loss: 0.00017310230759903789\n",
            "step: 7726, loss: 4.746407284983434e-05\n",
            "step: 7727, loss: 0.04017660766839981\n",
            "step: 7728, loss: 0.03129265084862709\n",
            "step: 7729, loss: 2.4751736418693326e-05\n",
            "step: 7730, loss: 1.7603562810108997e-05\n",
            "step: 7731, loss: 1.1217186511203181e-05\n",
            "step: 7732, loss: 2.8602338716154918e-05\n",
            "step: 7733, loss: 2.2616768546868116e-05\n",
            "step: 7734, loss: 1.767210960679222e-05\n",
            "step: 7735, loss: 0.00027104507898911834\n",
            "step: 7736, loss: 2.2237743905861862e-05\n",
            "step: 7737, loss: 1.0184845450567082e-05\n",
            "step: 7738, loss: 3.48801995642134e-06\n",
            "step: 7739, loss: 1.53839591803262e-05\n",
            "step: 7740, loss: 1.1173974598932546e-05\n",
            "step: 7741, loss: 8.24593644210836e-06\n",
            "step: 7742, loss: 0.00016136046906467527\n",
            "step: 7743, loss: 1.9216295186197385e-06\n",
            "step: 7744, loss: 2.4866722014849074e-06\n",
            "step: 7745, loss: 3.902855041815201e-06\n",
            "step: 7746, loss: 0.022341981530189514\n",
            "step: 7747, loss: 3.7430636439239606e-06\n",
            "step: 7748, loss: 6.441779987653717e-06\n",
            "step: 7749, loss: 4.2341948756075e-06\n",
            "step: 7750, loss: 2.2983388134889537e-06\n",
            "step: 7751, loss: 3.6333406114863465e-06\n",
            "step: 7752, loss: 7.311264653253602e-06\n",
            "step: 7753, loss: 5.887462612008676e-05\n",
            "step: 7754, loss: 3.6311081203166395e-05\n",
            "step: 7755, loss: 0.02605227753520012\n",
            "step: 7756, loss: 3.6097251722821966e-05\n",
            "step: 7757, loss: 3.213615491404198e-05\n",
            "step: 7758, loss: 1.1992007785011083e-05\n",
            "step: 7759, loss: 0.023920053616166115\n",
            "step: 7760, loss: 0.033525899052619934\n",
            "step: 7761, loss: 1.4836243281024508e-05\n",
            "step: 7762, loss: 1.963764225365594e-05\n",
            "step: 7763, loss: 2.601661253720522e-05\n",
            "step: 7764, loss: 0.06079920753836632\n",
            "step: 7765, loss: 1.001354462459858e-06\n",
            "step: 7766, loss: 7.704396011831705e-06\n",
            "step: 7767, loss: 0.025445664301514626\n",
            "step: 7768, loss: 4.434330548974685e-06\n",
            "step: 7769, loss: 5.722029072785517e-07\n",
            "step: 7770, loss: 1.8572426370155881e-06\n",
            "step: 7771, loss: 1.8715500118560158e-06\n",
            "step: 7772, loss: 2.9802137646584015e-07\n",
            "step: 7773, loss: 1.0490340400792775e-06\n",
            "step: 7774, loss: 2.574906545760314e-07\n",
            "step: 7775, loss: 5.16827822139021e-06\n",
            "step: 7776, loss: 7.176376470852119e-07\n",
            "step: 7777, loss: 3.387832521184464e-06\n",
            "step: 7778, loss: 6.208112608874217e-06\n",
            "step: 7779, loss: 0.027296841144561768\n",
            "step: 7780, loss: 5.868297375855036e-05\n",
            "step: 7781, loss: 6.172322173370048e-06\n",
            "step: 7782, loss: 7.939271995383024e-07\n",
            "step: 7783, loss: 4.954197720508091e-06\n",
            "step: 7784, loss: 2.174346718675224e-06\n",
            "step: 7785, loss: 2.438980800434365e-06\n",
            "step: 7786, loss: 1.5663655403841403e-06\n",
            "step: 7787, loss: 1.1920856195501983e-06\n",
            "step: 7788, loss: 1.0704945907491492e-06\n",
            "step: 7789, loss: 6.723385013174266e-07\n",
            "step: 7790, loss: 2.2319669369608164e-05\n",
            "step: 7791, loss: 4.148475909460103e-07\n",
            "step: 7792, loss: 1.4448066849581664e-06\n",
            "step: 7793, loss: 7.343271590798395e-07\n",
            "step: 7794, loss: 1.746746238495689e-05\n",
            "step: 7795, loss: 3.0279113616416e-07\n",
            "step: 7796, loss: 1.9716849237738643e-06\n",
            "step: 7797, loss: 7.629358833582955e-07\n",
            "step: 7798, loss: 4.336635356594343e-06\n",
            "step: 7799, loss: 2.930129312517238e-06\n",
            "step: 7800, loss: 1.7475636013841722e-06\n",
            "step: 7801, loss: 1.7108808606280945e-05\n",
            "step: 7802, loss: 2.6928593797492795e-05\n",
            "step: 7803, loss: 5.485490419232519e-06\n",
            "step: 7804, loss: 1.0371154530730564e-06\n",
            "step: 7805, loss: 9.488997534390364e-07\n",
            "step: 7806, loss: 2.539064098527888e-06\n",
            "step: 7807, loss: 2.3292766400118126e-06\n",
            "step: 7808, loss: 1.9001435020982171e-06\n",
            "step: 7809, loss: 9.083710779123066e-07\n",
            "step: 7810, loss: 5.030622105550719e-07\n",
            "step: 7811, loss: 1.1634724614850711e-06\n",
            "step: 7812, loss: 2.0741852040373487e-06\n",
            "step: 7813, loss: 6.263072009460302e-06\n",
            "step: 7814, loss: 1.2658333616855089e-05\n",
            "step: 7815, loss: 8.25111328595085e-06\n",
            "step: 7816, loss: 6.008008313074242e-06\n",
            "step: 7817, loss: 1.0141159691556823e-05\n",
            "step: 7818, loss: 3.0189326935214922e-05\n",
            "step: 7819, loss: 3.576188191800611e-06\n",
            "step: 7820, loss: 4.0201070078182966e-05\n",
            "step: 7821, loss: 1.415866154275136e-05\n",
            "step: 7822, loss: 2.3125901861931197e-05\n",
            "step: 7823, loss: 2.4365168428630568e-05\n",
            "step: 7824, loss: 1.75388249772368e-05\n",
            "step: 7825, loss: 1.7186492186738178e-05\n",
            "step: 7826, loss: 0.06203960254788399\n",
            "step: 7827, loss: 0.00020212163508404046\n",
            "step: 7828, loss: 1.6874320863280445e-05\n",
            "step: 7829, loss: 2.919039070548024e-05\n",
            "step: 7830, loss: 9.885287727229297e-05\n",
            "step: 7831, loss: 1.1066918887081556e-05\n",
            "step: 7832, loss: 2.084429797832854e-05\n",
            "step: 7833, loss: 0.021698355674743652\n",
            "step: 7834, loss: 6.439561275328742e-06\n",
            "step: 7835, loss: 7.571860805910546e-06\n",
            "step: 7836, loss: 2.700629920582287e-05\n",
            "step: 7837, loss: 2.28129792958498e-05\n",
            "step: 7838, loss: 0.0001615828077774495\n",
            "step: 7839, loss: 2.9730531423410866e-06\n",
            "step: 7840, loss: 0.00011937248200410977\n",
            "step: 7841, loss: 5.435832918010419e-06\n",
            "step: 7842, loss: 1.6373887774534523e-05\n",
            "step: 7843, loss: 9.62908688961761e-06\n",
            "step: 7844, loss: 7.370306411758065e-05\n",
            "step: 7845, loss: 6.01518877374474e-06\n",
            "step: 7846, loss: 7.343171091633849e-06\n",
            "step: 7847, loss: 8.901511137082707e-06\n",
            "step: 7848, loss: 3.76695584236586e-06\n",
            "step: 7849, loss: 9.450174729863647e-06\n",
            "step: 7850, loss: 6.265129741223063e-06\n",
            "step: 7851, loss: 1.6647116353851743e-05\n",
            "step: 7852, loss: 6.131668214948149e-06\n",
            "step: 7853, loss: 3.666696102300193e-06\n",
            "step: 7854, loss: 8.654506586935895e-07\n",
            "step: 7855, loss: 8.153832595780841e-07\n",
            "step: 7856, loss: 2.667807166290004e-06\n",
            "step: 7857, loss: 1.1205660399582484e-07\n",
            "step: 7858, loss: 6.438868695113342e-06\n",
            "step: 7859, loss: 5.496676021721214e-05\n",
            "step: 7860, loss: 1.3540960935642943e-05\n",
            "step: 7861, loss: 2.539340675866697e-05\n",
            "step: 7862, loss: 5.887333827558905e-05\n",
            "step: 7863, loss: 1.4971203199820593e-05\n",
            "step: 7864, loss: 9.576723641657736e-06\n",
            "step: 7865, loss: 3.2829709653015016e-06\n",
            "step: 7866, loss: 5.516905730473809e-06\n",
            "step: 7867, loss: 9.107254300033674e-06\n",
            "step: 7868, loss: 3.1375166145153344e-05\n",
            "step: 7869, loss: 3.908664075424895e-05\n",
            "step: 7870, loss: 3.878978532156907e-05\n",
            "step: 7871, loss: 1.2614156730705872e-05\n",
            "step: 7872, loss: 3.6120018194196746e-06\n",
            "step: 7873, loss: 1.021492607833352e-05\n",
            "step: 7874, loss: 4.489119874051539e-06\n",
            "step: 7875, loss: 6.970707545406185e-06\n",
            "step: 7876, loss: 2.2697224721923703e-06\n",
            "step: 7877, loss: 1.170627342617081e-06\n",
            "step: 7878, loss: 0.18328753113746643\n",
            "step: 7879, loss: 2.96587563752837e-06\n",
            "step: 7880, loss: 1.8668019947654102e-06\n",
            "step: 7881, loss: 2.0837308056798065e-06\n",
            "step: 7882, loss: 4.150708718952956e-06\n",
            "step: 7883, loss: 9.450508514419198e-06\n",
            "step: 7884, loss: 9.939390110957902e-06\n",
            "step: 7885, loss: 4.560890829452546e-06\n",
            "step: 7886, loss: 1.3755538930126932e-05\n",
            "step: 7887, loss: 4.038724000565708e-06\n",
            "step: 7888, loss: 7.0401783887064084e-06\n",
            "step: 7889, loss: 1.0871859785765992e-06\n",
            "step: 7890, loss: 3.28535816151998e-06\n",
            "step: 7891, loss: 3.5500145258993143e-06\n",
            "step: 7892, loss: 5.1782576520054135e-06\n",
            "step: 7893, loss: 3.2567668313276954e-06\n",
            "step: 7894, loss: 3.509460384520935e-06\n",
            "step: 7895, loss: 1.3684062651009299e-05\n",
            "step: 7896, loss: 2.060109363810625e-05\n",
            "step: 7897, loss: 2.4056150778051233e-06\n",
            "step: 7898, loss: 1.6927518800002872e-06\n",
            "step: 7899, loss: 8.368448334294953e-07\n",
            "step: 7900, loss: 2.9086024824209744e-06\n",
            "step: 7901, loss: 2.803743427648442e-06\n",
            "step: 7902, loss: 2.1934476990281837e-07\n",
            "step: 7903, loss: 7.557848675787682e-07\n",
            "step: 7904, loss: 1.5186017662927043e-05\n",
            "step: 7905, loss: 7.750790973659605e-05\n",
            "step: 7906, loss: 2.0529769244603813e-05\n",
            "step: 7907, loss: 2.1433422716654604e-06\n",
            "step: 7908, loss: 1.8412545614410192e-05\n",
            "step: 7909, loss: 1.3935800780018326e-05\n",
            "step: 7910, loss: 4.48704759037355e-06\n",
            "step: 7911, loss: 1.647830504225567e-05\n",
            "step: 7912, loss: 6.594245405722177e-06\n",
            "step: 7913, loss: 5.5717141549394e-06\n",
            "step: 7914, loss: 1.1631829693214968e-05\n",
            "step: 7915, loss: 1.67812413565116e-05\n",
            "step: 7916, loss: 7.805344466760289e-06\n",
            "step: 7917, loss: 9.509848496236373e-06\n",
            "step: 7918, loss: 1.5923307728371583e-05\n",
            "step: 7919, loss: 8.935592632042244e-06\n",
            "step: 7920, loss: 0.03234497457742691\n",
            "step: 7921, loss: 0.00011880190868396312\n",
            "step: 7922, loss: 0.0001214607254951261\n",
            "step: 7923, loss: 0.03934500366449356\n",
            "step: 7924, loss: 5.758874613093212e-05\n",
            "step: 7925, loss: 2.0395791580085643e-05\n",
            "step: 7926, loss: 5.983453229418956e-05\n",
            "step: 7927, loss: 2.9040676963631995e-05\n",
            "step: 7928, loss: 0.06084073707461357\n",
            "step: 7929, loss: 0.061894189566373825\n",
            "step: 7930, loss: 2.734888403210789e-05\n",
            "step: 7931, loss: 1.6371379388147034e-05\n",
            "step: 7932, loss: 0.05190248042345047\n",
            "step: 7933, loss: 8.002863614819944e-05\n",
            "step: 7934, loss: 4.3902447941945866e-05\n",
            "step: 7935, loss: 0.0020334527362138033\n",
            "step: 7936, loss: 5.402171882451512e-05\n",
            "step: 7937, loss: 0.04325872287154198\n",
            "step: 7938, loss: 0.00023237902496475726\n",
            "step: 7939, loss: 0.06212048977613449\n",
            "step: 7940, loss: 3.540169564075768e-05\n",
            "step: 7941, loss: 1.565139609738253e-05\n",
            "step: 7942, loss: 1.219918249262264e-05\n",
            "step: 7943, loss: 1.284025620407192e-05\n",
            "step: 7944, loss: 5.6090928410412744e-05\n",
            "step: 7945, loss: 0.037661824375391006\n",
            "step: 7946, loss: 7.681795977987349e-05\n",
            "step: 7947, loss: 9.439943096367642e-05\n",
            "step: 7948, loss: 5.028273517382331e-05\n",
            "step: 7949, loss: 8.933482604334131e-05\n",
            "step: 7950, loss: 1.1994116903224494e-05\n",
            "step: 7951, loss: 1.4254024790716358e-05\n",
            "step: 7952, loss: 3.475774428807199e-05\n",
            "step: 7953, loss: 0.05355466902256012\n",
            "step: 7954, loss: 0.032691869884729385\n",
            "step: 7955, loss: 2.297620812896639e-05\n",
            "step: 7956, loss: 5.977088221698068e-05\n",
            "step: 7957, loss: 1.0473392649146263e-05\n",
            "step: 7958, loss: 2.156457230739761e-05\n",
            "step: 7959, loss: 1.937499655468855e-05\n",
            "step: 7960, loss: 1.290475938731106e-05\n",
            "step: 7961, loss: 0.00024840704281814396\n",
            "step: 7962, loss: 2.2065925804781727e-05\n",
            "step: 7963, loss: 8.628081559436396e-06\n",
            "step: 7964, loss: 2.746558493527118e-06\n",
            "step: 7965, loss: 1.409668675478315e-05\n",
            "step: 7966, loss: 1.3911837413616013e-05\n",
            "step: 7967, loss: 7.914707566669676e-06\n",
            "step: 7968, loss: 0.0001541130623081699\n",
            "step: 7969, loss: 3.235271378798643e-06\n",
            "step: 7970, loss: 4.932755473419093e-06\n",
            "step: 7971, loss: 7.700640708208084e-06\n",
            "step: 7972, loss: 0.03820963203907013\n",
            "step: 7973, loss: 5.333246008376591e-06\n",
            "step: 7974, loss: 1.31974920805078e-05\n",
            "step: 7975, loss: 6.625424703088356e-06\n",
            "step: 7976, loss: 3.704983100760728e-06\n",
            "step: 7977, loss: 5.485741439770209e-06\n",
            "step: 7978, loss: 1.161803629656788e-05\n",
            "step: 7979, loss: 5.420390152721666e-05\n",
            "step: 7980, loss: 2.9976828955113888e-05\n",
            "step: 7981, loss: 0.023632461205124855\n",
            "step: 7982, loss: 3.488782385829836e-05\n",
            "step: 7983, loss: 2.6662875825422816e-05\n",
            "step: 7984, loss: 9.548366506351158e-06\n",
            "step: 7985, loss: 0.02173796109855175\n",
            "step: 7986, loss: 0.034181952476501465\n",
            "step: 7987, loss: 1.1598698620218784e-05\n",
            "step: 7988, loss: 1.5847021131776273e-05\n",
            "step: 7989, loss: 1.941576920216903e-05\n",
            "step: 7990, loss: 0.06347284466028214\n",
            "step: 7991, loss: 1.1300998039587284e-06\n",
            "step: 7992, loss: 3.269711305620149e-05\n",
            "step: 7993, loss: 0.027071340009570122\n",
            "step: 7994, loss: 4.458159764908487e-06\n",
            "step: 7995, loss: 6.294233116932446e-07\n",
            "step: 7996, loss: 2.0884938294329913e-06\n",
            "step: 7997, loss: 2.047975613095332e-06\n",
            "step: 7998, loss: 2.837164174707141e-07\n",
            "step: 7999, loss: 1.0394982155048638e-06\n",
            "step: 8000, loss: 2.7894816412299406e-07\n",
            "step: 8001, loss: 5.00620399179752e-06\n",
            "step: 8002, loss: 8.130047604026913e-07\n",
            "step: 8003, loss: 3.206633209629217e-06\n",
            "step: 8004, loss: 5.259284080239013e-06\n",
            "step: 8005, loss: 0.027496451511979103\n",
            "step: 8006, loss: 5.4063330026110634e-05\n",
            "step: 8007, loss: 5.21395486430265e-06\n",
            "step: 8008, loss: 6.627992661378812e-07\n",
            "step: 8009, loss: 1.3160610023987829e-06\n",
            "step: 8010, loss: 1.8143443867302267e-06\n",
            "step: 8011, loss: 1.902552639876376e-06\n",
            "step: 8012, loss: 1.270737584491144e-06\n",
            "step: 8013, loss: 9.059871786121221e-07\n",
            "step: 8014, loss: 7.820105452083226e-07\n",
            "step: 8015, loss: 9.822788342717104e-07\n",
            "step: 8016, loss: 2.738532202783972e-05\n",
            "step: 8017, loss: 4.6253114760475e-07\n",
            "step: 8018, loss: 1.726137952573481e-06\n",
            "step: 8019, loss: 1.487711415393278e-06\n",
            "step: 8020, loss: 2.2310498025035486e-05\n",
            "step: 8021, loss: 4.601467367137957e-07\n",
            "step: 8022, loss: 2.026528591159149e-06\n",
            "step: 8023, loss: 9.131386491390003e-07\n",
            "step: 8024, loss: 5.0184376050310675e-06\n",
            "step: 8025, loss: 2.913444404839538e-06\n",
            "step: 8026, loss: 2.0884760942863068e-06\n",
            "step: 8027, loss: 1.3343836144485977e-05\n",
            "step: 8028, loss: 1.6512309230165556e-05\n",
            "step: 8029, loss: 2.4508697151759407e-06\n",
            "step: 8030, loss: 8.225412102547125e-07\n",
            "step: 8031, loss: 8.964480571194144e-07\n",
            "step: 8032, loss: 2.233909526694333e-06\n",
            "step: 8033, loss: 1.5473104895136203e-06\n",
            "step: 8034, loss: 1.7070301510102581e-06\n",
            "step: 8035, loss: 7.820103178346471e-07\n",
            "step: 8036, loss: 4.577627237267734e-07\n",
            "step: 8037, loss: 1.0061197599497973e-06\n",
            "step: 8038, loss: 5.793561399514147e-07\n",
            "step: 8039, loss: 5.4762895160820335e-06\n",
            "step: 8040, loss: 6.436888270400232e-06\n",
            "step: 8041, loss: 5.0755857046169695e-06\n",
            "step: 8042, loss: 2.434225962133496e-06\n",
            "step: 8043, loss: 5.550064543058397e-06\n",
            "step: 8044, loss: 1.4875266060698777e-05\n",
            "step: 8045, loss: 9.632053661334794e-07\n",
            "step: 8046, loss: 0.003081204602494836\n",
            "step: 8047, loss: 7.619565167260589e-06\n",
            "step: 8048, loss: 6.727790605509654e-06\n",
            "step: 8049, loss: 2.5749020551302237e-06\n",
            "step: 8050, loss: 2.0732160919578746e-05\n",
            "step: 8051, loss: 3.0146038625389338e-05\n",
            "step: 8052, loss: 0.069337859749794\n",
            "step: 8053, loss: 0.00025342125445604324\n",
            "step: 8054, loss: 1.5072062524268404e-05\n",
            "step: 8055, loss: 5.5003529269015417e-05\n",
            "step: 8056, loss: 7.44649296393618e-05\n",
            "step: 8057, loss: 1.1360169992258307e-05\n",
            "step: 8058, loss: 2.5306298994109966e-05\n",
            "step: 8059, loss: 0.024441571906208992\n",
            "step: 8060, loss: 1.3398059309110977e-05\n",
            "step: 8061, loss: 3.935398126486689e-05\n",
            "step: 8062, loss: 2.353678246436175e-05\n",
            "step: 8063, loss: 1.6732472431613132e-05\n",
            "step: 8064, loss: 0.00013233472418505698\n",
            "step: 8065, loss: 2.4151634079316864e-06\n",
            "step: 8066, loss: 6.918573490111157e-05\n",
            "step: 8067, loss: 4.799277121492196e-06\n",
            "step: 8068, loss: 1.4428930626309011e-05\n",
            "step: 8069, loss: 6.172488610900473e-06\n",
            "step: 8070, loss: 6.128070526756346e-05\n",
            "step: 8071, loss: 5.299953045323491e-06\n",
            "step: 8072, loss: 6.260785539780045e-06\n",
            "step: 8073, loss: 7.201953394542215e-06\n",
            "step: 8074, loss: 3.826564807241084e-06\n",
            "step: 8075, loss: 1.3649801076098811e-05\n",
            "step: 8076, loss: 1.1420683222240768e-05\n",
            "step: 8077, loss: 2.000191670958884e-05\n",
            "step: 8078, loss: 1.6391264580306597e-05\n",
            "step: 8079, loss: 5.106495336804073e-06\n",
            "step: 8080, loss: 8.225396754824033e-07\n",
            "step: 8081, loss: 1.2659891126531875e-06\n",
            "step: 8082, loss: 2.553401827753987e-06\n",
            "step: 8083, loss: 1.335142343350526e-07\n",
            "step: 8084, loss: 1.6630701793474145e-05\n",
            "step: 8085, loss: 4.858241300098598e-05\n",
            "step: 8086, loss: 1.3769887118542101e-05\n",
            "step: 8087, loss: 2.5048309908015653e-05\n",
            "step: 8088, loss: 6.004019087413326e-05\n",
            "step: 8089, loss: 1.9792758394032717e-05\n",
            "step: 8090, loss: 9.858073099167086e-06\n",
            "step: 8091, loss: 2.9491989153029863e-06\n",
            "step: 8092, loss: 5.097301709611202e-06\n",
            "step: 8093, loss: 8.578003871662077e-06\n",
            "step: 8094, loss: 2.9346761948545463e-05\n",
            "step: 8095, loss: 3.2025756809161976e-05\n",
            "step: 8096, loss: 3.500590173644014e-05\n",
            "step: 8097, loss: 1.0854811080207583e-05\n",
            "step: 8098, loss: 3.6691233162855497e-06\n",
            "step: 8099, loss: 6.291397312452318e-06\n",
            "step: 8100, loss: 1.8906063132817508e-06\n",
            "step: 8101, loss: 5.821633294544881e-06\n",
            "step: 8102, loss: 1.530637632640719e-06\n",
            "step: 8103, loss: 6.389582836163754e-07\n",
            "step: 8104, loss: 0.00010897781612584367\n",
            "step: 8105, loss: 2.074212488878402e-06\n",
            "step: 8106, loss: 1.707061642264307e-06\n",
            "step: 8107, loss: 2.1266291696520057e-06\n",
            "step: 8108, loss: 4.9230911827180535e-06\n",
            "step: 8109, loss: 1.1262392035860103e-05\n",
            "step: 8110, loss: 1.3541591215471271e-05\n",
            "step: 8111, loss: 5.185554527997738e-06\n",
            "step: 8112, loss: 1.3131158993928693e-05\n",
            "step: 8113, loss: 4.184160388831515e-06\n",
            "step: 8114, loss: 6.9043135226820596e-06\n",
            "step: 8115, loss: 1.4352746120493975e-06\n",
            "step: 8116, loss: 3.74788032786455e-06\n",
            "step: 8117, loss: 3.597700469981646e-06\n",
            "step: 8118, loss: 5.068638074590126e-06\n",
            "step: 8119, loss: 3.862331595883006e-06\n",
            "step: 8120, loss: 3.063635176658863e-06\n",
            "step: 8121, loss: 1.2663771485676989e-05\n",
            "step: 8122, loss: 1.8046472177957185e-05\n",
            "step: 8123, loss: 2.0479942577367183e-06\n",
            "step: 8124, loss: 1.4519540627588867e-06\n",
            "step: 8125, loss: 7.462466555807623e-07\n",
            "step: 8126, loss: 2.941993898275541e-06\n",
            "step: 8127, loss: 2.4747391762502957e-06\n",
            "step: 8128, loss: 1.9073461032803607e-07\n",
            "step: 8129, loss: 7.486323170269316e-07\n",
            "step: 8130, loss: 1.4478073353529908e-05\n",
            "step: 8131, loss: 9.275513730244711e-05\n",
            "step: 8132, loss: 1.9163991964887828e-05\n",
            "step: 8133, loss: 2.009833224292379e-06\n",
            "step: 8134, loss: 1.8262360754306428e-05\n",
            "step: 8135, loss: 1.1373780580470338e-05\n",
            "step: 8136, loss: 4.6677241698489524e-06\n",
            "step: 8137, loss: 1.4766737876925617e-05\n",
            "step: 8138, loss: 6.546547410835046e-06\n",
            "step: 8139, loss: 4.639537110051606e-06\n",
            "step: 8140, loss: 1.0406398359918967e-05\n",
            "step: 8141, loss: 1.677407999522984e-05\n",
            "step: 8142, loss: 7.090162853273796e-06\n",
            "step: 8143, loss: 8.477585652144626e-06\n",
            "step: 8144, loss: 1.4662477951787878e-05\n",
            "step: 8145, loss: 8.892676305549685e-06\n",
            "step: 8146, loss: 0.02451072260737419\n",
            "step: 8147, loss: 7.794908015057445e-05\n",
            "step: 8148, loss: 0.0001077978522516787\n",
            "step: 8149, loss: 0.034171611070632935\n",
            "step: 8150, loss: 5.6902848882600665e-05\n",
            "step: 8151, loss: 1.97260105778696e-05\n",
            "step: 8152, loss: 5.876145223737694e-05\n",
            "step: 8153, loss: 2.674045754247345e-05\n",
            "step: 8154, loss: 0.06023457646369934\n",
            "step: 8155, loss: 0.06285861879587173\n",
            "step: 8156, loss: 2.5401755920029245e-05\n",
            "step: 8157, loss: 1.3880175174563192e-05\n",
            "step: 8158, loss: 0.056843556463718414\n",
            "step: 8159, loss: 4.86627577629406e-05\n",
            "step: 8160, loss: 2.753485387074761e-05\n",
            "step: 8161, loss: 4.7172852646326646e-05\n",
            "step: 8162, loss: 5.642226824420504e-05\n",
            "step: 8163, loss: 0.0385582260787487\n",
            "step: 8164, loss: 0.00013828834926243871\n",
            "step: 8165, loss: 0.06288108229637146\n",
            "step: 8166, loss: 2.9647930205101147e-05\n",
            "step: 8167, loss: 1.2967091606697068e-05\n",
            "step: 8168, loss: 1.0258687325404026e-05\n",
            "step: 8169, loss: 1.035397781379288e-05\n",
            "step: 8170, loss: 3.1480438337894157e-05\n",
            "step: 8171, loss: 0.04324807599186897\n",
            "step: 8172, loss: 6.803448923164979e-05\n",
            "step: 8173, loss: 5.7897752412827685e-05\n",
            "step: 8174, loss: 3.645670221885666e-05\n",
            "step: 8175, loss: 6.004143870086409e-05\n",
            "step: 8176, loss: 9.3718172138324e-06\n",
            "step: 8177, loss: 1.0032130376202986e-05\n",
            "step: 8178, loss: 1.9466910089249723e-05\n",
            "step: 8179, loss: 0.13243618607521057\n",
            "step: 8180, loss: 0.03255508840084076\n",
            "step: 8181, loss: 1.8671227735467255e-05\n",
            "step: 8182, loss: 1.130991404352244e-05\n",
            "step: 8183, loss: 8.470801731164102e-06\n",
            "step: 8184, loss: 1.6437556041637436e-05\n",
            "step: 8185, loss: 1.627587334951386e-05\n",
            "step: 8186, loss: 1.0883284630835988e-05\n",
            "step: 8187, loss: 0.0002027766458922997\n",
            "step: 8188, loss: 1.9184191842214204e-05\n",
            "step: 8189, loss: 6.685071184620028e-06\n",
            "step: 8190, loss: 2.5367532998643583e-06\n",
            "step: 8191, loss: 1.0945214853563812e-05\n",
            "step: 8192, loss: 9.440595022169873e-06\n",
            "step: 8193, loss: 6.012492121953983e-06\n",
            "step: 8194, loss: 0.00013872486306354403\n",
            "step: 8195, loss: 2.4461305656586774e-06\n",
            "step: 8196, loss: 3.5118439427606063e-06\n",
            "step: 8197, loss: 4.4869557314086705e-06\n",
            "step: 8198, loss: 0.03736794367432594\n",
            "step: 8199, loss: 3.256733862144756e-06\n",
            "step: 8200, loss: 8.015063940547407e-06\n",
            "step: 8201, loss: 4.03871490561869e-06\n",
            "step: 8202, loss: 2.136216153303394e-06\n",
            "step: 8203, loss: 3.3854200864880113e-06\n",
            "step: 8204, loss: 6.886928986205021e-06\n",
            "step: 8205, loss: 4.277343032299541e-05\n",
            "step: 8206, loss: 2.3852320737205446e-05\n",
            "step: 8207, loss: 0.025740528479218483\n",
            "step: 8208, loss: 2.1597077648038976e-05\n",
            "step: 8209, loss: 2.1117928554303944e-05\n",
            "step: 8210, loss: 8.783114026300609e-06\n",
            "step: 8211, loss: 0.023403020575642586\n",
            "step: 8212, loss: 0.035690803080797195\n",
            "step: 8213, loss: 8.079816325334832e-06\n",
            "step: 8214, loss: 1.529384098830633e-05\n",
            "step: 8215, loss: 1.7003067114274018e-05\n",
            "step: 8216, loss: 0.0661672055721283\n",
            "step: 8217, loss: 1.1491734994706349e-06\n",
            "step: 8218, loss: 2.3523534764535725e-05\n",
            "step: 8219, loss: 0.026484934613108635\n",
            "step: 8220, loss: 3.850258963211672e-06\n",
            "step: 8221, loss: 7.53400399844395e-07\n",
            "step: 8222, loss: 2.300672576893703e-06\n",
            "step: 8223, loss: 1.9693002286658157e-06\n",
            "step: 8224, loss: 2.3841748486574943e-07\n",
            "step: 8225, loss: 1.1181750778632704e-06\n",
            "step: 8226, loss: 2.884847845052718e-07\n",
            "step: 8227, loss: 4.3411705519247334e-06\n",
            "step: 8228, loss: 9.250608172806096e-07\n",
            "step: 8229, loss: 3.0731282549822936e-06\n",
            "step: 8230, loss: 5.237826826487435e-06\n",
            "step: 8231, loss: 0.028740964829921722\n",
            "step: 8232, loss: 3.552526322891936e-05\n",
            "step: 8233, loss: 4.61559784525889e-06\n",
            "step: 8234, loss: 6.985620188970643e-07\n",
            "step: 8235, loss: 1.325597850154736e-06\n",
            "step: 8236, loss: 1.6450711655124906e-06\n",
            "step: 8237, loss: 1.8024188648269046e-06\n",
            "step: 8238, loss: 1.1872957657033112e-06\n",
            "step: 8239, loss: 7.343273864535149e-07\n",
            "step: 8240, loss: 2.4532375846320065e-06\n",
            "step: 8241, loss: 9.918160230881767e-07\n",
            "step: 8242, loss: 1.03468055385747e-05\n",
            "step: 8243, loss: 4.959096031598165e-07\n",
            "step: 8244, loss: 1.5687854784118827e-06\n",
            "step: 8245, loss: 1.1801616892626043e-06\n",
            "step: 8246, loss: 1.8158523744205013e-05\n",
            "step: 8247, loss: 4.816042178390489e-07\n",
            "step: 8248, loss: 2.0479844806686742e-06\n",
            "step: 8249, loss: 1.1277132898612763e-06\n",
            "step: 8250, loss: 6.331987606245093e-06\n",
            "step: 8251, loss: 3.182852879035636e-06\n",
            "step: 8252, loss: 1.7618667698116042e-06\n",
            "step: 8253, loss: 1.0569778169156052e-05\n",
            "step: 8254, loss: 1.1462064321676735e-05\n",
            "step: 8255, loss: 1.6307586747643654e-06\n",
            "step: 8256, loss: 6.794912223995198e-07\n",
            "step: 8257, loss: 8.416125183430267e-07\n",
            "step: 8258, loss: 1.847697149059968e-06\n",
            "step: 8259, loss: 1.4805546015850268e-06\n",
            "step: 8260, loss: 1.5401481050503207e-06\n",
            "step: 8261, loss: 7.510157047363464e-07\n",
            "step: 8262, loss: 4.744520367694349e-07\n",
            "step: 8263, loss: 8.130034530040575e-07\n",
            "step: 8264, loss: 5.173673116587452e-07\n",
            "step: 8265, loss: 3.3854207686090376e-06\n",
            "step: 8266, loss: 4.260357854946051e-06\n",
            "step: 8267, loss: 4.417510808707448e-06\n",
            "step: 8268, loss: 1.778580667632923e-06\n",
            "step: 8269, loss: 2.7727294309443096e-06\n",
            "step: 8270, loss: 7.876600648160093e-06\n",
            "step: 8271, loss: 4.5776246793138853e-07\n",
            "step: 8272, loss: 1.088733824872179e-05\n",
            "step: 8273, loss: 6.279675744735869e-06\n",
            "step: 8274, loss: 2.7798969313153066e-06\n",
            "step: 8275, loss: 1.516336055829015e-06\n",
            "step: 8276, loss: 1.1405071745684836e-05\n",
            "step: 8277, loss: 1.834013164625503e-05\n",
            "step: 8278, loss: 0.06785924732685089\n",
            "step: 8279, loss: 0.0001072433587978594\n",
            "step: 8280, loss: 8.413563591602724e-06\n",
            "step: 8281, loss: 3.521996404742822e-05\n",
            "step: 8282, loss: 4.302850356907584e-05\n",
            "step: 8283, loss: 9.095389941649046e-06\n",
            "step: 8284, loss: 1.4708979506394826e-05\n",
            "step: 8285, loss: 0.023435890674591064\n",
            "step: 8286, loss: 6.449090960813919e-06\n",
            "step: 8287, loss: 1.7366235624649562e-05\n",
            "step: 8288, loss: 2.0407200281624682e-05\n",
            "step: 8289, loss: 1.320668525295332e-05\n",
            "step: 8290, loss: 0.00011782078217947856\n",
            "step: 8291, loss: 2.1719795313401846e-06\n",
            "step: 8292, loss: 3.512812327244319e-05\n",
            "step: 8293, loss: 4.393977178551722e-06\n",
            "step: 8294, loss: 1.3399208000919316e-05\n",
            "step: 8295, loss: 4.672923751058988e-06\n",
            "step: 8296, loss: 5.4793305025668815e-05\n",
            "step: 8297, loss: 4.911338237434393e-06\n",
            "step: 8298, loss: 5.6146895985875744e-06\n",
            "step: 8299, loss: 5.9910089476034045e-06\n",
            "step: 8300, loss: 3.4355668958596652e-06\n",
            "step: 8301, loss: 9.693217180029023e-06\n",
            "step: 8302, loss: 2.1003722849854967e-06\n",
            "step: 8303, loss: 1.0117137207998894e-05\n",
            "step: 8304, loss: 6.134154773462797e-06\n",
            "step: 8305, loss: 3.316257561891689e-06\n",
            "step: 8306, loss: 5.793550599264563e-07\n",
            "step: 8307, loss: 1.2111495379940607e-06\n",
            "step: 8308, loss: 1.943076313182246e-06\n",
            "step: 8309, loss: 1.2874586730049487e-07\n",
            "step: 8310, loss: 1.1157936796735157e-06\n",
            "step: 8311, loss: 4.3384425225667655e-05\n",
            "step: 8312, loss: 0.0004070393624715507\n",
            "step: 8313, loss: 7.12001055944711e-05\n",
            "step: 8314, loss: 0.027585027739405632\n",
            "step: 8315, loss: 0.00024113651306834072\n",
            "step: 8316, loss: 0.0004084290994796902\n",
            "step: 8317, loss: 1.553133552079089e-05\n",
            "step: 8318, loss: 4.441640157892834e-06\n",
            "step: 8319, loss: 7.244801508932142e-06\n",
            "step: 8320, loss: 1.2928411706525367e-05\n",
            "step: 8321, loss: 0.00020751002011820674\n",
            "step: 8322, loss: 0.00025033700512722135\n",
            "step: 8323, loss: 1.98362522496609e-06\n",
            "step: 8324, loss: 2.090903763019014e-06\n",
            "step: 8325, loss: 6.3343368310597725e-06\n",
            "step: 8326, loss: 9.941974212779314e-07\n",
            "step: 8327, loss: 6.93955098540755e-06\n",
            "step: 8328, loss: 1.6713037211957271e-06\n",
            "step: 8329, loss: 6.151171874080319e-07\n",
            "step: 8330, loss: 0.00013036193558946252\n",
            "step: 8331, loss: 3.0254441298893653e-06\n",
            "step: 8332, loss: 1.6331545111825108e-06\n",
            "step: 8333, loss: 2.6511036139709176e-06\n",
            "step: 8334, loss: 5.828927896800451e-06\n",
            "step: 8335, loss: 9.483837857260369e-06\n",
            "step: 8336, loss: 9.584129657014273e-06\n",
            "step: 8337, loss: 3.385524678378715e-06\n",
            "step: 8338, loss: 1.082110611605458e-05\n",
            "step: 8339, loss: 3.766943109440035e-06\n",
            "step: 8340, loss: 6.8542071858246345e-06\n",
            "step: 8341, loss: 1.0371181815571617e-06\n",
            "step: 8342, loss: 3.535686118993908e-06\n",
            "step: 8343, loss: 3.0803435038251337e-06\n",
            "step: 8344, loss: 3.6119711239734897e-06\n",
            "step: 8345, loss: 2.8562251372932224e-06\n",
            "step: 8346, loss: 2.3936959223647136e-06\n",
            "step: 8347, loss: 1.1207210263819434e-05\n",
            "step: 8348, loss: 1.705934300844092e-05\n",
            "step: 8349, loss: 1.3828179135089158e-06\n",
            "step: 8350, loss: 1.1086373206126154e-06\n",
            "step: 8351, loss: 5.936597631261975e-07\n",
            "step: 8352, loss: 2.4151058823917992e-06\n",
            "step: 8353, loss: 1.864406954155129e-06\n",
            "step: 8354, loss: 1.4066682751945336e-07\n",
            "step: 8355, loss: 1.1014876690751407e-06\n",
            "step: 8356, loss: 1.605644320079591e-05\n",
            "step: 8357, loss: 5.931426858296618e-05\n",
            "step: 8358, loss: 1.561956560180988e-05\n",
            "step: 8359, loss: 5.6835770010366105e-06\n",
            "step: 8360, loss: 2.686194420675747e-05\n",
            "step: 8361, loss: 5.2868781494908035e-05\n",
            "step: 8362, loss: 5.850436082255328e-06\n",
            "step: 8363, loss: 1.551129753352143e-05\n",
            "step: 8364, loss: 0.0002764550154097378\n",
            "step: 8365, loss: 4.117281787330285e-05\n",
            "step: 8366, loss: 4.3781325075542554e-05\n",
            "step: 8367, loss: 0.00017237261636182666\n",
            "step: 8368, loss: 0.00020422815578058362\n",
            "step: 8369, loss: 3.519155870890245e-05\n",
            "step: 8370, loss: 4.279606946511194e-05\n",
            "step: 8371, loss: 6.085662971599959e-05\n",
            "step: 8372, loss: 0.03247027471661568\n",
            "step: 8373, loss: 8.877883374225348e-05\n",
            "step: 8374, loss: 0.01921692304313183\n",
            "step: 8375, loss: 0.04477657750248909\n",
            "step: 8376, loss: 5.9391968534328043e-05\n",
            "step: 8377, loss: 1.1436625754868146e-05\n",
            "step: 8378, loss: 1.9310284187668003e-05\n",
            "step: 8379, loss: 9.793659955903422e-06\n",
            "step: 8380, loss: 0.06121117249131203\n",
            "step: 8381, loss: 0.07608218491077423\n",
            "step: 8382, loss: 6.215447683644015e-06\n",
            "step: 8383, loss: 3.883769295498496e-06\n",
            "step: 8384, loss: 0.18646076321601868\n",
            "step: 8385, loss: 0.00010096049663843587\n",
            "step: 8386, loss: 0.00012084239278919995\n",
            "step: 8387, loss: 0.001009853440336883\n",
            "step: 8388, loss: 0.00044869192061014473\n",
            "step: 8389, loss: 0.040417563170194626\n",
            "step: 8390, loss: 0.00014429408474825323\n",
            "step: 8391, loss: 0.08012469112873077\n",
            "step: 8392, loss: 0.00011623625323409215\n",
            "step: 8393, loss: 0.00011080336116719991\n",
            "step: 8394, loss: 4.224582517053932e-05\n",
            "step: 8395, loss: 4.696892210631631e-05\n",
            "step: 8396, loss: 0.00019196217181161046\n",
            "step: 8397, loss: 0.04744676128029823\n",
            "step: 8398, loss: 7.491205906262621e-05\n",
            "step: 8399, loss: 0.0004871594428550452\n",
            "step: 8400, loss: 0.00033958826679736376\n",
            "step: 8401, loss: 0.00016577827045693994\n",
            "step: 8402, loss: 5.7902492699213326e-05\n",
            "step: 8403, loss: 1.3796144230582286e-05\n",
            "step: 8404, loss: 5.925962614128366e-05\n",
            "step: 8405, loss: 0.27274125814437866\n",
            "step: 8406, loss: 0.03490056097507477\n",
            "step: 8407, loss: 1.8568824089015834e-05\n",
            "step: 8408, loss: 3.440246291575022e-05\n",
            "step: 8409, loss: 3.5663477319758385e-05\n",
            "step: 8410, loss: 9.310344466939569e-05\n",
            "step: 8411, loss: 0.0001852654677350074\n",
            "step: 8412, loss: 0.008909541182219982\n",
            "step: 8413, loss: 0.0007356713758781552\n",
            "step: 8414, loss: 0.00017126269813161343\n",
            "step: 8415, loss: 5.9315138059901074e-05\n",
            "step: 8416, loss: 2.5880524844978936e-05\n",
            "step: 8417, loss: 6.2487752074957825e-06\n",
            "step: 8418, loss: 4.6965178626123816e-05\n",
            "step: 8419, loss: 5.690639227395877e-06\n",
            "step: 8420, loss: 0.00013144039257895201\n",
            "step: 8421, loss: 2.8275735530769452e-06\n",
            "step: 8422, loss: 6.61553622194333e-06\n",
            "step: 8423, loss: 5.1187507779104635e-06\n",
            "step: 8424, loss: 0.04017764702439308\n",
            "step: 8425, loss: 0.0013357010902836919\n",
            "step: 8426, loss: 6.625429250561865e-06\n",
            "step: 8427, loss: 4.6156469579727855e-06\n",
            "step: 8428, loss: 2.0646721168304794e-06\n",
            "step: 8429, loss: 1.1539308388819336e-06\n",
            "step: 8430, loss: 4.014661499240901e-06\n",
            "step: 8431, loss: 0.0001329804363194853\n",
            "step: 8432, loss: 5.799471909995191e-05\n",
            "step: 8433, loss: 0.02685515582561493\n",
            "step: 8434, loss: 0.00017496330838184804\n",
            "step: 8435, loss: 5.4870561143616214e-05\n",
            "step: 8436, loss: 2.4464652597089298e-05\n",
            "step: 8437, loss: 0.024291662499308586\n",
            "step: 8438, loss: 0.03640322759747505\n",
            "step: 8439, loss: 1.57558770297328e-05\n",
            "step: 8440, loss: 0.00020142212451901287\n",
            "step: 8441, loss: 0.00014749298861715943\n",
            "step: 8442, loss: 0.06846457719802856\n",
            "step: 8443, loss: 2.4938356091297464e-06\n",
            "step: 8444, loss: 0.00013528703129850328\n",
            "step: 8445, loss: 0.028023436665534973\n",
            "step: 8446, loss: 9.21877654036507e-06\n",
            "step: 8447, loss: 1.3923447568231495e-06\n",
            "step: 8448, loss: 9.382440475746989e-05\n",
            "step: 8449, loss: 1.9120832348562544e-06\n",
            "step: 8450, loss: 1.2874353387815063e-06\n",
            "step: 8451, loss: 6.875547114759684e-06\n",
            "step: 8452, loss: 1.0275600743625546e-06\n",
            "step: 8453, loss: 4.789540071215015e-06\n",
            "step: 8454, loss: 1.921621560541098e-06\n",
            "step: 8455, loss: 7.87864064477617e-06\n",
            "step: 8456, loss: 5.3260982895153575e-06\n",
            "step: 8457, loss: 0.029735300689935684\n",
            "step: 8458, loss: 0.010168067179620266\n",
            "step: 8459, loss: 2.224425315944245e-06\n",
            "step: 8460, loss: 3.2424833307231893e-07\n",
            "step: 8461, loss: 8.106182463052392e-07\n",
            "step: 8462, loss: 3.576268170490948e-07\n",
            "step: 8463, loss: 1.358983467980579e-07\n",
            "step: 8464, loss: 2.861005441445741e-07\n",
            "step: 8465, loss: 1.9073424084581347e-07\n",
            "step: 8466, loss: 5.245184979685291e-07\n",
            "step: 8467, loss: 9.209220479533542e-06\n",
            "step: 8468, loss: 0.00015304883709177375\n",
            "step: 8469, loss: 8.794341556495056e-05\n",
            "step: 8470, loss: 7.204715075204149e-06\n",
            "step: 8471, loss: 1.8311184248887002e-05\n",
            "step: 8472, loss: 0.00017582523287273943\n",
            "step: 8473, loss: 3.187520178471459e-06\n",
            "step: 8474, loss: 4.916062607662752e-06\n",
            "step: 8475, loss: 2.9429484129650518e-05\n",
            "step: 8476, loss: 0.10063591599464417\n",
            "step: 8477, loss: 1.0515888789086603e-05\n",
            "step: 8478, loss: 6.8058229771850165e-06\n",
            "step: 8479, loss: 6.125157960923389e-05\n",
            "step: 8480, loss: 6.874559767311439e-05\n",
            "step: 8481, loss: 3.366397322679404e-06\n",
            "step: 8482, loss: 9.298296390625183e-07\n",
            "step: 8483, loss: 3.8526814023498446e-06\n",
            "step: 8484, loss: 1.7952759208128555e-06\n",
            "step: 8485, loss: 7.4594590842025355e-06\n",
            "step: 8486, loss: 5.077820787846576e-06\n",
            "step: 8487, loss: 2.3483864879381144e-06\n",
            "step: 8488, loss: 4.7393550630658865e-06\n",
            "step: 8489, loss: 1.1477880434540566e-05\n",
            "step: 8490, loss: 2.6010536657850025e-06\n",
            "step: 8491, loss: 6.307474541245028e-05\n",
            "step: 8492, loss: 0.0002097978285746649\n",
            "step: 8493, loss: 0.0001117886058636941\n",
            "step: 8494, loss: 1.612990308785811e-05\n",
            "step: 8495, loss: 4.249140329193324e-05\n",
            "step: 8496, loss: 1.2777133633790072e-05\n",
            "step: 8497, loss: 4.386882892504218e-07\n",
            "step: 8498, loss: 1.4757021745026577e-05\n",
            "step: 8499, loss: 0.0035808151587843895\n",
            "step: 8500, loss: 1.8667983567866031e-06\n",
            "step: 8501, loss: 0.0006399229750968516\n",
            "step: 8502, loss: 4.073317177244462e-05\n",
            "step: 8503, loss: 0.00010473426664248109\n",
            "step: 8504, loss: 0.07152973860502243\n",
            "step: 8505, loss: 0.0009757174411788583\n",
            "step: 8506, loss: 9.621570643503219e-05\n",
            "step: 8507, loss: 0.0007496066973544657\n",
            "step: 8508, loss: 0.00013689228217117488\n",
            "step: 8509, loss: 4.249569610692561e-05\n",
            "step: 8510, loss: 9.951667743735015e-05\n",
            "step: 8511, loss: 0.02547825127840042\n",
            "step: 8512, loss: 4.469160921871662e-05\n",
            "step: 8513, loss: 7.546190317953005e-05\n",
            "step: 8514, loss: 1.7072447008104064e-05\n",
            "step: 8515, loss: 4.067345798830502e-06\n",
            "step: 8516, loss: 0.00020421341469045728\n",
            "step: 8517, loss: 2.6654615794541314e-06\n",
            "step: 8518, loss: 7.260459096869454e-05\n",
            "step: 8519, loss: 5.133022568770684e-06\n",
            "step: 8520, loss: 5.462078206619481e-06\n",
            "step: 8521, loss: 4.701476427726448e-06\n",
            "step: 8522, loss: 8.930075273383409e-05\n",
            "step: 8523, loss: 6.844747531431494e-06\n",
            "step: 8524, loss: 4.470295607461594e-06\n",
            "step: 8525, loss: 3.7835584407730494e-06\n",
            "step: 8526, loss: 5.335630248737289e-06\n",
            "step: 8527, loss: 0.0002598416176624596\n",
            "step: 8528, loss: 0.00011108480248367414\n",
            "step: 8529, loss: 0.0008658077567815781\n",
            "step: 8530, loss: 2.1694995666621253e-05\n",
            "step: 8531, loss: 2.5724832539708586e-06\n",
            "step: 8532, loss: 4.818254183192039e-06\n",
            "step: 8533, loss: 7.706070027779788e-05\n",
            "step: 8534, loss: 3.411629677430028e-06\n",
            "step: 8535, loss: 3.385529225852224e-07\n",
            "step: 8536, loss: 2.114701237587724e-05\n",
            "step: 8537, loss: 0.00014891706814523786\n",
            "step: 8538, loss: 4.9540711188456044e-05\n",
            "step: 8539, loss: 6.913465767866e-05\n",
            "step: 8540, loss: 7.050736167002469e-05\n",
            "step: 8541, loss: 0.0001872167777037248\n",
            "step: 8542, loss: 3.236642078263685e-05\n",
            "step: 8543, loss: 9.76226874627173e-05\n",
            "step: 8544, loss: 5.881034303456545e-05\n",
            "step: 8545, loss: 0.0005140474531799555\n",
            "step: 8546, loss: 0.00030348447035066783\n",
            "step: 8547, loss: 0.018109498545527458\n",
            "step: 8548, loss: 0.0036421630065888166\n",
            "step: 8549, loss: 0.00029500757227651775\n",
            "step: 8550, loss: 3.0993492146080825e-06\n",
            "step: 8551, loss: 0.024588650092482567\n",
            "step: 8552, loss: 4.386879197681992e-07\n",
            "step: 8553, loss: 0.010406735353171825\n",
            "step: 8554, loss: 2.498582489351975e-06\n",
            "step: 8555, loss: 2.09807680562335e-07\n",
            "step: 8556, loss: 8.193583926185966e-05\n",
            "step: 8557, loss: 1.1869788067997433e-05\n",
            "step: 8558, loss: 1.764292818506874e-07\n",
            "step: 8559, loss: 4.5775911416967574e-07\n",
            "step: 8560, loss: 5.054430971540569e-07\n",
            "step: 8561, loss: 3.200655191903934e-05\n",
            "step: 8562, loss: 3.9332295273197815e-05\n",
            "step: 8563, loss: 0.00014190144429448992\n",
            "step: 8564, loss: 8.739873010199517e-05\n",
            "step: 8565, loss: 1.0384553206677083e-05\n",
            "step: 8566, loss: 9.682856762083247e-05\n",
            "step: 8567, loss: 3.5976918297819793e-06\n",
            "step: 8568, loss: 1.8620371520228218e-06\n",
            "step: 8569, loss: 5.555058578465832e-06\n",
            "step: 8570, loss: 4.291475761419861e-06\n",
            "step: 8571, loss: 8.549105587007944e-06\n",
            "step: 8572, loss: 0.00011849161091959104\n",
            "step: 8573, loss: 0.00010452792776050046\n",
            "step: 8574, loss: 4.330889350967482e-05\n",
            "step: 8575, loss: 3.303284029243514e-05\n",
            "step: 8576, loss: 5.1485159929143265e-05\n",
            "step: 8577, loss: 9.669562132330611e-06\n",
            "step: 8578, loss: 0.00010077586193801835\n",
            "step: 8579, loss: 2.7996911740046926e-05\n",
            "step: 8580, loss: 1.3684968962479616e-06\n",
            "step: 8581, loss: 1.2802993296645582e-06\n",
            "step: 8582, loss: 9.510143172519747e-06\n",
            "step: 8583, loss: 0.0001259918208234012\n",
            "step: 8584, loss: 1.509975209046388e-05\n",
            "step: 8585, loss: 5.705031981051434e-06\n",
            "step: 8586, loss: 2.807912096614018e-05\n",
            "step: 8587, loss: 8.034491656871978e-06\n",
            "step: 8588, loss: 3.2931204714259366e-06\n",
            "step: 8589, loss: 0.000651836337056011\n",
            "step: 8590, loss: 5.610591688309796e-05\n",
            "step: 8591, loss: 5.062689888291061e-05\n",
            "step: 8592, loss: 6.212203879840672e-05\n",
            "step: 8593, loss: 0.00019526317191775888\n",
            "step: 8594, loss: 5.2146511734463274e-05\n",
            "step: 8595, loss: 0.00012223261001054198\n",
            "step: 8596, loss: 4.8324483941541985e-05\n",
            "step: 8597, loss: 0.00010555416520219296\n",
            "step: 8598, loss: 0.014675500802695751\n",
            "step: 8599, loss: 0.00046981035848148167\n",
            "step: 8600, loss: 0.007298718672245741\n",
            "step: 8601, loss: 0.07767806202173233\n",
            "step: 8602, loss: 0.0007987485732883215\n",
            "step: 8603, loss: 1.6726076864870265e-05\n",
            "step: 8604, loss: 7.554690091637895e-05\n",
            "step: 8605, loss: 8.839874499244615e-05\n",
            "step: 8606, loss: 0.0644533708691597\n",
            "step: 8607, loss: 0.060700830072164536\n",
            "step: 8608, loss: 8.018362132133916e-05\n",
            "step: 8609, loss: 2.8842550818808377e-05\n",
            "step: 8610, loss: 0.1160958781838417\n",
            "step: 8611, loss: 0.0018958642613142729\n",
            "step: 8612, loss: 0.00044889614218845963\n",
            "step: 8613, loss: 0.0003728809824679047\n",
            "step: 8614, loss: 0.0008583455346524715\n",
            "step: 8615, loss: 0.03791088983416557\n",
            "step: 8616, loss: 8.094855002127588e-05\n",
            "step: 8617, loss: 0.06872186064720154\n",
            "step: 8618, loss: 0.00047250965144485235\n",
            "step: 8619, loss: 3.4170127037214115e-05\n",
            "step: 8620, loss: 1.858437099144794e-05\n",
            "step: 8621, loss: 0.0001142593682743609\n",
            "step: 8622, loss: 0.021037068217992783\n",
            "step: 8623, loss: 0.055342406034469604\n",
            "step: 8624, loss: 0.0014639266300946474\n",
            "step: 8625, loss: 0.0042314687743783\n",
            "step: 8626, loss: 0.0004392661794554442\n",
            "step: 8627, loss: 0.0034956755116581917\n",
            "step: 8628, loss: 3.4633012546692044e-05\n",
            "step: 8629, loss: 0.00020769935508724302\n",
            "step: 8630, loss: 8.579803397879004e-05\n",
            "step: 8631, loss: 0.08142324537038803\n",
            "step: 8632, loss: 0.03496967628598213\n",
            "step: 8633, loss: 8.639591214887332e-06\n",
            "step: 8634, loss: 2.6210058422293514e-05\n",
            "step: 8635, loss: 3.7883935419813497e-06\n",
            "step: 8636, loss: 4.2532856241450645e-06\n",
            "step: 8637, loss: 5.1528717449400574e-05\n",
            "step: 8638, loss: 2.410001070529688e-05\n",
            "step: 8639, loss: 0.000445743091404438\n",
            "step: 8640, loss: 0.0009287864668294787\n",
            "step: 8641, loss: 1.7432626918889582e-05\n",
            "step: 8642, loss: 8.082365070549713e-07\n",
            "step: 8643, loss: 8.25594543130137e-06\n",
            "step: 8644, loss: 0.0033233952708542347\n",
            "step: 8645, loss: 9.127875273406971e-06\n",
            "step: 8646, loss: 7.287992048077285e-05\n",
            "step: 8647, loss: 6.181757271406241e-06\n",
            "step: 8648, loss: 4.19778298237361e-05\n",
            "step: 8649, loss: 1.1397776688681915e-05\n",
            "step: 8650, loss: 0.04376162588596344\n",
            "step: 8651, loss: 4.11542241636198e-05\n",
            "step: 8652, loss: 3.8956668504397385e-06\n",
            "step: 8653, loss: 6.324965397652704e-06\n",
            "step: 8654, loss: 1.7554677469888702e-05\n",
            "step: 8655, loss: 1.3685080375580583e-06\n",
            "step: 8656, loss: 7.662044481548946e-06\n",
            "step: 8657, loss: 9.288719593314454e-05\n",
            "step: 8658, loss: 8.350657299160957e-05\n",
            "step: 8659, loss: 0.38839051127433777\n",
            "step: 8660, loss: 5.318588955560699e-05\n",
            "step: 8661, loss: 0.00016447553934995085\n",
            "step: 8662, loss: 2.2721249479218386e-05\n",
            "step: 8663, loss: 0.02469446510076523\n",
            "step: 8664, loss: 0.04044071212410927\n",
            "step: 8665, loss: 2.056174707831815e-05\n",
            "step: 8666, loss: 0.20006956160068512\n",
            "step: 8667, loss: 3.099265450146049e-05\n",
            "step: 8668, loss: 0.05468924343585968\n",
            "step: 8669, loss: 1.127327595895622e-05\n",
            "step: 8670, loss: 1.3164646588847972e-05\n",
            "step: 8671, loss: 0.02631048485636711\n",
            "step: 8672, loss: 2.5833600375335664e-05\n",
            "step: 8673, loss: 2.0908958049403736e-06\n",
            "step: 8674, loss: 8.685114880790934e-05\n",
            "step: 8675, loss: 8.52526500239037e-06\n",
            "step: 8676, loss: 1.3661144748766674e-06\n",
            "step: 8677, loss: 6.892298188176937e-06\n",
            "step: 8678, loss: 5.245194643066498e-07\n",
            "step: 8679, loss: 6.146058240119601e-06\n",
            "step: 8680, loss: 7.061009455355816e-06\n",
            "step: 8681, loss: 1.3318848687049467e-05\n",
            "step: 8682, loss: 1.1646591701719444e-05\n",
            "step: 8683, loss: 0.031203150749206543\n",
            "step: 8684, loss: 0.010340261273086071\n",
            "step: 8685, loss: 1.246758893103106e-05\n",
            "step: 8686, loss: 4.982934456165822e-07\n",
            "step: 8687, loss: 5.075699391454691e-06\n",
            "step: 8688, loss: 8.753390829951968e-06\n",
            "step: 8689, loss: 3.9338843293990067e-07\n",
            "step: 8690, loss: 2.002710033366384e-07\n",
            "step: 8691, loss: 1.335143196001809e-07\n",
            "step: 8692, loss: 8.94155618880177e-06\n",
            "step: 8693, loss: 4.053114821545023e-08\n",
            "step: 8694, loss: 3.7277288356563076e-05\n",
            "step: 8695, loss: 1.978872745667104e-07\n",
            "step: 8696, loss: 0.0037919594906270504\n",
            "step: 8697, loss: 9.13276835490251e-06\n",
            "step: 8698, loss: 0.00010464166552992538\n",
            "step: 8699, loss: 6.937872853995941e-07\n",
            "step: 8700, loss: 0.0003976535808760673\n",
            "step: 8701, loss: 1.7166097165954852e-07\n",
            "step: 8702, loss: 1.0466487765370402e-06\n",
            "step: 8703, loss: 1.0704782198445173e-06\n",
            "step: 8704, loss: 2.3126085579860955e-06\n",
            "step: 8705, loss: 0.019499333575367928\n",
            "step: 8706, loss: 3.2675088732503355e-05\n",
            "step: 8707, loss: 1.099101837098715e-06\n",
            "step: 8708, loss: 4.3630470258904097e-07\n",
            "step: 8709, loss: 5.555117468247772e-07\n",
            "step: 8710, loss: 1.5258778773841186e-07\n",
            "step: 8711, loss: 3.3140059940706124e-07\n",
            "step: 8712, loss: 1.931186517367678e-07\n",
            "step: 8713, loss: 6.675713848380838e-08\n",
            "step: 8714, loss: 6.198879276553271e-08\n",
            "step: 8715, loss: 1.7404512675511796e-07\n",
            "step: 8716, loss: 9.059899497287915e-08\n",
            "step: 8717, loss: 7.1732465585228056e-06\n",
            "step: 8718, loss: 2.422232682874892e-06\n",
            "step: 8719, loss: 4.911373707727762e-07\n",
            "step: 8720, loss: 8.245939534390345e-05\n",
            "step: 8721, loss: 4.076931929830607e-07\n",
            "step: 8722, loss: 6.684748314000899e-06\n",
            "step: 8723, loss: 3.6001037528876623e-07\n",
            "step: 8724, loss: 1.6164334510904155e-06\n",
            "step: 8725, loss: 6.448777639889158e-06\n",
            "step: 8726, loss: 9.918132946040714e-07\n",
            "step: 8727, loss: 5.555131679102487e-07\n",
            "step: 8728, loss: 1.622157469682861e-05\n",
            "step: 8729, loss: 9.703168871055823e-06\n",
            "step: 8730, loss: 0.151978000998497\n",
            "step: 8731, loss: 0.0002440151001792401\n",
            "step: 8732, loss: 7.936563633847982e-06\n",
            "step: 8733, loss: 0.0008650294039398432\n",
            "step: 8734, loss: 2.9109511160640977e-05\n",
            "step: 8735, loss: 0.0007917890907265246\n",
            "step: 8736, loss: 0.021160418167710304\n",
            "step: 8737, loss: 0.025435568764805794\n",
            "step: 8738, loss: 0.0007727004121989012\n",
            "step: 8739, loss: 6.008109494359815e-07\n",
            "step: 8740, loss: 0.0830264538526535\n",
            "step: 8741, loss: 4.09833455705666e-06\n",
            "step: 8742, loss: 8.87293426785618e-05\n",
            "step: 8743, loss: 5.698191216652049e-07\n",
            "step: 8744, loss: 0.0018051464576274157\n",
            "step: 8745, loss: 6.151176989988016e-07\n",
            "step: 8746, loss: 6.055782364455808e-07\n",
            "step: 8747, loss: 1.0013575035827671e-07\n",
            "step: 8748, loss: 3.794657459366135e-05\n",
            "step: 8749, loss: 9.536737621829161e-08\n",
            "step: 8750, loss: 9.178936579701258e-07\n",
            "step: 8751, loss: 2.861022529998536e-08\n",
            "step: 8752, loss: 3.0179731766111217e-05\n",
            "step: 8753, loss: 0.08218009024858475\n",
            "step: 8754, loss: 0.3804093897342682\n",
            "step: 8755, loss: 0.9467170834541321\n",
            "step: 8756, loss: 4.910978896077722e-05\n",
            "step: 8757, loss: 2.130026405211538e-05\n",
            "step: 8758, loss: 6.008073683005932e-07\n",
            "step: 8759, loss: 5.340513666851621e-07\n",
            "step: 8760, loss: 4.031295702588977e-06\n",
            "step: 8761, loss: 7.15255632499634e-09\n",
            "step: 8762, loss: 2.38418573772492e-09\n",
            "step: 8763, loss: 8.010704277694458e-07\n",
            "step: 8764, loss: 4.806171091331635e-06\n",
            "step: 8765, loss: 0.014749845489859581\n",
            "step: 8766, loss: 1.2584138858073857e-05\n",
            "step: 8767, loss: 1.7827358533395454e-05\n",
            "step: 8768, loss: 1.5520838587690378e-06\n",
            "step: 8769, loss: 8.953311771620065e-05\n",
            "step: 8770, loss: 2.145684902643552e-06\n",
            "step: 8771, loss: 3.242485036025755e-07\n",
            "step: 8772, loss: 0.012966837733983994\n",
            "step: 8773, loss: 0.002763593103736639\n",
            "step: 8774, loss: 1.4853122820568387e-06\n",
            "step: 8775, loss: 0.041173871606588364\n",
            "step: 8776, loss: 0.619077205657959\n",
            "step: 8777, loss: 0.12409025430679321\n",
            "step: 8778, loss: 0.33606570959091187\n",
            "step: 8779, loss: 0.5332968235015869\n",
            "step: 8780, loss: 1.3160312164472998e-06\n",
            "step: 8781, loss: 2.38418573772492e-09\n",
            "step: 8782, loss: 0.00054059928515926\n",
            "step: 8783, loss: 1.6736286170271342e-06\n",
            "step: 8784, loss: 0.0\n",
            "step: 8785, loss: 4.76837103136063e-09\n",
            "step: 8786, loss: 3.8146950487316644e-08\n",
            "step: 8787, loss: 0.00015764590352773666\n",
            "step: 8788, loss: 0.0026729844976216555\n",
            "step: 8789, loss: 0.23065687716007233\n",
            "step: 8790, loss: 0.00359880062751472\n",
            "step: 8791, loss: 0.04783400148153305\n",
            "step: 8792, loss: 0.00357734109275043\n",
            "step: 8793, loss: 2.1885634851059876e-06\n",
            "step: 8794, loss: 7.646202720934525e-05\n",
            "step: 8795, loss: 6.127327196736587e-07\n",
            "step: 8796, loss: 0.0001546001003589481\n",
            "step: 8797, loss: 1.2159333095951297e-07\n",
            "step: 8798, loss: 0.9143362641334534\n",
            "step: 8799, loss: 2.367830991744995\n",
            "step: 8800, loss: 0.07795292139053345\n",
            "step: 8801, loss: 0.0016923442017287016\n",
            "step: 8802, loss: 0.04330744594335556\n",
            "step: 8803, loss: 0.0\n",
            "step: 8804, loss: 3.027686716450262e-06\n",
            "step: 8805, loss: 0.0\n",
            "step: 8806, loss: 0.0\n",
            "step: 8807, loss: 0.5990256667137146\n",
            "step: 8808, loss: 1.8996214866638184\n",
            "step: 8809, loss: 1.133392572402954\n",
            "step: 8810, loss: 0.0803014487028122\n",
            "step: 8811, loss: 0.3721756339073181\n",
            "step: 8812, loss: 6.743304402334616e-05\n",
            "step: 8813, loss: 2.8610209312773804e-08\n",
            "step: 8814, loss: 2.235172580355993e-08\n",
            "step: 8815, loss: 4.055394172668457\n",
            "step: 8816, loss: 0.3808809518814087\n",
            "step: 8817, loss: 0.00017772417049854994\n",
            "step: 8818, loss: 4.462730430532247e-06\n",
            "step: 8819, loss: 9.144640898739453e-06\n",
            "step: 8820, loss: 1.289802867177059e-06\n",
            "step: 8821, loss: 1.0967224284286203e-07\n",
            "step: 8822, loss: 0.0\n",
            "step: 8823, loss: 0.0\n",
            "step: 8824, loss: 0.2832352817058563\n",
            "step: 8825, loss: 1.342362880706787\n",
            "step: 8826, loss: 0.2186421900987625\n",
            "step: 8827, loss: 0.003738812170922756\n",
            "step: 8828, loss: 0.6842719316482544\n",
            "step: 8829, loss: 5.483623510826874e-08\n",
            "step: 8830, loss: 0.0\n",
            "step: 8831, loss: 1.907347702001516e-08\n",
            "step: 8832, loss: 4.967000495526008e-05\n",
            "step: 8833, loss: 5.96045985901128e-08\n",
            "step: 8834, loss: 0.0\n",
            "step: 8835, loss: 0.0\n",
            "step: 8836, loss: 6.238783359527588\n",
            "step: 8837, loss: 3.9148550033569336\n",
            "step: 8838, loss: 0.5556729435920715\n",
            "step: 8839, loss: 0.06528570502996445\n",
            "step: 8840, loss: 0.054872121661901474\n",
            "step: 8841, loss: 8.438171062152833e-05\n",
            "step: 8842, loss: 1.907348234908568e-08\n",
            "step: 8843, loss: 5.006783965200157e-08\n",
            "step: 8844, loss: 4.76837103136063e-09\n",
            "step: 8845, loss: 1.3112979502238886e-07\n",
            "step: 8846, loss: 0.0\n",
            "step: 8847, loss: 0.0\n",
            "step: 8848, loss: 13.395549774169922\n",
            "step: 8849, loss: 10.688689231872559\n",
            "step: 8850, loss: 3.0597198009490967\n",
            "step: 8851, loss: 0.770760715007782\n",
            "step: 8852, loss: 0.1844227910041809\n",
            "step: 8853, loss: 0.05186215788125992\n",
            "step: 8854, loss: 0.00012539539602585137\n",
            "step: 8855, loss: 6.937385478522629e-05\n",
            "step: 8856, loss: 0.031178202480077744\n",
            "step: 8857, loss: 5.2452033827421474e-08\n",
            "step: 8858, loss: 0.000107475949334912\n",
            "step: 8859, loss: 2.215409278869629\n",
            "step: 8860, loss: 13.967415809631348\n",
            "step: 8861, loss: 7.2683329582214355\n",
            "step: 8862, loss: 2.4472525119781494\n",
            "step: 8863, loss: 1.495345115661621\n",
            "step: 8864, loss: 0.07661274820566177\n",
            "step: 8865, loss: 0.06068959832191467\n",
            "step: 8866, loss: 7.890348933869973e-05\n",
            "step: 8867, loss: 3.337857279461787e-08\n",
            "step: 8868, loss: 0.0\n",
            "step: 8869, loss: 0.0\n",
            "step: 8870, loss: 0.0\n",
            "step: 8871, loss: 0.6411663293838501\n",
            "step: 8872, loss: 1.9279682636260986\n",
            "step: 8873, loss: 1.0966851711273193\n",
            "step: 8874, loss: 0.13263539969921112\n",
            "step: 8875, loss: 0.34632956981658936\n",
            "step: 8876, loss: 0.047254156321287155\n",
            "step: 8877, loss: 0.07957228273153305\n",
            "step: 8878, loss: 0.008265061303973198\n",
            "step: 8879, loss: 0.004859564360231161\n",
            "step: 8880, loss: 4.76837103136063e-09\n",
            "step: 8881, loss: 0.0\n",
            "step: 8882, loss: 1.1300231562927365e-05\n",
            "step: 8883, loss: 3.6405704021453857\n",
            "step: 8884, loss: 3.3237862586975098\n",
            "step: 8885, loss: 0.9032198190689087\n",
            "step: 8886, loss: 1.7499526739120483\n",
            "step: 8887, loss: 0.17919881641864777\n",
            "step: 8888, loss: 0.7288005352020264\n",
            "step: 8889, loss: 0.47935447096824646\n",
            "step: 8890, loss: 0.022386226803064346\n",
            "step: 8891, loss: 0.24717040359973907\n",
            "step: 8892, loss: 1.7642925342897797e-07\n",
            "step: 8893, loss: 4.76837147544984e-09\n",
            "step: 8894, loss: 1.5663486010453198e-06\n",
            "step: 8895, loss: 5.796926975250244\n",
            "step: 8896, loss: 2.3976073265075684\n",
            "step: 8897, loss: 1.7184853553771973\n",
            "step: 8898, loss: 0.43097588419914246\n",
            "step: 8899, loss: 0.16745810210704803\n",
            "step: 8900, loss: 0.00011813498713308945\n",
            "step: 8901, loss: 0.018177149817347527\n",
            "step: 8902, loss: 0.001177882426418364\n",
            "step: 8903, loss: 1.1133964790133177e-06\n",
            "step: 8904, loss: 2.38418573772492e-09\n",
            "step: 8905, loss: 0.0\n",
            "step: 8906, loss: 0.11515834927558899\n",
            "step: 8907, loss: 4.121857643127441\n",
            "step: 8908, loss: 2.006385326385498\n",
            "step: 8909, loss: 1.34905207157135\n",
            "step: 8910, loss: 0.5314776301383972\n",
            "step: 8911, loss: 0.10446994751691818\n",
            "step: 8912, loss: 0.00018363347044214606\n",
            "step: 8913, loss: 0.0011760389897972345\n",
            "step: 8914, loss: 2.384185116000026e-08\n",
            "step: 8915, loss: 3.814693627646193e-08\n",
            "step: 8916, loss: 0.0\n",
            "step: 8917, loss: 0.0\n",
            "step: 8918, loss: 0.05280093103647232\n",
            "step: 8919, loss: 3.0193185806274414\n",
            "step: 8920, loss: 1.6632651090621948\n",
            "step: 8921, loss: 0.7276308536529541\n",
            "step: 8922, loss: 0.035583026707172394\n",
            "step: 8923, loss: 1.2969696854270296e-06\n",
            "step: 8924, loss: 2.6187100957031362e-05\n",
            "step: 8925, loss: 9.53674206272126e-09\n",
            "step: 8926, loss: 7.557739536423469e-07\n",
            "step: 8927, loss: 7.096797344274819e-05\n",
            "step: 8928, loss: 0.0\n",
            "step: 8929, loss: 0.0\n",
            "step: 8930, loss: 0.5166040658950806\n",
            "step: 8931, loss: 1.6975278854370117\n",
            "step: 8932, loss: 0.2900959849357605\n",
            "step: 8933, loss: 0.24250845611095428\n",
            "step: 8934, loss: 0.015592051669955254\n",
            "step: 8935, loss: 0.001584492507390678\n",
            "step: 8936, loss: 1.5425091532961233e-06\n",
            "step: 8937, loss: 4.053074746934726e-07\n",
            "step: 8938, loss: 1.3123020835337229e-05\n",
            "step: 8939, loss: 0.0\n",
            "step: 8940, loss: 0.0\n",
            "step: 8941, loss: 4.76837103136063e-09\n",
            "step: 8942, loss: 5.923779826844111e-05\n",
            "step: 8943, loss: 0.31749287247657776\n",
            "step: 8944, loss: 0.04414212331175804\n",
            "step: 8945, loss: 0.08078659325838089\n",
            "step: 8946, loss: 0.139601469039917\n",
            "step: 8947, loss: 0.0747000053524971\n",
            "step: 8948, loss: 9.238976417691447e-06\n",
            "step: 8949, loss: 0.035864029079675674\n",
            "step: 8950, loss: 1.568016887176782e-05\n",
            "step: 8951, loss: 0.019514255225658417\n",
            "step: 8952, loss: 0.23483364284038544\n",
            "step: 8953, loss: 0.0\n",
            "step: 8954, loss: 1.7414056062698364\n",
            "step: 8955, loss: 1.6096389293670654\n",
            "step: 8956, loss: 1.2885135412216187\n",
            "step: 8957, loss: 0.45814746618270874\n",
            "step: 8958, loss: 0.004638071171939373\n",
            "step: 8959, loss: 0.15811513364315033\n",
            "step: 8960, loss: 0.07606703042984009\n",
            "step: 8961, loss: 0.0402347594499588\n",
            "step: 8962, loss: 5.960460924825384e-08\n",
            "step: 8963, loss: 0.02858823351562023\n",
            "step: 8964, loss: 4.5399865484796464e-05\n",
            "step: 8965, loss: 7.867804185934801e-08\n",
            "step: 8966, loss: 1.7559118270874023\n",
            "step: 8967, loss: 2.961221694946289\n",
            "step: 8968, loss: 1.0135986804962158\n",
            "step: 8969, loss: 0.43480297923088074\n",
            "step: 8970, loss: 0.3693482577800751\n",
            "step: 8971, loss: 0.042466823011636734\n",
            "step: 8972, loss: 0.23667874932289124\n",
            "step: 8973, loss: 0.03133585304021835\n",
            "step: 8974, loss: 0.0007872125715948641\n",
            "step: 8975, loss: 3.576275631189674e-08\n",
            "step: 8976, loss: 3.2827170798555017e-05\n",
            "step: 8977, loss: 0.0\n",
            "step: 8978, loss: 0.8735231161117554\n",
            "step: 8979, loss: 0.45968377590179443\n",
            "step: 8980, loss: 0.23136481642723083\n",
            "step: 8981, loss: 0.41513147950172424\n",
            "step: 8982, loss: 0.42149773240089417\n",
            "step: 8983, loss: 0.11267070472240448\n",
            "step: 8984, loss: 0.0007949232822284102\n",
            "step: 8985, loss: 0.2447696477174759\n",
            "step: 8986, loss: 0.001392729114741087\n",
            "step: 8987, loss: 0.43402099609375\n",
            "step: 8988, loss: 1.995463890125393e-06\n",
            "step: 8989, loss: 0.00010917850158875808\n",
            "step: 8990, loss: 0.3397100865840912\n",
            "step: 8991, loss: 0.08580799400806427\n",
            "step: 8992, loss: 0.7024068236351013\n",
            "step: 8993, loss: 0.4517613351345062\n",
            "step: 8994, loss: 0.14594197273254395\n",
            "step: 8995, loss: 0.0006935846759006381\n",
            "step: 8996, loss: 0.0002944643492810428\n",
            "step: 8997, loss: 3.4974289064848563e-06\n",
            "step: 8998, loss: 1.6784372292022454e-06\n",
            "step: 8999, loss: 8.249115239777893e-07\n",
            "step: 9000, loss: 0.015937304124236107\n",
            "step: 9001, loss: 0.000428052619099617\n",
            "step: 9002, loss: 0.4357527494430542\n",
            "step: 9003, loss: 0.14619092643260956\n",
            "step: 9004, loss: 0.06871697306632996\n",
            "step: 9005, loss: 0.713590145111084\n",
            "step: 9006, loss: 0.09092395752668381\n",
            "step: 9007, loss: 1.249681830406189\n",
            "step: 9008, loss: 0.5658648014068604\n",
            "step: 9009, loss: 0.556658923625946\n",
            "step: 9010, loss: 0.2364671677350998\n",
            "step: 9011, loss: 0.2591628432273865\n",
            "step: 9012, loss: 4.696816233717982e-07\n",
            "step: 9013, loss: 2.367877721786499\n",
            "step: 9014, loss: 1.246242642402649\n",
            "step: 9015, loss: 0.34404975175857544\n",
            "step: 9016, loss: 0.012386050075292587\n",
            "step: 9017, loss: 0.0005378637579269707\n",
            "step: 9018, loss: 0.07643603533506393\n",
            "step: 9019, loss: 2.9085138066875516e-06\n",
            "step: 9020, loss: 0.06057184562087059\n",
            "step: 9021, loss: 0.000968675478361547\n",
            "step: 9022, loss: 3.33785834527589e-08\n",
            "step: 9023, loss: 0.0632084384560585\n",
            "step: 9024, loss: 0.18988846242427826\n",
            "step: 9025, loss: 0.6668256521224976\n",
            "step: 9026, loss: 0.8449094891548157\n",
            "step: 9027, loss: 1.0150893926620483\n",
            "step: 9028, loss: 0.3306937515735626\n",
            "step: 9029, loss: 0.5465071797370911\n",
            "step: 9030, loss: 0.08709271252155304\n",
            "step: 9031, loss: 0.11961541324853897\n",
            "step: 9032, loss: 8.153757562467945e-07\n",
            "step: 9033, loss: 0.2338332235813141\n",
            "step: 9034, loss: 0.7335659861564636\n",
            "step: 9035, loss: 3.0778238773345947\n",
            "step: 9036, loss: 1.7851654291152954\n",
            "step: 9037, loss: 1.046332836151123\n",
            "step: 9038, loss: 0.42540037631988525\n",
            "step: 9039, loss: 0.0014939557295292616\n",
            "step: 9040, loss: 0.7145290374755859\n",
            "step: 9041, loss: 2.4893665313720703\n",
            "step: 9042, loss: 1.3071497678756714\n",
            "step: 9043, loss: 0.00608305586501956\n",
            "step: 9044, loss: 0.8506649732589722\n",
            "step: 9045, loss: 1.0774643421173096\n",
            "step: 9046, loss: 2.1960761547088623\n",
            "step: 9047, loss: 1.145634412765503\n",
            "step: 9048, loss: 1.1289280652999878\n",
            "step: 9049, loss: 0.8912060260772705\n",
            "step: 9050, loss: 2.890509605407715\n",
            "step: 9051, loss: 2.5804708003997803\n",
            "step: 9052, loss: 3.1757843494415283\n",
            "step: 9053, loss: 1.088694453239441\n",
            "step: 9054, loss: 0.615573525428772\n",
            "step: 9055, loss: 0.0025072928983718157\n",
            "step: 9056, loss: 0.1272336095571518\n",
            "step: 9057, loss: 0.17087703943252563\n",
            "step: 9058, loss: 0.02569013647735119\n",
            "step: 9059, loss: 0.18613795936107635\n",
            "step: 9060, loss: 1.7881328062685498e-07\n",
            "step: 9061, loss: 0.0927615612745285\n",
            "step: 9062, loss: 6.567807197570801\n",
            "step: 9063, loss: 7.8114914894104\n",
            "step: 9064, loss: 5.093143939971924\n",
            "step: 9065, loss: 4.492560863494873\n",
            "step: 9066, loss: 3.4640774726867676\n",
            "step: 9067, loss: 1.9442194700241089\n",
            "step: 9068, loss: 0.5740180611610413\n",
            "step: 9069, loss: 0.27620837092399597\n",
            "step: 9070, loss: 0.10663607716560364\n",
            "step: 9071, loss: 0.13907451927661896\n",
            "step: 9072, loss: 0.015307948924601078\n",
            "step: 9073, loss: 0.016122734174132347\n",
            "step: 9074, loss: 7.7869391441345215\n",
            "step: 9075, loss: 8.875072479248047\n",
            "step: 9076, loss: 3.5616729259490967\n",
            "step: 9077, loss: 5.186469554901123\n",
            "step: 9078, loss: 4.305103302001953\n",
            "step: 9079, loss: 2.3436965942382812\n",
            "step: 9080, loss: 2.479844093322754\n",
            "step: 9081, loss: 1.0731439590454102\n",
            "step: 9082, loss: 1.3240963220596313\n",
            "step: 9083, loss: 0.8162904977798462\n",
            "step: 9084, loss: 0.5262424349784851\n",
            "step: 9085, loss: 1.1318479776382446\n",
            "step: 9086, loss: 4.9808125495910645\n",
            "step: 9087, loss: 3.174269437789917\n",
            "step: 9088, loss: 4.815596580505371\n",
            "step: 9089, loss: 4.856991291046143\n",
            "step: 9090, loss: 4.224616527557373\n",
            "step: 9091, loss: 5.503747463226318\n",
            "step: 9092, loss: 3.7849419116973877\n",
            "step: 9093, loss: 0.7460564374923706\n",
            "step: 9094, loss: 0.17361721396446228\n",
            "step: 9095, loss: 0.04077371209859848\n",
            "step: 9096, loss: 0.2928595542907715\n",
            "step: 9097, loss: 1.8435108661651611\n",
            "step: 9098, loss: 2.8397529125213623\n",
            "step: 9099, loss: 2.641566276550293\n",
            "step: 9100, loss: 1.3238486051559448\n",
            "step: 9101, loss: 0.8616461157798767\n",
            "step: 9102, loss: 0.22883158922195435\n",
            "step: 9103, loss: 0.47245869040489197\n",
            "step: 9104, loss: 0.003192188451066613\n",
            "step: 9105, loss: 0.22915153205394745\n",
            "step: 9106, loss: 0.005747465416789055\n",
            "step: 9107, loss: 0.0390409454703331\n",
            "step: 9108, loss: 0.05346454307436943\n",
            "step: 9109, loss: 1.1771442890167236\n",
            "step: 9110, loss: 5.784524440765381\n",
            "step: 9111, loss: 4.799916744232178\n",
            "step: 9112, loss: 2.3722972869873047\n",
            "step: 9113, loss: 4.608943939208984\n",
            "step: 9114, loss: 2.1565492153167725\n",
            "step: 9115, loss: 3.3954052925109863\n",
            "step: 9116, loss: 1.419501781463623\n",
            "step: 9117, loss: 1.092024803161621\n",
            "step: 9118, loss: 0.9946361780166626\n",
            "step: 9119, loss: 0.269682377576828\n",
            "step: 9120, loss: 0.06510548293590546\n",
            "step: 9121, loss: 0.47729477286338806\n",
            "step: 9122, loss: 0.02006383240222931\n",
            "step: 9123, loss: 0.352508544921875\n",
            "step: 9124, loss: 0.8405780792236328\n",
            "step: 9125, loss: 3.0196192264556885\n",
            "step: 9126, loss: 0.7384347319602966\n",
            "step: 9127, loss: 0.06356794387102127\n",
            "step: 9128, loss: 0.10147283226251602\n",
            "step: 9129, loss: 0.7004585266113281\n",
            "step: 9130, loss: 0.17490899562835693\n",
            "step: 9131, loss: 0.502770721912384\n",
            "step: 9132, loss: 0.17806483805179596\n",
            "step: 9133, loss: 0.1362275630235672\n",
            "step: 9134, loss: 0.7659773230552673\n",
            "step: 9135, loss: 0.5678014755249023\n",
            "step: 9136, loss: 0.514764130115509\n",
            "step: 9137, loss: 0.6617098450660706\n",
            "step: 9138, loss: 0.5629551410675049\n",
            "step: 9139, loss: 0.9536008238792419\n",
            "step: 9140, loss: 0.22524383664131165\n",
            "step: 9141, loss: 1.5457791090011597\n",
            "step: 9142, loss: 0.0031572370789945126\n",
            "step: 9143, loss: 0.4622272849082947\n",
            "step: 9144, loss: 0.22165967524051666\n",
            "step: 9145, loss: 1.5323704481124878\n",
            "step: 9146, loss: 0.8873805999755859\n",
            "step: 9147, loss: 0.26324915885925293\n",
            "step: 9148, loss: 0.36651507019996643\n",
            "step: 9149, loss: 0.38677695393562317\n",
            "step: 9150, loss: 1.1511163711547852\n",
            "step: 9151, loss: 0.4062977135181427\n",
            "step: 9152, loss: 0.13952726125717163\n",
            "step: 9153, loss: 0.2356947511434555\n",
            "step: 9154, loss: 0.16536393761634827\n",
            "step: 9155, loss: 0.32789146900177\n",
            "step: 9156, loss: 0.06225307285785675\n",
            "step: 9157, loss: 0.0020254559349268675\n",
            "step: 9158, loss: 0.7346557378768921\n",
            "step: 9159, loss: 0.15082091093063354\n",
            "step: 9160, loss: 0.0004122795653529465\n",
            "step: 9161, loss: 0.4924747049808502\n",
            "step: 9162, loss: 0.11877016723155975\n",
            "step: 9163, loss: 0.1489744335412979\n",
            "step: 9164, loss: 0.034635916352272034\n",
            "step: 9165, loss: 0.9918981790542603\n",
            "step: 9166, loss: 0.21691244840621948\n",
            "step: 9167, loss: 0.6404513716697693\n",
            "step: 9168, loss: 0.06521191447973251\n",
            "step: 9169, loss: 0.28056010603904724\n",
            "step: 9170, loss: 0.0009302122052758932\n",
            "step: 9171, loss: 0.21241261065006256\n",
            "step: 9172, loss: 0.3261604309082031\n",
            "step: 9173, loss: 0.36946141719818115\n",
            "step: 9174, loss: 2.286351445945911e-06\n",
            "step: 9175, loss: 0.09729211777448654\n",
            "step: 9176, loss: 0.21045233309268951\n",
            "step: 9177, loss: 0.08520908653736115\n",
            "step: 9178, loss: 0.1597386598587036\n",
            "step: 9179, loss: 0.015489700250327587\n",
            "step: 9180, loss: 0.3943076431751251\n",
            "step: 9181, loss: 0.4766802489757538\n",
            "step: 9182, loss: 0.9117316603660583\n",
            "step: 9183, loss: 1.5397820472717285\n",
            "step: 9184, loss: 0.9278332591056824\n",
            "step: 9185, loss: 0.5861336588859558\n",
            "step: 9186, loss: 0.8240618705749512\n",
            "step: 9187, loss: 0.9483080506324768\n",
            "step: 9188, loss: 0.4512665867805481\n",
            "step: 9189, loss: 0.432719886302948\n",
            "step: 9190, loss: 0.44498521089553833\n",
            "step: 9191, loss: 0.9112036228179932\n",
            "step: 9192, loss: 0.3546803295612335\n",
            "step: 9193, loss: 0.27984777092933655\n",
            "step: 9194, loss: 0.0015348941087722778\n",
            "step: 9195, loss: 0.021573465317487717\n",
            "step: 9196, loss: 0.5721222162246704\n",
            "step: 9197, loss: 0.04552720487117767\n",
            "step: 9198, loss: 0.217966228723526\n",
            "step: 9199, loss: 0.23939622938632965\n",
            "step: 9200, loss: 0.26044848561286926\n",
            "step: 9201, loss: 0.4027690887451172\n",
            "step: 9202, loss: 0.5528832077980042\n",
            "step: 9203, loss: 0.0013335238909348845\n",
            "step: 9204, loss: 0.00017102935817092657\n",
            "step: 9205, loss: 0.08979775756597519\n",
            "step: 9206, loss: 0.06658770143985748\n",
            "step: 9207, loss: 0.6973697543144226\n",
            "step: 9208, loss: 0.830768883228302\n",
            "step: 9209, loss: 1.1917240619659424\n",
            "step: 9210, loss: 0.1984338015317917\n",
            "step: 9211, loss: 0.2830852270126343\n",
            "step: 9212, loss: 0.0722980797290802\n",
            "step: 9213, loss: 0.3442858159542084\n",
            "step: 9214, loss: 0.3643283545970917\n",
            "step: 9215, loss: 0.0018092645332217216\n",
            "step: 9216, loss: 0.8163214325904846\n",
            "step: 9217, loss: 0.4618806838989258\n",
            "step: 9218, loss: 1.3050074577331543\n",
            "step: 9219, loss: 1.0668206214904785\n",
            "step: 9220, loss: 0.4422263205051422\n",
            "step: 9221, loss: 0.16123811900615692\n",
            "step: 9222, loss: 0.68597412109375\n",
            "step: 9223, loss: 0.02522226609289646\n",
            "step: 9224, loss: 0.43353644013404846\n",
            "step: 9225, loss: 1.7169362763524987e-05\n",
            "step: 9226, loss: 0.0005313948495313525\n",
            "step: 9227, loss: 0.006465088110417128\n",
            "step: 9228, loss: 0.15264993906021118\n",
            "step: 9229, loss: 0.1859157681465149\n",
            "step: 9230, loss: 0.12688474357128143\n",
            "step: 9231, loss: 0.40463557839393616\n",
            "step: 9232, loss: 0.23502622544765472\n",
            "step: 9233, loss: 0.7018470764160156\n",
            "step: 9234, loss: 0.6969980001449585\n",
            "step: 9235, loss: 0.000510051439050585\n",
            "step: 9236, loss: 1.5020349053429527e-07\n",
            "step: 9237, loss: 0.00039587568608112633\n",
            "step: 9238, loss: 0.13667553663253784\n",
            "step: 9239, loss: 0.0005367517587728798\n",
            "step: 9240, loss: 9.596431482350454e-06\n",
            "step: 9241, loss: 0.03196437656879425\n",
            "step: 9242, loss: 0.00011672681284835562\n",
            "step: 9243, loss: 0.002404620870947838\n",
            "step: 9244, loss: 0.09082190692424774\n",
            "step: 9245, loss: 0.24850936233997345\n",
            "step: 9246, loss: 0.40535271167755127\n",
            "step: 9247, loss: 0.03687296807765961\n",
            "step: 9248, loss: 0.021588515490293503\n",
            "step: 9249, loss: 0.12553223967552185\n",
            "step: 9250, loss: 0.13984471559524536\n",
            "step: 9251, loss: 0.291485071182251\n",
            "step: 9252, loss: 0.5685161352157593\n",
            "step: 9253, loss: 1.016281247138977\n",
            "step: 9254, loss: 1.2944824695587158\n",
            "step: 9255, loss: 0.1471957266330719\n",
            "step: 9256, loss: 1.1380993127822876\n",
            "step: 9257, loss: 1.3183488845825195\n",
            "step: 9258, loss: 0.08694039285182953\n",
            "step: 9259, loss: 0.04934864118695259\n",
            "step: 9260, loss: 0.41047433018684387\n",
            "step: 9261, loss: 0.8041569590568542\n",
            "step: 9262, loss: 0.2721632122993469\n",
            "step: 9263, loss: 0.526461660861969\n",
            "step: 9264, loss: 0.8708555102348328\n",
            "step: 9265, loss: 0.7161284685134888\n",
            "step: 9266, loss: 0.6784026026725769\n",
            "step: 9267, loss: 0.2522585391998291\n",
            "step: 9268, loss: 0.23311465978622437\n",
            "step: 9269, loss: 0.14636841416358948\n",
            "step: 9270, loss: 0.08844217658042908\n",
            "step: 9271, loss: 0.5727773308753967\n",
            "step: 9272, loss: 0.00017182774899993092\n",
            "step: 9273, loss: 0.656614363193512\n",
            "step: 9274, loss: 0.5271415114402771\n",
            "step: 9275, loss: 0.9215430617332458\n",
            "step: 9276, loss: 0.7485803365707397\n",
            "step: 9277, loss: 0.652071475982666\n",
            "step: 9278, loss: 1.2939451932907104\n",
            "step: 9279, loss: 0.8205440044403076\n",
            "step: 9280, loss: 1.4861987829208374\n",
            "step: 9281, loss: 2.1731526851654053\n",
            "step: 9282, loss: 1.4116990566253662\n",
            "step: 9283, loss: 1.2757048606872559\n",
            "step: 9284, loss: 0.8480544090270996\n",
            "step: 9285, loss: 1.7970188856124878\n",
            "step: 9286, loss: 1.468562364578247\n",
            "step: 9287, loss: 0.314759224653244\n",
            "step: 9288, loss: 0.709449291229248\n",
            "step: 9289, loss: 1.3899949789047241\n",
            "step: 9290, loss: 1.2730807065963745\n",
            "step: 9291, loss: 0.6626150608062744\n",
            "step: 9292, loss: 0.35220515727996826\n",
            "step: 9293, loss: 0.8538751006126404\n",
            "step: 9294, loss: 0.9899595379829407\n",
            "step: 9295, loss: 1.663503885269165\n",
            "step: 9296, loss: 2.4644429683685303\n",
            "step: 9297, loss: 0.9333716630935669\n",
            "step: 9298, loss: 1.4288873672485352\n",
            "step: 9299, loss: 1.0379996299743652\n",
            "step: 9300, loss: 0.7921425104141235\n",
            "step: 9301, loss: 1.2961890697479248\n",
            "step: 9302, loss: 0.22373849153518677\n",
            "step: 9303, loss: 0.9262549877166748\n",
            "step: 9304, loss: 0.7999818921089172\n",
            "step: 9305, loss: 2.1975009441375732\n",
            "step: 9306, loss: 1.0206724405288696\n",
            "step: 9307, loss: 0.6987805962562561\n",
            "step: 9308, loss: 1.1053595542907715\n",
            "step: 9309, loss: 2.4879467487335205\n",
            "step: 9310, loss: 2.600701093673706\n",
            "step: 9311, loss: 0.7977221608161926\n",
            "step: 9312, loss: 0.11677787452936172\n",
            "step: 9313, loss: 0.006294780410826206\n",
            "step: 9314, loss: 0.12852267920970917\n",
            "step: 9315, loss: 4.001380511908792e-05\n",
            "step: 9316, loss: 0.29102757573127747\n",
            "step: 9317, loss: 0.4707486033439636\n",
            "step: 9318, loss: 1.3084582090377808\n",
            "step: 9319, loss: 0.009443237446248531\n",
            "step: 9320, loss: 1.2636566162109375\n",
            "step: 9321, loss: 0.9792102575302124\n",
            "step: 9322, loss: 0.7378668785095215\n",
            "step: 9323, loss: 0.9993265271186829\n",
            "step: 9324, loss: 0.8678098917007446\n",
            "step: 9325, loss: 2.8908777236938477\n",
            "step: 9326, loss: 0.8649183511734009\n",
            "step: 9327, loss: 0.9067325592041016\n",
            "step: 9328, loss: 0.49216315150260925\n",
            "step: 9329, loss: 0.774598240852356\n",
            "step: 9330, loss: 0.3178006112575531\n",
            "step: 9331, loss: 0.663003146648407\n",
            "step: 9332, loss: 0.7737259864807129\n",
            "step: 9333, loss: 0.4194519817829132\n",
            "step: 9334, loss: 0.3544975221157074\n",
            "step: 9335, loss: 5.08308219909668\n",
            "step: 9336, loss: 5.937655448913574\n",
            "step: 9337, loss: 8.534980773925781\n",
            "step: 9338, loss: 2.7217788696289062\n",
            "step: 9339, loss: 3.3294012546539307\n",
            "step: 9340, loss: 0.9246308207511902\n",
            "step: 9341, loss: 1.2301448583602905\n",
            "step: 9342, loss: 1.1299681663513184\n",
            "step: 9343, loss: 0.3738337755203247\n",
            "step: 9344, loss: 0.6291526556015015\n",
            "step: 9345, loss: 0.2941524386405945\n",
            "step: 9346, loss: 0.6983986496925354\n",
            "step: 9347, loss: 0.23896443843841553\n",
            "step: 9348, loss: 0.036600738763809204\n",
            "step: 9349, loss: 0.4194101393222809\n",
            "step: 9350, loss: 0.4734423756599426\n",
            "step: 9351, loss: 0.4649481177330017\n",
            "step: 9352, loss: 0.027380559593439102\n",
            "step: 9353, loss: 0.6188504099845886\n",
            "step: 9354, loss: 0.06304604560136795\n",
            "step: 9355, loss: 0.14612628519535065\n",
            "step: 9356, loss: 0.081013984978199\n",
            "step: 9357, loss: 0.03401616960763931\n",
            "step: 9358, loss: 0.10292016714811325\n",
            "step: 9359, loss: 1.668929350273629e-08\n",
            "step: 9360, loss: 0.0064581711776554585\n",
            "step: 9361, loss: 0.13961286842823029\n",
            "step: 9362, loss: 3.5274621041025966e-05\n",
            "step: 9363, loss: 0.0001311288506258279\n",
            "step: 9364, loss: 0.0\n",
            "step: 9365, loss: 0.15085847675800323\n",
            "step: 9366, loss: 0.00021086959168314934\n",
            "step: 9367, loss: 4.6968270339675655e-07\n",
            "step: 9368, loss: 3.5762759864610416e-08\n",
            "step: 9369, loss: 0.07910742610692978\n",
            "step: 9370, loss: 0.0025290304329246283\n",
            "step: 9371, loss: 0.00020832696463912725\n",
            "step: 9372, loss: 0.32424119114875793\n",
            "step: 9373, loss: 0.06139479950070381\n",
            "step: 9374, loss: 0.22484546899795532\n",
            "step: 9375, loss: 0.0070342207327485085\n",
            "step: 9376, loss: 0.02230481058359146\n",
            "step: 9377, loss: 0.17030513286590576\n",
            "step: 9378, loss: 0.1831241250038147\n",
            "step: 9379, loss: 0.11873089522123337\n",
            "step: 9380, loss: 0.19201917946338654\n",
            "step: 9381, loss: 0.8995734453201294\n",
            "step: 9382, loss: 0.04371793195605278\n",
            "step: 9383, loss: 0.5269691944122314\n",
            "step: 9384, loss: 0.6117372512817383\n",
            "step: 9385, loss: 0.5040491223335266\n",
            "step: 9386, loss: 0.19902324676513672\n",
            "step: 9387, loss: 0.004997723735868931\n",
            "step: 9388, loss: 0.008722711354494095\n",
            "step: 9389, loss: 0.0005992144579067826\n",
            "step: 9390, loss: 0.00040385033935308456\n",
            "step: 9391, loss: 7.816752622602507e-05\n",
            "step: 9392, loss: 0.1526203751564026\n",
            "step: 9393, loss: 0.07772710919380188\n",
            "step: 9394, loss: 0.6639739871025085\n",
            "step: 9395, loss: 0.3439686894416809\n",
            "step: 9396, loss: 0.004384417086839676\n",
            "step: 9397, loss: 0.6928569674491882\n",
            "step: 9398, loss: 0.1562081277370453\n",
            "step: 9399, loss: 0.39792031049728394\n",
            "step: 9400, loss: 0.00018187117530032992\n",
            "step: 9401, loss: 0.15028069913387299\n",
            "step: 9402, loss: 0.23827682435512543\n",
            "step: 9403, loss: 0.026236629113554955\n",
            "step: 9404, loss: 0.054374031722545624\n",
            "step: 9405, loss: 0.6218404173851013\n",
            "step: 9406, loss: 0.371346116065979\n",
            "step: 9407, loss: 2.2811121940612793\n",
            "step: 9408, loss: 1.4964687824249268\n",
            "step: 9409, loss: 0.9763306975364685\n",
            "step: 9410, loss: 1.8148019313812256\n",
            "step: 9411, loss: 0.9967384338378906\n",
            "step: 9412, loss: 1.1653740406036377\n",
            "step: 9413, loss: 0.8743828535079956\n",
            "step: 9414, loss: 0.18269728124141693\n",
            "step: 9415, loss: 0.7403905987739563\n",
            "step: 9416, loss: 0.6043897867202759\n",
            "step: 9417, loss: 0.382973313331604\n",
            "step: 9418, loss: 0.1881498396396637\n",
            "step: 9419, loss: 0.0\n",
            "step: 9420, loss: 2.2417123545892537e-05\n",
            "step: 9421, loss: 6.508742558253289e-07\n",
            "step: 9422, loss: 0.2646280825138092\n",
            "step: 9423, loss: 2.622604000634965e-08\n",
            "step: 9424, loss: 8.911162876756862e-05\n",
            "step: 9425, loss: 1.192092646817855e-08\n",
            "step: 9426, loss: 0.02444992959499359\n",
            "step: 9427, loss: 0.053036320954561234\n",
            "step: 9428, loss: 0.1039803996682167\n",
            "step: 9429, loss: 0.2358723282814026\n",
            "step: 9430, loss: 0.16375595331192017\n",
            "step: 9431, loss: 1.9023076674784534e-05\n",
            "step: 9432, loss: 0.00029972082120366395\n",
            "step: 9433, loss: 0.07412929832935333\n",
            "step: 9434, loss: 0.0021012502256780863\n",
            "step: 9435, loss: 0.14092443883419037\n",
            "step: 9436, loss: 0.09404174983501434\n",
            "step: 9437, loss: 0.14832031726837158\n",
            "step: 9438, loss: 0.17260441184043884\n",
            "step: 9439, loss: 0.14582349359989166\n",
            "step: 9440, loss: 0.0017325308872386813\n",
            "step: 9441, loss: 0.4995863437652588\n",
            "step: 9442, loss: 0.01588701270520687\n",
            "step: 9443, loss: 0.0015546143986284733\n",
            "step: 9444, loss: 0.00031175132608041167\n",
            "step: 9445, loss: 0.7795863151550293\n",
            "step: 9446, loss: 0.07618790864944458\n",
            "step: 9447, loss: 0.017290301620960236\n",
            "step: 9448, loss: 0.3114250898361206\n",
            "step: 9449, loss: 0.0750344768166542\n",
            "step: 9450, loss: 0.15856851637363434\n",
            "step: 9451, loss: 0.004892144817858934\n",
            "step: 9452, loss: 0.11459749191999435\n",
            "step: 9453, loss: 0.40840327739715576\n",
            "step: 9454, loss: 4.250561232765904e-06\n",
            "step: 9455, loss: 0.0002786212135106325\n",
            "step: 9456, loss: 5.4836245766409775e-08\n",
            "step: 9457, loss: 3.6477769072007504e-07\n",
            "step: 9458, loss: 0.006138557102531195\n",
            "step: 9459, loss: 2.4642073185532354e-05\n",
            "step: 9460, loss: 0.5586550235748291\n",
            "step: 9461, loss: 6.862250302219763e-05\n",
            "step: 9462, loss: 0.00357601186260581\n",
            "step: 9463, loss: 0.0009241437655873597\n",
            "step: 9464, loss: 0.21550840139389038\n",
            "step: 9465, loss: 0.12023007124662399\n",
            "step: 9466, loss: 4.887542104370368e-07\n",
            "step: 9467, loss: 0.0\n",
            "step: 9468, loss: 1.9033182979910634e-05\n",
            "step: 9469, loss: 8.106223248205424e-08\n",
            "step: 9470, loss: 0.005614980589598417\n",
            "step: 9471, loss: 0.05350286513566971\n",
            "step: 9472, loss: 1.279958087252453e-05\n",
            "step: 9473, loss: 9.296230018662754e-06\n",
            "step: 9474, loss: 0.000410100823501125\n",
            "step: 9475, loss: 0.01062521617859602\n",
            "step: 9476, loss: 1.0871682434299146e-06\n",
            "step: 9477, loss: 0.0003014461835846305\n",
            "step: 9478, loss: 0.13948355615139008\n",
            "step: 9479, loss: 0.0001159472594736144\n",
            "step: 9480, loss: 0.0217150766402483\n",
            "step: 9481, loss: 0.0010810617823153734\n",
            "step: 9482, loss: 1.3547538401326165e-05\n",
            "step: 9483, loss: 0.0013323872117325664\n",
            "step: 9484, loss: 0.002075708471238613\n",
            "step: 9485, loss: 0.10680356621742249\n",
            "step: 9486, loss: 0.06579472869634628\n",
            "step: 9487, loss: 0.003998591564595699\n",
            "step: 9488, loss: 0.07269052416086197\n",
            "step: 9489, loss: 0.0005869283922947943\n",
            "step: 9490, loss: 6.996658612479223e-06\n",
            "step: 9491, loss: 0.0009042014717124403\n",
            "step: 9492, loss: 0.46691280603408813\n",
            "step: 9493, loss: 4.124617021261656e-07\n",
            "step: 9494, loss: 6.298027528828243e-06\n",
            "step: 9495, loss: 2.2481622181658167e-06\n",
            "step: 9496, loss: 2.38418573772492e-09\n",
            "step: 9497, loss: 0.25685980916023254\n",
            "step: 9498, loss: 7.351220119744539e-05\n",
            "step: 9499, loss: 0.00014630536315962672\n",
            "step: 9500, loss: 0.006177797447890043\n",
            "step: 9501, loss: 1.1507668495178223\n",
            "step: 9502, loss: 0.3864857852458954\n",
            "step: 9503, loss: 0.12500251829624176\n",
            "step: 9504, loss: 0.41796600818634033\n",
            "step: 9505, loss: 1.0374916791915894\n",
            "step: 9506, loss: 1.1382237672805786\n",
            "step: 9507, loss: 0.8265143036842346\n",
            "step: 9508, loss: 1.1083202362060547\n",
            "step: 9509, loss: 1.0139583349227905\n",
            "step: 9510, loss: 0.9495887160301208\n",
            "step: 9511, loss: 1.7825570106506348\n",
            "step: 9512, loss: 0.6302092671394348\n",
            "step: 9513, loss: 0.08313151448965073\n",
            "step: 9514, loss: 0.8673215508460999\n",
            "step: 9515, loss: 1.8615869283676147\n",
            "step: 9516, loss: 0.6745672821998596\n",
            "step: 9517, loss: 0.519747793674469\n",
            "step: 9518, loss: 0.7778235077857971\n",
            "step: 9519, loss: 0.48847144842147827\n",
            "step: 9520, loss: 1.0006382465362549\n",
            "step: 9521, loss: 0.5642669200897217\n",
            "step: 9522, loss: 0.39062607288360596\n",
            "step: 9523, loss: 1.9244322776794434\n",
            "step: 9524, loss: 0.7068623304367065\n",
            "step: 9525, loss: 0.37258532643318176\n",
            "step: 9526, loss: 3.0864861011505127\n",
            "step: 9527, loss: 1.6848927736282349\n",
            "step: 9528, loss: 0.22999615967273712\n",
            "step: 9529, loss: 0.8226057291030884\n",
            "step: 9530, loss: 0.6996580362319946\n",
            "step: 9531, loss: 0.24085602164268494\n",
            "step: 9532, loss: 0.3207666873931885\n",
            "step: 9533, loss: 0.3737563192844391\n",
            "step: 9534, loss: 0.14048072695732117\n",
            "step: 9535, loss: 0.05821133032441139\n",
            "step: 9536, loss: 1.3044700622558594\n",
            "step: 9537, loss: 0.3599415719509125\n",
            "step: 9538, loss: 0.020900581032037735\n",
            "step: 9539, loss: 5.280638106341939e-06\n",
            "step: 9540, loss: 0.07010985165834427\n",
            "step: 9541, loss: 0.31693023443222046\n",
            "step: 9542, loss: 1.3931727409362793\n",
            "step: 9543, loss: 0.7813722491264343\n",
            "step: 9544, loss: 0.36184829473495483\n",
            "step: 9545, loss: 0.10834721475839615\n",
            "step: 9546, loss: 0.5370335578918457\n",
            "step: 9547, loss: 0.0015423905570060015\n",
            "step: 9548, loss: 0.00028703061980195343\n",
            "step: 9549, loss: 0.4955095946788788\n",
            "step: 9550, loss: 0.29738497734069824\n",
            "step: 9551, loss: 0.7019424438476562\n",
            "step: 9552, loss: 0.34336045384407043\n",
            "step: 9553, loss: 0.40587714314460754\n",
            "step: 9554, loss: 0.6279533505439758\n",
            "step: 9555, loss: 0.2176305651664734\n",
            "step: 9556, loss: 0.5338876247406006\n",
            "step: 9557, loss: 1.1193653345108032\n",
            "step: 9558, loss: 0.21715281903743744\n",
            "step: 9559, loss: 0.9072757959365845\n",
            "step: 9560, loss: 0.7278892397880554\n",
            "step: 9561, loss: 0.1224450021982193\n",
            "step: 9562, loss: 4.2516727262409404e-05\n",
            "step: 9563, loss: 0.003915628418326378\n",
            "step: 9564, loss: 0.43640726804733276\n",
            "step: 9565, loss: 4.118242213735357e-05\n",
            "step: 9566, loss: 0.00034648992004804313\n",
            "step: 9567, loss: 0.014658247120678425\n",
            "step: 9568, loss: 0.2566893994808197\n",
            "step: 9569, loss: 0.00045189697993919253\n",
            "step: 9570, loss: 0.0010209174361079931\n",
            "step: 9571, loss: 0.4981890022754669\n",
            "step: 9572, loss: 0.060549452900886536\n",
            "step: 9573, loss: 4.291510435905366e-07\n",
            "step: 9574, loss: 3.0994396382766354e-08\n",
            "step: 9575, loss: 6.879220018163323e-05\n",
            "step: 9576, loss: 0.13491694629192352\n",
            "step: 9577, loss: 0.004600405693054199\n",
            "step: 9578, loss: 1.148386400018353e-05\n",
            "step: 9579, loss: 1.192092558000013e-08\n",
            "step: 9580, loss: 0.0\n",
            "step: 9581, loss: 9.772551129572093e-05\n",
            "step: 9582, loss: 2.6347039238316938e-05\n",
            "step: 9583, loss: 7.867798501592915e-08\n",
            "step: 9584, loss: 0.06369031220674515\n",
            "step: 9585, loss: 0.0\n",
            "step: 9586, loss: 0.0011829682625830173\n",
            "step: 9587, loss: 0.15012477338314056\n",
            "step: 9588, loss: 1.2039911325700814e-06\n",
            "step: 9589, loss: 6.675709585124423e-08\n",
            "step: 9590, loss: 0.0\n",
            "step: 9591, loss: 0.1686733216047287\n",
            "step: 9592, loss: 0.010889346711337566\n",
            "step: 9593, loss: 2.38418573772492e-09\n",
            "step: 9594, loss: 1.668929350273629e-08\n",
            "step: 9595, loss: 1.090722707886016e-05\n",
            "step: 9596, loss: 5.542819963011425e-06\n",
            "step: 9597, loss: 1.192092558000013e-08\n",
            "step: 9598, loss: 0.14251722395420074\n",
            "step: 9599, loss: 5.960459148468544e-08\n",
            "step: 9600, loss: 7.412034756271169e-05\n",
            "step: 9601, loss: 2.6915688522421988e-06\n",
            "step: 9602, loss: 0.011071775108575821\n",
            "step: 9603, loss: 0.006902907509356737\n",
            "step: 9604, loss: 0.004581061191856861\n",
            "step: 9605, loss: 6.491271960840095e-06\n",
            "step: 9606, loss: 0.0003118181193713099\n",
            "step: 9607, loss: 6.526918241434032e-06\n",
            "step: 9608, loss: 2.2911153791937977e-06\n",
            "step: 9609, loss: 0.00012208890984766185\n",
            "step: 9610, loss: 0.04594944790005684\n",
            "step: 9611, loss: 0.0008532569045200944\n",
            "step: 9612, loss: 0.0949941948056221\n",
            "step: 9613, loss: 2.38418529363571e-08\n",
            "step: 9614, loss: 0.144846111536026\n",
            "step: 9615, loss: 0.0014765405794605613\n",
            "step: 9616, loss: 0.0034234686754643917\n",
            "step: 9617, loss: 0.00012006935867248103\n",
            "step: 9618, loss: 0.10649186372756958\n",
            "step: 9619, loss: 0.027831386774778366\n",
            "step: 9620, loss: 0.021254897117614746\n",
            "step: 9621, loss: 0.06107252091169357\n",
            "step: 9622, loss: 0.13441132009029388\n",
            "step: 9623, loss: 0.40236717462539673\n",
            "step: 9624, loss: 0.20383507013320923\n",
            "step: 9625, loss: 3.576246569991781e-07\n",
            "step: 9626, loss: 0.05948786810040474\n",
            "step: 9627, loss: 0.04453993961215019\n",
            "step: 9628, loss: 0.011772244237363338\n",
            "step: 9629, loss: 0.002188372425734997\n",
            "step: 9630, loss: 1.6682522982591763e-05\n",
            "step: 9631, loss: 0.06383640319108963\n",
            "step: 9632, loss: 1.1099416017532349\n",
            "step: 9633, loss: 0.5688117742538452\n",
            "step: 9634, loss: 0.32970961928367615\n",
            "step: 9635, loss: 0.00155264837667346\n",
            "step: 9636, loss: 0.0032061892561614513\n",
            "step: 9637, loss: 0.18587610125541687\n",
            "step: 9638, loss: 0.1437298059463501\n",
            "step: 9639, loss: 0.12859539687633514\n",
            "step: 9640, loss: 0.06854775547981262\n",
            "step: 9641, loss: 0.48158347606658936\n",
            "step: 9642, loss: 0.8541650176048279\n",
            "step: 9643, loss: 1.1985927820205688\n",
            "step: 9644, loss: 0.015658773481845856\n",
            "step: 9645, loss: 0.0\n",
            "step: 9646, loss: 1.778380283212755e-05\n",
            "step: 9647, loss: 0.0\n",
            "step: 9648, loss: 0.12576845288276672\n",
            "step: 9649, loss: 0.0\n",
            "step: 9650, loss: 2.541380808906979e-06\n",
            "step: 9651, loss: 0.0011597353732213378\n",
            "step: 9652, loss: 5.909780611546012e-06\n",
            "step: 9653, loss: 2.38418573772492e-09\n",
            "step: 9654, loss: 1.025137953547528e-05\n",
            "step: 9655, loss: 2.2888058026637736e-07\n",
            "step: 9656, loss: 7.15255676908555e-09\n",
            "step: 9657, loss: 1.6044940593928914e-06\n",
            "step: 9658, loss: 0.0003158623294439167\n",
            "step: 9659, loss: 1.907347702001516e-08\n",
            "step: 9660, loss: 4.243814260007639e-07\n",
            "step: 9661, loss: 0.029655879363417625\n",
            "step: 9662, loss: 0.0009011488291434944\n",
            "step: 9663, loss: 1.4113885526967351e-06\n",
            "step: 9664, loss: 3.147108884604677e-07\n",
            "step: 9665, loss: 0.0\n",
            "step: 9666, loss: 0.0\n",
            "step: 9667, loss: 0.18170331418514252\n",
            "step: 9668, loss: 0.14957204461097717\n",
            "step: 9669, loss: 3.576275631189674e-08\n",
            "step: 9670, loss: 4.246919706929475e-05\n",
            "step: 9671, loss: 0.00828039925545454\n",
            "step: 9672, loss: 0.011829385533928871\n",
            "step: 9673, loss: 1.277897695217689e-06\n",
            "step: 9674, loss: 0.0016618412919342518\n",
            "step: 9675, loss: 7.13719600753393e-06\n",
            "step: 9676, loss: 0.003950676415115595\n",
            "step: 9677, loss: 6.086812209105119e-05\n",
            "step: 9678, loss: 9.894201866700314e-07\n",
            "step: 9679, loss: 4.1337440052302554e-05\n",
            "step: 9680, loss: 4.8721081839175895e-05\n",
            "step: 9681, loss: 0.006296277511864901\n",
            "step: 9682, loss: 2.8393646971380804e-06\n",
            "step: 9683, loss: 1.1205654004697863e-07\n",
            "step: 9684, loss: 0.0003857865813188255\n",
            "step: 9685, loss: 1.389979115629103e-05\n",
            "step: 9686, loss: 0.610484778881073\n",
            "step: 9687, loss: 0.006651408039033413\n",
            "step: 9688, loss: 0.04425196722149849\n",
            "step: 9689, loss: 1.800400968932081e-05\n",
            "step: 9690, loss: 0.00027607183437794447\n",
            "step: 9691, loss: 2.38418573772492e-09\n",
            "step: 9692, loss: 6.205301906447858e-05\n",
            "step: 9693, loss: 4.053111624102712e-08\n",
            "step: 9694, loss: 0.00023994380899239331\n",
            "step: 9695, loss: 0.0002575246908236295\n",
            "step: 9696, loss: 0.00029516438371501863\n",
            "step: 9697, loss: 0.00015714865003246814\n",
            "step: 9698, loss: 6.405298336176202e-06\n",
            "step: 9699, loss: 0.0003781065752264112\n",
            "step: 9700, loss: 3.334601933602244e-05\n",
            "step: 9701, loss: 2.503382461327419e-07\n",
            "step: 9702, loss: 6.176500846777344e-06\n",
            "step: 9703, loss: 4.3793329496111255e-06\n",
            "step: 9704, loss: 1.7404195205017459e-06\n",
            "step: 9705, loss: 1.192092646817855e-08\n",
            "step: 9706, loss: 3.7431368582474533e-07\n",
            "step: 9707, loss: 1.8018708942690864e-05\n",
            "step: 9708, loss: 4.243806586146093e-07\n",
            "step: 9709, loss: 5.96045985901128e-08\n",
            "step: 9710, loss: 1.9073395662871917e-07\n",
            "step: 9711, loss: 0.00026299135060980916\n",
            "step: 9712, loss: 4.839875487050449e-07\n",
            "step: 9713, loss: 0.0064142863266170025\n",
            "step: 9714, loss: 9.219401545124128e-05\n",
            "step: 9715, loss: 0.0\n",
            "step: 9716, loss: 2.2081681890995242e-05\n",
            "step: 9717, loss: 0.0020736781880259514\n",
            "step: 9718, loss: 0.008054669015109539\n",
            "step: 9719, loss: 4.141618046560325e-05\n",
            "step: 9720, loss: 0.0013388436054810882\n",
            "step: 9721, loss: 4.76837103136063e-09\n",
            "step: 9722, loss: 0.0\n",
            "step: 9723, loss: 0.0004597385704983026\n",
            "step: 9724, loss: 6.866337685096369e-07\n",
            "step: 9725, loss: 1.907347702001516e-08\n",
            "step: 9726, loss: 0.004850855562835932\n",
            "step: 9727, loss: 0.03017108514904976\n",
            "step: 9728, loss: 0.11326231062412262\n",
            "step: 9729, loss: 0.676948070526123\n",
            "step: 9730, loss: 0.32029974460601807\n",
            "step: 9731, loss: 1.1288803815841675\n",
            "step: 9732, loss: 0.758394181728363\n",
            "step: 9733, loss: 0.10693475604057312\n",
            "step: 9734, loss: 0.7174622416496277\n",
            "step: 9735, loss: 0.9237731695175171\n",
            "step: 9736, loss: 1.4032402038574219\n",
            "step: 9737, loss: 1.4541090726852417\n",
            "step: 9738, loss: 0.3042822778224945\n",
            "step: 9739, loss: 0.2166437953710556\n",
            "step: 9740, loss: 0.22078099846839905\n",
            "step: 9741, loss: 0.01600179634988308\n",
            "step: 9742, loss: 0.0395059660077095\n",
            "step: 9743, loss: 0.073999784886837\n",
            "step: 9744, loss: 5.509132279257756e-06\n",
            "step: 9745, loss: 0.0568285807967186\n",
            "step: 9746, loss: 2.8610977096832357e-05\n",
            "step: 9747, loss: 0.0003212882438674569\n",
            "step: 9748, loss: 0.003981289453804493\n",
            "step: 9749, loss: 0.495096892118454\n",
            "step: 9750, loss: 0.05103196203708649\n",
            "step: 9751, loss: 0.008458461612462997\n",
            "step: 9752, loss: 0.20529475808143616\n",
            "step: 9753, loss: 0.1902076154947281\n",
            "step: 9754, loss: 0.0023308091331273317\n",
            "step: 9755, loss: 0.09533170610666275\n",
            "step: 9756, loss: 0.0023503003176301718\n",
            "step: 9757, loss: 2.0743953427881934e-05\n",
            "step: 9758, loss: 0.001160111976787448\n",
            "step: 9759, loss: 0.009106108918786049\n",
            "step: 9760, loss: 0.0007293985690921545\n",
            "step: 9761, loss: 0.04234832897782326\n",
            "step: 9762, loss: 1.1015490293502808\n",
            "step: 9763, loss: 0.11909809708595276\n",
            "step: 9764, loss: 3.8146946934602965e-08\n",
            "step: 9765, loss: 3.337857279461787e-08\n",
            "step: 9766, loss: 7.15255632499634e-09\n",
            "step: 9767, loss: 6.627956281590741e-07\n",
            "step: 9768, loss: 6.6322845668764785e-06\n",
            "step: 9769, loss: 0.005366004537791014\n",
            "step: 9770, loss: 0.0023423219099640846\n",
            "step: 9771, loss: 0.007521175779402256\n",
            "step: 9772, loss: 3.709613793034805e-06\n",
            "step: 9773, loss: 7.934104360174388e-05\n",
            "step: 9774, loss: 0.005029094405472279\n",
            "step: 9775, loss: 9.059891681317822e-08\n",
            "step: 9776, loss: 0.0001049467537086457\n",
            "step: 9777, loss: 1.1672001164697576e-05\n",
            "step: 9778, loss: 0.22447305917739868\n",
            "step: 9779, loss: 6.62973570797476e-06\n",
            "step: 9780, loss: 0.05728133022785187\n",
            "step: 9781, loss: 0.30902722477912903\n",
            "step: 9782, loss: 0.0751589983701706\n",
            "step: 9783, loss: 0.3535713851451874\n",
            "step: 9784, loss: 0.16151058673858643\n",
            "step: 9785, loss: 0.1816704124212265\n",
            "step: 9786, loss: 0.22174161672592163\n",
            "step: 9787, loss: 0.4889846444129944\n",
            "step: 9788, loss: 4.834838364331517e-06\n",
            "step: 9789, loss: 0.29636985063552856\n",
            "step: 9790, loss: 0.0004995344788767397\n",
            "step: 9791, loss: 0.00449085608124733\n",
            "step: 9792, loss: 0.005750502459704876\n",
            "step: 9793, loss: 0.003830687375739217\n",
            "step: 9794, loss: 0.09366932511329651\n",
            "step: 9795, loss: 0.05349816381931305\n",
            "step: 9796, loss: 0.027077384293079376\n",
            "step: 9797, loss: 0.33924025297164917\n",
            "step: 9798, loss: 0.18264397978782654\n",
            "step: 9799, loss: 0.0006214415770955384\n",
            "step: 9800, loss: 9.53674117454284e-09\n",
            "step: 9801, loss: 0.07926192879676819\n",
            "step: 9802, loss: 5.245205159098987e-08\n",
            "step: 9803, loss: 5.835727279190905e-06\n",
            "step: 9804, loss: 1.3875733202439733e-06\n",
            "step: 9805, loss: 0.002375246724113822\n",
            "step: 9806, loss: 6.914130779023253e-08\n",
            "step: 9807, loss: 0.09586415439844131\n",
            "step: 9808, loss: 0.00018296144844498485\n",
            "step: 9809, loss: 6.437298338823894e-08\n",
            "step: 9810, loss: 0.1139155849814415\n",
            "step: 9811, loss: 1.907348234908568e-08\n",
            "step: 9812, loss: 0.055898260325193405\n",
            "step: 9813, loss: 0.10509995371103287\n",
            "step: 9814, loss: 3.099440704090739e-08\n",
            "step: 9815, loss: 8.209585939766839e-05\n",
            "step: 9816, loss: 0.00048381093074567616\n",
            "step: 9817, loss: 1.169962797575863e-05\n",
            "step: 9818, loss: 2.3149727894633543e-06\n",
            "step: 9819, loss: 4.053111624102712e-08\n",
            "step: 9820, loss: 2.596310878288932e-06\n",
            "step: 9821, loss: 2.0407821921253344e-06\n",
            "step: 9822, loss: 3.618913524405798e-06\n",
            "step: 9823, loss: 2.7749352739192545e-05\n",
            "step: 9824, loss: 1.835815481854297e-07\n",
            "step: 9825, loss: 0.0\n",
            "step: 9826, loss: 0.00014255552378017455\n",
            "step: 9827, loss: 4.76837147544984e-09\n",
            "step: 9828, loss: 1.907348234908568e-08\n",
            "step: 9829, loss: 2.38418573772492e-09\n",
            "step: 9830, loss: 0.04761120676994324\n",
            "step: 9831, loss: 0.005047434009611607\n",
            "step: 9832, loss: 2.208132718806155e-05\n",
            "step: 9833, loss: 0.12410473078489304\n",
            "step: 9834, loss: 0.13942259550094604\n",
            "step: 9835, loss: 1.022555079543963e-05\n",
            "step: 9836, loss: 0.0004564375849440694\n",
            "step: 9837, loss: 6.294152967711852e-07\n",
            "step: 9838, loss: 2.38418573772492e-09\n",
            "step: 9839, loss: 0.0\n",
            "step: 9840, loss: 0.0\n",
            "step: 9841, loss: 0.000359807803761214\n",
            "step: 9842, loss: 5.960459148468544e-08\n",
            "step: 9843, loss: 1.015644556900952e-06\n",
            "step: 9844, loss: 4.76837103136063e-09\n",
            "step: 9845, loss: 3.60008840516457e-07\n",
            "step: 9846, loss: 1.0752529533419874e-06\n",
            "step: 9847, loss: 1.0728809485271995e-07\n",
            "step: 9848, loss: 4.76837103136063e-09\n",
            "step: 9849, loss: 1.192092558000013e-08\n",
            "step: 9850, loss: 4.336448910180479e-06\n",
            "step: 9851, loss: 1.907348234908568e-08\n",
            "step: 9852, loss: 0.0\n",
            "step: 9853, loss: 0.0\n",
            "step: 9854, loss: 0.0\n",
            "step: 9855, loss: 2.1457660537294032e-08\n",
            "step: 9856, loss: 0.0\n",
            "step: 9857, loss: 2.7956897611147724e-05\n",
            "step: 9858, loss: 8.362205335288309e-06\n",
            "step: 9859, loss: 2.009824584092712e-06\n",
            "step: 9860, loss: 0.040605708956718445\n",
            "step: 9861, loss: 0.0005369861610233784\n",
            "step: 9862, loss: 2.5210196326952428e-05\n",
            "step: 9863, loss: 0.0009205241221934557\n",
            "step: 9864, loss: 2.6606981009535957e-06\n",
            "step: 9865, loss: 0.000445220764959231\n",
            "step: 9866, loss: 2.0159934138064273e-05\n",
            "step: 9867, loss: 0.07504294067621231\n",
            "step: 9868, loss: 1.6450857742711378e-07\n",
            "step: 9869, loss: 7.69468806538498e-06\n",
            "step: 9870, loss: 0.00084523088298738\n",
            "step: 9871, loss: 9.53674117454284e-09\n",
            "step: 9872, loss: 4.395968971948605e-06\n",
            "step: 9873, loss: 0.0\n",
            "step: 9874, loss: 0.31269654631614685\n",
            "step: 9875, loss: 0.0008261940092779696\n",
            "step: 9876, loss: 9.647108527133241e-06\n",
            "step: 9877, loss: 7.15255676908555e-09\n",
            "step: 9878, loss: 3.6905692013533553e-06\n",
            "step: 9879, loss: 0.0\n",
            "step: 9880, loss: 0.005948076955974102\n",
            "step: 9881, loss: 1.468633854528889e-06\n",
            "step: 9882, loss: 2.145766764272139e-08\n",
            "step: 9883, loss: 4.76837103136063e-09\n",
            "step: 9884, loss: 3.3378576347331546e-08\n",
            "step: 9885, loss: 4.76837103136063e-09\n",
            "step: 9886, loss: 2.1790303890156792e-06\n",
            "step: 9887, loss: 1.2396311831253115e-05\n",
            "step: 9888, loss: 7.510046202696685e-07\n",
            "step: 9889, loss: 7.152545578037461e-08\n",
            "step: 9890, loss: 0.0003118329623248428\n",
            "step: 9891, loss: 0.0\n",
            "step: 9892, loss: 0.0\n",
            "step: 9893, loss: 0.0350935123860836\n",
            "step: 9894, loss: 0.016787109896540642\n",
            "step: 9895, loss: 7.15255632499634e-09\n",
            "step: 9896, loss: 1.7547374682180816e-06\n",
            "step: 9897, loss: 0.0005032592453062534\n",
            "step: 9898, loss: 0.06680676341056824\n",
            "step: 9899, loss: 8.183782483683899e-06\n",
            "step: 9900, loss: 3.480894861240813e-07\n",
            "step: 9901, loss: 1.7642925342897797e-07\n",
            "step: 9902, loss: 0.00021172208653297275\n",
            "step: 9903, loss: 2.7607372885540826e-06\n",
            "step: 9904, loss: 5.984234121569898e-07\n",
            "step: 9905, loss: 1.9075576346949674e-05\n",
            "step: 9906, loss: 3.576275631189674e-08\n",
            "step: 9907, loss: 7.009391538304044e-07\n",
            "step: 9908, loss: 8.058385674303281e-07\n",
            "step: 9909, loss: 7.15255676908555e-09\n",
            "step: 9910, loss: 2.3841845830929742e-08\n",
            "step: 9911, loss: 7.152544867494726e-08\n",
            "step: 9912, loss: 0.2673228979110718\n",
            "step: 9913, loss: 7.55772703087132e-07\n",
            "step: 9914, loss: 1.2874568255938357e-07\n",
            "step: 9915, loss: 8.106224669290896e-08\n",
            "step: 9916, loss: 0.002049630042165518\n",
            "step: 9917, loss: 0.0\n",
            "step: 9918, loss: 4.486557827476645e-06\n",
            "step: 9919, loss: 5.006783965200157e-08\n",
            "step: 9920, loss: 4.5537694859376643e-07\n",
            "step: 9921, loss: 2.145766231365087e-08\n",
            "step: 9922, loss: 1.215933593812224e-07\n",
            "step: 9923, loss: 2.38418573772492e-09\n",
            "step: 9924, loss: 0.0\n",
            "step: 9925, loss: 1.1426836863392964e-05\n",
            "step: 9926, loss: 3.552405303253181e-07\n",
            "step: 9927, loss: 0.002086911117658019\n",
            "step: 9928, loss: 5.721994966734201e-07\n",
            "step: 9929, loss: 1.5568396065646084e-06\n",
            "step: 9930, loss: 7.74970612837933e-06\n",
            "step: 9931, loss: 7.15255676908555e-09\n",
            "step: 9932, loss: 2.408013131116604e-07\n",
            "step: 9933, loss: 6.045381724106846e-06\n",
            "step: 9934, loss: 4.691527919931104e-06\n",
            "step: 9935, loss: 3.0994396382766354e-08\n",
            "step: 9936, loss: 6.961724352549936e-07\n",
            "step: 9937, loss: 4.76837147544984e-09\n",
            "step: 9938, loss: 1.0383204426034354e-05\n",
            "step: 9939, loss: 0.0019496433669701219\n",
            "step: 9940, loss: 4.115073170396499e-05\n",
            "step: 9941, loss: 2.38418573772492e-09\n",
            "step: 9942, loss: 1.9827759388135746e-05\n",
            "step: 9943, loss: 0.00646856427192688\n",
            "step: 9944, loss: 0.0059485528618097305\n",
            "step: 9945, loss: 4.0671102397027425e-06\n",
            "step: 9946, loss: 0.0\n",
            "step: 9947, loss: 2.38418573772492e-09\n",
            "step: 9948, loss: 0.0\n",
            "step: 9949, loss: 8.988243394014717e-07\n",
            "step: 9950, loss: 3.361676021995663e-07\n",
            "step: 9951, loss: 0.0\n",
            "step: 9952, loss: 0.00011669893137877807\n",
            "step: 9953, loss: 0.00033603273914195597\n",
            "step: 9954, loss: 0.00031878231675364077\n",
            "step: 9955, loss: 0.040534380823373795\n",
            "step: 9956, loss: 2.1695991847536789e-07\n",
            "step: 9957, loss: 0.007977220229804516\n",
            "step: 9958, loss: 3.843056038022041e-05\n",
            "step: 9959, loss: 2.1457660537294032e-08\n",
            "step: 9960, loss: 0.0004682033904828131\n",
            "step: 9961, loss: 2.0286293874960393e-05\n",
            "step: 9962, loss: 0.007261929102241993\n",
            "step: 9963, loss: 0.22375698387622833\n",
            "step: 9964, loss: 5.266020889393985e-05\n",
            "step: 9965, loss: 0.0001073984894901514\n",
            "step: 9966, loss: 0.09394707530736923\n",
            "step: 9967, loss: 0.005954484920948744\n",
            "step: 9968, loss: 0.0028730416670441628\n",
            "step: 9969, loss: 0.0015047010965645313\n",
            "step: 9970, loss: 1.2922627320222091e-05\n",
            "step: 9971, loss: 0.06406354159116745\n",
            "step: 9972, loss: 3.875411130138673e-05\n",
            "step: 9973, loss: 0.0005029691965319216\n",
            "step: 9974, loss: 0.00017922879487741739\n",
            "step: 9975, loss: 0.00022951584833208472\n",
            "step: 9976, loss: 0.00010147356078960001\n",
            "step: 9977, loss: 0.0005153273232281208\n",
            "step: 9978, loss: 0.0023173964582383633\n",
            "step: 9979, loss: 0.14656968414783478\n",
            "step: 9980, loss: 0.001926486031152308\n",
            "step: 9981, loss: 0.0008270387188531458\n",
            "step: 9982, loss: 9.312781185144559e-05\n",
            "step: 9983, loss: 4.432009973243112e-06\n",
            "step: 9984, loss: 5.157278064871207e-05\n",
            "step: 9985, loss: 0.0006042770110070705\n",
            "step: 9986, loss: 0.0006335138459689915\n",
            "step: 9987, loss: 0.0006368997856043279\n",
            "step: 9988, loss: 0.4083607792854309\n",
            "step: 9989, loss: 0.028281239792704582\n",
            "step: 9990, loss: 2.479541194588819e-07\n",
            "step: 9991, loss: 3.0994389277338996e-08\n",
            "step: 9992, loss: 9.53674117454284e-09\n",
            "step: 9993, loss: 1.8071456224788562e-06\n",
            "step: 9994, loss: 3.838332759187324e-06\n",
            "step: 9995, loss: 1.316518410021672e-05\n",
            "step: 9996, loss: 2.816387132043019e-05\n",
            "step: 9997, loss: 2.199233313149307e-05\n",
            "step: 9998, loss: 0.00025398589787073433\n",
            "step: 9999, loss: 6.455363291024696e-06\n",
            "step: 10000, loss: 0.011105972342193127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE54VKpHl_3j"
      },
      "source": [
        "#Lưu tham số mô hình"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2BoEnltl4OW"
      },
      "source": [
        "#Khôi phục"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4z8qt_ql6iE"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  trainable_variables = tf.trainable_variables()\n",
        "  for variable in trainable_variables:\n",
        "    saved_value = restore_parameters(variable.name, 44)\n",
        "    assign_op = variable.assign(saved_value)\n",
        "    sess.run(assign_op)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}